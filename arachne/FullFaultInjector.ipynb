{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, \"../apricot/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjsohn/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jjsohn/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jjsohn/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jjsohn/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jjsohn/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jjsohn/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import CifarClassifier\n",
    "import model\n",
    "import pytorch2keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "idlm_path = './models/CIFAR10_CifarClassifier.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarClassifier(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_net = CifarClassifier(img_size = 3*32*32)\n",
    "org_net.load_state_dict(torch.load(idlm_path))\n",
    "org_net.eval()\n",
    "org_net_org_weights = org_net.dense_layers[-1][-1].weight.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0303,  0.2385,  0.2139],\n",
      "          [ 0.0067, -0.1750,  0.0638],\n",
      "          [ 0.1029,  0.0129, -0.0354]],\n",
      "\n",
      "         [[-0.1706, -0.1518, -0.1546],\n",
      "          [-0.0834, -0.1887,  0.0242],\n",
      "          [-0.0789, -0.0695, -0.1823]],\n",
      "\n",
      "         [[-0.1093,  0.0612,  0.0718],\n",
      "          [-0.0521,  0.0259,  0.1292],\n",
      "          [ 0.0935, -0.0489, -0.0781]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0280,  0.1058,  0.1323],\n",
      "          [-0.0297, -0.0357, -0.3150],\n",
      "          [-0.0578, -0.0934,  0.0427]],\n",
      "\n",
      "         [[ 0.1431,  0.2659,  0.2494],\n",
      "          [-0.1142, -0.1243, -0.1658],\n",
      "          [-0.1367,  0.0363, -0.0245]],\n",
      "\n",
      "         [[ 0.2578, -0.1678,  0.0977],\n",
      "          [-0.0521, -0.0551, -0.0103],\n",
      "          [-0.0262,  0.0837, -0.1140]]],\n",
      "\n",
      "\n",
      "        [[[-0.0570, -0.2920,  0.0649],\n",
      "          [-0.2321, -0.0058, -0.0722],\n",
      "          [ 0.1853, -0.1142, -0.1197]],\n",
      "\n",
      "         [[-0.0230,  0.0724,  0.0617],\n",
      "          [ 0.0149, -0.0870, -0.1538],\n",
      "          [-0.1856,  0.0544, -0.0559]],\n",
      "\n",
      "         [[ 0.1704,  0.1557, -0.0410],\n",
      "          [ 0.1885,  0.2088,  0.1413],\n",
      "          [-0.1395,  0.1063,  0.1030]]],\n",
      "\n",
      "\n",
      "        [[[-0.1791, -0.1599,  0.1591],\n",
      "          [-0.2023,  0.1551,  0.0381],\n",
      "          [ 0.0327,  0.1570,  0.1444]],\n",
      "\n",
      "         [[ 0.1765,  0.0032, -0.0774],\n",
      "          [ 0.1602, -0.1863,  0.0550],\n",
      "          [-0.1576, -0.1173, -0.0785]],\n",
      "\n",
      "         [[ 0.0559,  0.1540, -0.1020],\n",
      "          [ 0.0657,  0.0270, -0.1164],\n",
      "          [ 0.1675, -0.1032, -0.1049]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1675, -0.2032,  0.0368],\n",
      "          [ 0.0305, -0.0268,  0.0435],\n",
      "          [ 0.1495, -0.2198,  0.0406]],\n",
      "\n",
      "         [[ 0.0668, -0.1832,  0.1360],\n",
      "          [ 0.0994, -0.1716, -0.0286],\n",
      "          [ 0.0905, -0.1669,  0.1917]],\n",
      "\n",
      "         [[ 0.0475, -0.0878,  0.0143],\n",
      "          [ 0.0597, -0.1145,  0.1457],\n",
      "          [ 0.0483, -0.1089, -0.0118]]],\n",
      "\n",
      "\n",
      "        [[[-0.0681, -0.0626,  0.2386],\n",
      "          [-0.1289,  0.2215, -0.0158],\n",
      "          [ 0.1513,  0.0202,  0.0097]],\n",
      "\n",
      "         [[-0.0097, -0.0446,  0.0091],\n",
      "          [-0.0296,  0.0826, -0.0336],\n",
      "          [ 0.1306, -0.0720, -0.0160]],\n",
      "\n",
      "         [[-0.0654, -0.1635,  0.1148],\n",
      "          [-0.1209,  0.1385,  0.0562],\n",
      "          [ 0.0438,  0.0727, -0.1123]]],\n",
      "\n",
      "\n",
      "        [[[-0.1727,  0.2420, -0.0369],\n",
      "          [-0.1842,  0.1249,  0.0741],\n",
      "          [-0.1959, -0.0384,  0.1709]],\n",
      "\n",
      "         [[-0.2547,  0.0901,  0.0419],\n",
      "          [-0.0842,  0.1272,  0.0309],\n",
      "          [-0.1305, -0.0424, -0.0820]],\n",
      "\n",
      "         [[ 0.1152,  0.0788, -0.1363],\n",
      "          [ 0.0184,  0.0343, -0.1073],\n",
      "          [ 0.0111,  0.1352,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[-0.1023, -0.0359,  0.0766],\n",
      "          [ 0.1304, -0.0945, -0.0557],\n",
      "          [-0.0883,  0.0799,  0.0253]],\n",
      "\n",
      "         [[ 0.1304,  0.1645, -0.2191],\n",
      "          [ 0.1402, -0.0853,  0.0555],\n",
      "          [-0.1926,  0.1741, -0.0433]],\n",
      "\n",
      "         [[-0.2631,  0.0539,  0.1490],\n",
      "          [ 0.1749, -0.2401,  0.0283],\n",
      "          [ 0.0096,  0.0117, -0.0292]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3556,  0.1674,  0.1902],\n",
      "          [-0.1330, -0.0770, -0.2507],\n",
      "          [-0.1321,  0.0417, -0.0385]],\n",
      "\n",
      "         [[-0.0741, -0.1619,  0.0689],\n",
      "          [-0.2390, -0.0479, -0.0049],\n",
      "          [ 0.2024, -0.0747,  0.0306]],\n",
      "\n",
      "         [[-0.0631,  0.0429, -0.0418],\n",
      "          [ 0.0807,  0.0327, -0.0375],\n",
      "          [-0.0062,  0.1140,  0.0705]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0871, -0.0984, -0.0420],\n",
      "          [-0.1001, -0.0754,  0.0997],\n",
      "          [-0.0043,  0.1183,  0.0004]],\n",
      "\n",
      "         [[ 0.2098, -0.0245, -0.0654],\n",
      "          [-0.0192, -0.0596,  0.1474],\n",
      "          [-0.1283,  0.0366, -0.2151]],\n",
      "\n",
      "         [[ 0.0350, -0.0246, -0.1050],\n",
      "          [-0.0804, -0.2454,  0.1690],\n",
      "          [-0.0067,  0.2361,  0.0688]]],\n",
      "\n",
      "\n",
      "        [[[-0.0741,  0.1710, -0.0418],\n",
      "          [ 0.1179, -0.2769,  0.0744],\n",
      "          [-0.0010,  0.1426, -0.0580]],\n",
      "\n",
      "         [[-0.1197, -0.0160,  0.0993],\n",
      "          [ 0.0329, -0.1948,  0.1712],\n",
      "          [ 0.1034,  0.0602, -0.2341]],\n",
      "\n",
      "         [[-0.1198,  0.1052,  0.0391],\n",
      "          [ 0.1125, -0.2695,  0.0615],\n",
      "          [ 0.0517,  0.0592, -0.0710]]],\n",
      "\n",
      "\n",
      "        [[[-0.1849,  0.0978,  0.2900],\n",
      "          [-0.1392,  0.1024, -0.0353],\n",
      "          [-0.1231, -0.1716, -0.0250]],\n",
      "\n",
      "         [[ 0.1632, -0.2116, -0.1212],\n",
      "          [ 0.0192, -0.1137,  0.1306],\n",
      "          [ 0.2325, -0.0209,  0.0468]],\n",
      "\n",
      "         [[ 0.0603, -0.0271, -0.1334],\n",
      "          [ 0.1884, -0.0904,  0.0175],\n",
      "          [ 0.0360, -0.0313,  0.0123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0956, -0.0336, -0.0291],\n",
      "          [ 0.0427, -0.0376,  0.0024],\n",
      "          [-0.0720,  0.0719, -0.0208]],\n",
      "\n",
      "         [[ 0.0457, -0.2600,  0.0356],\n",
      "          [ 0.0600, -0.1689,  0.1673],\n",
      "          [-0.0592, -0.1477,  0.1578]],\n",
      "\n",
      "         [[-0.0897, -0.1656,  0.2348],\n",
      "          [-0.0778, -0.0987,  0.1108],\n",
      "          [-0.0883, -0.0771,  0.2174]]],\n",
      "\n",
      "\n",
      "        [[[-0.0488,  0.0393, -0.0903],\n",
      "          [ 0.1086, -0.1083, -0.0924],\n",
      "          [ 0.1888, -0.0457,  0.1068]],\n",
      "\n",
      "         [[-0.0810,  0.0318,  0.0146],\n",
      "          [-0.0984,  0.0721, -0.0674],\n",
      "          [-0.1164,  0.0092,  0.0767]],\n",
      "\n",
      "         [[ 0.3328,  0.0208, -0.1706],\n",
      "          [-0.0423,  0.2281,  0.2847],\n",
      "          [-0.1873,  0.0274, -0.0274]]],\n",
      "\n",
      "\n",
      "        [[[-0.1577, -0.0070, -0.1151],\n",
      "          [ 0.1413,  0.1570,  0.0657],\n",
      "          [-0.0707, -0.0880,  0.0195]],\n",
      "\n",
      "         [[-0.0328, -0.0578, -0.0291],\n",
      "          [-0.1444, -0.0285, -0.1647],\n",
      "          [ 0.1979,  0.0632,  0.1404]],\n",
      "\n",
      "         [[ 0.1278,  0.1127,  0.1579],\n",
      "          [-0.1739, -0.2494, -0.1831],\n",
      "          [ 0.1053,  0.1268,  0.0442]]],\n",
      "\n",
      "\n",
      "        [[[-0.1748, -0.1702, -0.0699],\n",
      "          [-0.1379, -0.3204, -0.1776],\n",
      "          [-0.0727,  0.1415,  0.0796]],\n",
      "\n",
      "         [[ 0.0944,  0.0860,  0.0743],\n",
      "          [-0.0479,  0.1701, -0.0115],\n",
      "          [-0.1245, -0.2547, -0.1074]],\n",
      "\n",
      "         [[ 0.1305, -0.0621, -0.2021],\n",
      "          [ 0.1461, -0.1806,  0.1123],\n",
      "          [-0.0231,  0.0726,  0.0395]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in org_net.conv_layers[0]:\n",
    "    if type(layer) == nn.Conv2d:\n",
    "        print(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "seed_val = 0\n",
    "proportion = 0.05\n",
    "\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_faults(layer):\n",
    "    if type(layer) in (nn.Linear, nn.Conv2d):\n",
    "        org_weights_np = layer.weight.detach().numpy()\n",
    "        ow_stdev = np.std(org_weights_np)\n",
    "        random_faults = np.random.binomial(1, proportion, size=org_weights_np.shape)\n",
    "        new_weights_np = (1-random_faults)*org_weights_np + random_faults*ow_stdev*np.random.randn(*org_weights_np.shape)\n",
    "        layer.weight = nn.Parameter(torch.from_numpy(new_weights_np).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_faults_for_keras_mdl(layer):\n",
    "    import re\n",
    "    targeting_clname_pattns = ['Dense*', 'Conv*'] #if not target_all else None\n",
    "    is_target = lambda clname,targets: (targets is None) or any([bool(re.match(t,clname)) for t in targets])\n",
    "    \n",
    "    class_name = type(layer).__name__\n",
    "    if is_target(class_name, targeting_clname_pattns):\n",
    "        #org_weights_np = layer.weight.detach().numpy()\n",
    "        org_weights_np, org_bias = layer.get_weights()\n",
    "        \n",
    "        ow_stdev = np.std(org_weights_np)\n",
    "        random_faults = np.random.binomial(1, proportion, size = org_weights_np.shape)\n",
    "        new_weights_np = (1-random_faults)*org_weights_np + random_faults*ow_stdev*np.random.randn(*org_weights_np.shape)\n",
    "        #layer.weight = nn.Parameter(torch.from_numpy(new_weights_np).float())\n",
    "        layer.set_weights([new_weights_np, org_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_1/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_1/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_1/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_1/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_1/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_1/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_1/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_2/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_2/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_2/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_2/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_2/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_2/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_2/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_2/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_3/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_3/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_3/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_3/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_3/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_3/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_3/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_3/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_4/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_4/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_4/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_4/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_4/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_4/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_4/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_4/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_5/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_5/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_5/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_5/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_5/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_5/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_5/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_5/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_6/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_6/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_6/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_6/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_6/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_6/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_6/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_6/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_7/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_7/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_7/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_7/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_7/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_7/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_7/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_7/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_8/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_8/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_8/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_8/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_8/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_8/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_8/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_8/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_9/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_9/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_9/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_9/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_9/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_9/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_9/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_9/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_10/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_10/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_10/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_10/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_10/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_10/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_10/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_10/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_11/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_11/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_11/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_11/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_11/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_11/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_11/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_11/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_12/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_12/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_12/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_12/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_12/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_12/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_12/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_12/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_13/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_13/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_13/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_13/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_13/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_13/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_13/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_13/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_14/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_14/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_14/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_14/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_14/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_14/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_14/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_14/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_15/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_15/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_15/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_15/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_15/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_15/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_15/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_15/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_16/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_16/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_16/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_16/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_16/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_16/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_16/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_16/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_17/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_17/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_17/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_17/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_17/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_17/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_17/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_17/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_18/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_18/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_18/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_18/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_18/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_18/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_18/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_18/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_19/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_19/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_19/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_19/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_19/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_19/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_19/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_19/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_20/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_20/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_20/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_20/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_20/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_20/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_20/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_20/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_21/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_21/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_21/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_21/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_21/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_21/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_21/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_21/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_22/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_22/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_22/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_22/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_22/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_22/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_22/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_22/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_23/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_23/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_23/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_23/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_23/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_23/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_23/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_23/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_24/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_24/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_24/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_24/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_24/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_24/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_24/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_24/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_25/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_25/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_25/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_25/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_25/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_25/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_25/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_25/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_26/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_26/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_26/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_26/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_26/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_26/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_26/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_26/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_27/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_27/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_27/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_27/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_27/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_27/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_27/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_27/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_28/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_28/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_28/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_28/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_28/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_28/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_28/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_28/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 32, 32)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.0.weight with shape (16, 3, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.bias with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.num_batches_tracked with shape ().\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.running_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_layers.0.1.weight with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.0.1.weight with shape (512, 1024).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight dense_layers.1.1.weight with shape (10, 512).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 32, 32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 3, 32, 32),\n",
      "      %conv_layers.0.0.weight : Float(16, 3, 3, 3),\n",
      "      %conv_layers.0.0.bias : Float(16),\n",
      "      %conv_layers.0.1.weight : Float(16),\n",
      "      %conv_layers.0.1.bias : Float(16),\n",
      "      %conv_layers.0.1.running_mean : Float(16),\n",
      "      %conv_layers.0.1.running_var : Float(16),\n",
      "      %conv_layers.0.1.num_batches_tracked : Long(),\n",
      "      %dense_layers.0.1.weight : Float(512, 1024),\n",
      "      %dense_layers.0.1.bias : Float(512),\n",
      "      %dense_layers.1.1.weight : Float(10, 512),\n",
      "      %dense_layers.1.1.bias : Float(10)):\n",
      "  %12 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input_0, %conv_layers.0.0.weight, %conv_layers.0.0.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/modules/conv.py:350:0\n",
      "  %13 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%12, %conv_layers.0.1.weight, %conv_layers.0.1.bias, %conv_layers.0.1.running_mean, %conv_layers.0.1.running_var) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1923:0\n",
      "  %14 : Float(1, 16, 32, 32) = onnx::Relu(%13) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1063:0\n",
      "  %15 : Float(1, 16, 8, 8) = onnx::MaxPool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%14) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:539:0\n",
      "  %16 : Tensor = onnx::Constant[value=   -1  1024 [ CPULongType{2} ]]()\n",
      "  %17 : Float(1, 1024) = onnx::Reshape(%15, %16) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %18 : Float(1, 512) = onnx::Gemm[alpha=1., beta=1., transB=1](%17, %dense_layers.0.1.weight, %dense_layers.0.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  %19 : Float(1, 512) = onnx::Relu(%18) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:936:0\n",
      "  %output_0 : Float(1, 10) = onnx::Gemm[alpha=1., beta=1., transB=1](%19, %dense_layers.1.1.weight, %dense_layers.1.1.bias) # /home/sungmin/Documents/dlTestGen/dlenv/lib/python3.6/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_29/BiasAdd:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: 13\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'momentum': 0.8999999761581421, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 12).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name conv_layers.0.1.running_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name conv_layers.0.1.running_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"13_29/cond/Merge:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 14\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 13).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"14_29/Relu:0\", shape=(?, 16, 32, 32), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 15\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [4, 4], 'pads': [0, 0, 0, 0], 'strides': [4, 4], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 14).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"15_29/MaxPool:0\", shape=(?, 16, 8, 8), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 16\n",
      "DEBUG:onnx2keras:node_params: {'value': array([  -1, 1024]), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  -1 1024]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 15).\n",
      "DEBUG:onnx2keras:Check input 1 (name 16).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:reshape:The first argument is Keras/tf layer. Apply keras.Reshape.\n",
      "DEBUG:onnx2keras:reshape:Target shape :\n",
      "DEBUG:onnx2keras:reshape:[1024]\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17_29/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.0.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.0.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 1024, output units 512.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18_29/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19_29/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:Check input 1 (name dense_layers.1.1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name dense_layers.1.1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 512, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0_29/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for seed_val in range(30):\n",
    "    # plant seed\n",
    "    np.random.seed(seed_val)\n",
    "    \n",
    "    # reset network\n",
    "    org_net.load_state_dict(torch.load(idlm_path))\n",
    "    \n",
    "    # inject faults (over all layers)\n",
    "    org_net.apply(inject_faults)\n",
    "\n",
    "    # save network\n",
    "    input_var = torch.randn(1, 3, 32, 32)\n",
    "    k_model = pytorch2keras.pytorch_to_keras(org_net, input_var, [(3, 32, 32)], verbose=True)\n",
    "    k_model.save('./faulty_models/cifar10_allLayers_seed%d.h5' % seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_mdl_path = \"data/models/fmnist_simple.h5\"\n",
    "#gtsrb_mdl_path = \"data/models/GTSRB/gtsrb.model.0.wh.0.h5\"\n",
    "gtsrb_mdl_path = \"data/models/GTSRB/simple/gtsrb.model.t0.wh.0.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_0 (InputLayer)         (None, 1, 784)            0         \n",
      "_________________________________________________________________\n",
      "5 (Dense)                    (None, 1, 100)            78500     \n",
      "_________________________________________________________________\n",
      "6 (Activation)               (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "output_0 (Dense)             (None, 1, 10)             1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ec6aede1cc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm_mdl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "_mdl = load_model(fm_mdl_path, compile = False)\n",
    "_mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable '5_73/kernel:0' shape=(784, 100) dtype=float32>,\n",
       " <tf.Variable '5_73/bias:0' shape=(100,) dtype=float32>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mdl.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed0.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed1.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed2.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed3.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed4.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed5.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed6.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed7.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed8.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed9.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed10.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed11.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed12.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed13.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed14.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed15.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed16.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed17.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed18.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed19.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed20.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed21.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed22.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed23.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed24.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed25.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed26.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed27.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed28.h5\n",
      "Save to data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed29.h5\n"
     ]
    }
   ],
   "source": [
    "### for keras model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "path_to_keras_model = gtsrb_mdl_path #fm_mdl_path\n",
    "#dirname = \"data/models/faulty_models/fm/all_layers\"\n",
    "dirname = \"data/models/faulty_models/GTSRB/all_layers/simple\"\n",
    "os.makedirs(dirname, exist_ok = True)\n",
    "\n",
    "mdl_key = os.path.basename(path_to_keras_model)[:-3]\n",
    "\n",
    "for seed_val in range(30):\n",
    "    mdl = load_model(path_to_keras_model, compile = False)\n",
    "    # plant seed\n",
    "    np.random.seed(seed_val)\n",
    "    \n",
    "    # reset network\n",
    "    #org_net.load_state_dict(torch.load(idlm_path))\n",
    "    \n",
    "    # inject faults (over all layers)\n",
    "    #org_net.apply(inject_faults)\n",
    "    \n",
    "    for layer in mdl.layers:\n",
    "        inject_faults_for_keras_mdl(layer)\n",
    "        \n",
    "    # save network\n",
    "    #input_var = torch.randn(1, 3, 32, 32)\n",
    "    #k_model = pytorch2keras.pytorch_to_keras(org_net, input_var, [(3, 32, 32)], verbose=True)\n",
    "    #k_model.save('./faulty_models/cifar10_allLayers_seed%d.h5' % seed_val)\n",
    "    destfile = os.path.join(dirname, \"{}_seed{}.h5\".format(mdl_key, seed_val))\n",
    "    print (\"Save to {}\".format(destfile))\n",
    "    mdl.save(destfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 0.04924744897959184\n",
      "layer 3 0.056\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import re \n",
    "\n",
    "targeting_clname_pattns = ['Dense*', 'Conv*'] #if not target_all else None\n",
    "is_target = lambda clname,targets: (targets is None) or any([bool(re.match(t,clname)) for t in targets])\n",
    "    \n",
    "seed = 10\n",
    "mdl = load_model(fm_mdl_path, compile = False)\n",
    "#mdl = load_model(gtsrb_mdl_path, compile = False)\n",
    "mdl2 = load_model(\"data/models/faulty_models/fm/all_layers/fmnist_simple_seed{}.h5\".format(seed), compile = False)\n",
    "#mdl2 = load_model(\"data/models/faulty_models/GTSRB/all_layers/gtsrb.model.0.wh.0_seed{}.h5\".format(seed), compile = False)\n",
    "\n",
    "num = len(mdl.layers)\n",
    "for i in range(num):\n",
    "    class_name = type(mdl.layers[i]).__name__\n",
    "    if is_target(class_name, targeting_clname_pattns):\n",
    "        w, _ = mdl.layers[i].get_weights()\n",
    "        new_w, _ = mdl2.layers[i].get_weights()\n",
    "        \n",
    "        num_diff = len(np.where(new_w.flatten() != w.flatten())[0])\n",
    "        total_num = len(w.flatten())\n",
    "        print (\"layer\", i, num_diff/total_num)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_0 (InputLayer)         (None, 1, 784)            0         \n",
      "_________________________________________________________________\n",
      "5 (Dense)                    (None, 1, 100)            78500     \n",
      "_________________________________________________________________\n",
      "6 (Activation)               (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "output_0 (Dense)             (None, 1, 10)             1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0, ..., 783, 783, 783]),\n",
       " array([ 8, 20, 52, ..., 66, 68, 92]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(w - new_w != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.47774778,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.0920061 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.10139924,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.06765749,  0.        , -0.36194058,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.4815676 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.21602203,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -1.79320471,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.20871532,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.85648543,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.6170313 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.45489824,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -2.33628765,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -1.12169091,  0.        ,  0.        ,  1.94311499,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.2600761 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.05073652, -1.79068606],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -1.27517825,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.38766071,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.07779622,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -1.56097736,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -2.07363358,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -1.5648006 , -0.98749168,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.56983598,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.71453302,  0.73329525,  0.        ,\n",
       "         0.        , -1.61961127,  0.        ,  0.        , -0.914626  ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -1.70337337,  0.19351369,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.10074453,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -1.05061692,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.93122727,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.10210893,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -1.24031425,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -4.01703928,  0.        ,  0.        ,  0.        ,  0.7912195 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.69808517,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -1.02284081,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.4106616 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -1.35472173,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -3.41663959,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.39490054,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -1.20546992,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.28496364,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -3.19312222,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.57697863,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -1.69023291,  0.        , -1.34869521,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -1.3147341 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.21649657,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.64792539,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -2.00864126,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.16332517,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.03166525,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onow_np - new_weights_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gts(idx_to_tls, init_mdl, aft_mdl):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    gts = {}\n",
    "    for idx_to_tl in idx_to_tls: \n",
    "        init_weight = init_mdl.layers[idx_to_tl].get_weights()[0]\n",
    "        aft_weight = aft_mdl.layers[idx_to_tl].get_weights()[0]\n",
    "        \n",
    "        ret = np.where(init_weight != aft_weight)\n",
    "        ret_indices = list(zip(*ret))\n",
    "        gts[idx_to_tl] = ret_indices\n",
    "    \n",
    "    return gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_localise import get_target_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "c10_target_layes = get_target_weights(None, c10_mdl_path, indices_to_target = None, target_all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_target_layes = get_target_weights(None, fm_mdl_path, indices_to_target = None, target_all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsrb_target_layes = get_target_weights(None, gtsrb_mdl_path, indices_to_target = None, target_all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_mdl_path_fault_file_fm = \"data/models/faulty_models/fm/all_layers/fmnist_simple_seed{}.h5\"\n",
    "c10_mdl_path_fault_file_fm = \"data/models/faulty_models/c10/cifar10/cifar10_simple_seed{}.h5\"\n",
    "#gtsrb_mdl_path_fault_file_fm = \"data/models/faulty_models/GTSRB/all_layers/gtsrb.model.0.wh.0_seed{}.h5\"\n",
    "gtsrb_mdl_path_fault_file_fm = \"data/models/faulty_models/GTSRB/all_layers/simple/gtsrb.model.t0.wh.0_seed{}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c10_mdl_path = \"data/models/cifar_simple_90p.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_indices_to_tls = list(fm_target_layes.keys())\n",
    "c10_indices_to_tls = list(c10_target_layes.keys())\n",
    "gtsrb_indices_to_tls = list(gtsrb_target_layes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fm_mdl = load_model(fm_mdl_path, compile = False)\n",
    "target_c10_mdl = load_model(c10_mdl_path, compile = False)\n",
    "target_gtsrb_mdl = load_model(gtsrb_mdl_path, compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which = 'fashion_mnist'\n",
    "#which = 'cifar10'\n",
    "which = 'GTSRB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:57<00:00, 17.91s/it]\n"
     ]
    }
   ],
   "source": [
    "if which == 'fashion_mnist':\n",
    "    target_mdl = target_fm_mdl\n",
    "    target_tl_indices = fm_indices_to_tls\n",
    "elif which == 'cifar10':\n",
    "    target_mdl = target_c10_mdl\n",
    "    target_tl_indices = c10_indices_to_tls\n",
    "else:\n",
    "    target_mdl = target_gtsrb_mdl\n",
    "    target_tl_indices = gtsrb_indices_to_tls\n",
    "    \n",
    "gts_dir = os.path.join(\"data/gts/rq1/simple/{}\".format(which))\n",
    "os.makedirs(gts_dir, exist_ok = True)\n",
    "\n",
    "for seed in tqdm.tqdm(range(30)):\n",
    "    if which == 'fashion_mnist':\n",
    "        mdl = load_model(fm_mdl_path_fault_file_fm.format(seed), compile = False)\n",
    "    elif which == 'cifar10':\n",
    "        mdl = load_model(c10_mdl_path_fault_file_fm.format(seed), compile = False)\n",
    "    else:\n",
    "        mdl = load_model(gtsrb_mdl_path_fault_file_fm.format(seed), compile = False)\n",
    "        \n",
    "    gts = get_gts(target_tl_indices, target_mdl, mdl)\n",
    "    gts_file = os.path.join(gts_dir, \"rq1.seed{}.gts.pkl\".format(seed))\n",
    "    \n",
    "    #df = pd.DataFrame(gts)\n",
    "    #df.to_pickle(gts_file)\n",
    "    with open(gts_file, 'wb') as f:\n",
    "        pickle.dump(gts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc(ranks, gts):\n",
    "    from sklearn.metrics import auc,roc_curve \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    scaler = MinMaxScaler()\t\n",
    "\n",
    "    uniq_ranks = sorted(list(set(ranks.reshape(-1,))))\n",
    "\n",
    "    ranks_of_gts = ranks[gts]\n",
    "    num_gts = len(ranks_of_gts)\n",
    "\n",
    "    recall_per_ranks = []\n",
    "    for i,uniq_rank in enumerate(uniq_ranks):\n",
    "        cnt_loc = np.sum(ranks_of_gts <= uniq_rank)\n",
    "        recall_per_ranks.append(cnt_loc/num_gts)\n",
    "\n",
    "    xs = [int(r) for r in uniq_ranks]\n",
    "    auc_score = auc(xs, recall_per_ranks)\n",
    "    \n",
    "    return auc_score, list(zip(xs, recall_per_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_file = \"results/rq1/all_layers/simple_fm/loc.all_cost.loc.0.1.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38260412,  0.34203607,  0.15109418, ...,  0.07083493,\n",
       "        -0.090018  ,  0.37902394],\n",
       "       [ 0.08018471,  0.1468847 , -0.3148051 , ...,  0.26775002,\n",
       "         0.13219263, -0.44124016],\n",
       "       [ 0.99782073,  0.3959316 , -0.39116275, ...,  0.22424038,\n",
       "         0.43500382, -0.5753424 ],\n",
       "       ...,\n",
       "       [ 0.13608551,  0.04205639,  0.02728352, ...,  0.05676162,\n",
       "         0.02562602, -0.6894089 ],\n",
       "       [-0.33116543,  0.21478154,  0.471417  , ...,  0.10401588,\n",
       "         0.67420214,  0.04792061],\n",
       "       [ 0.20624009,  0.24127744,  0.44048694, ...,  0.6069383 ,\n",
       "         0.38830775, -0.80433786]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_target_layes[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc_file, 'rb') as f:\n",
    "    locs = pickle.load(f)\n",
    "new_locs = []\n",
    "for loc in locs:\n",
    "    indices, cost = loc\n",
    "    idx_to_l, local_idx = indices\n",
    "    local_idx = np.unravel_index(local_idx, fm_target_layes[idx_to_l][0].shape)\n",
    "    new_locs.append([[idx_to_l, local_idx], cost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, (0, 0)], array([3.13106738e-03, 2.67206152e-09])],\n",
       " [[1, (0, 1)], array([3.24256904e-02, 7.22222895e-09])],\n",
       " [[1, (0, 2)], array([0.00000000e+00, 9.73189086e-10])],\n",
       " [[1, (0, 3)], array([4.75183800e-02, 6.29985586e-10])],\n",
       " [[1, (0, 4)], array([0.00000000e+00, 4.93253876e-10])],\n",
       " [[1, (0, 5)], array([0.00000000e+00, 4.24946496e-09])],\n",
       " [[1, (0, 6)], array([5.80421556e-03, 2.51327012e-09])],\n",
       " [[1, (0, 7)], array([8.38170946e-03, 5.17119446e-09])],\n",
       " [[1, (0, 8)], array([0.00000000e+00, 2.82623413e-09])],\n",
       " [[1, (0, 9)], array([6.73324168e-02, 5.27330541e-09])],\n",
       " [[1, (0, 10)], array([0.00000000e+00, 6.37885461e-10])],\n",
       " [[1, (0, 11)], array([0.00000000e+00, 3.20596464e-10])],\n",
       " [[1, (0, 12)], array([4.72060814e-02, 6.13385501e-09])],\n",
       " [[1, (0, 13)], array([7.72617874e-04, 2.18397533e-09])],\n",
       " [[1, (0, 14)], array([0.0000000e+00, 2.1307218e-10])],\n",
       " [[1, (0, 15)], array([0.0000000e+00, 6.5554311e-11])],\n",
       " [[1, (0, 16)], array([6.58652335e-02, 1.85680249e-09])],\n",
       " [[1, (0, 17)], array([2.48858909e-04, 3.43613923e-09])],\n",
       " [[1, (0, 18)], array([0.00000000e+00, 1.41355913e-09])],\n",
       " [[1, (0, 19)], array([1.40547957e-02, 2.92376183e-09])],\n",
       " [[1, (0, 20)], array([2.59705028e-03, 2.30011073e-10])],\n",
       " [[1, (0, 21)], array([0.00000000e+00, 2.40682601e-09])],\n",
       " [[1, (0, 22)], array([0.00000000e+00, 6.61316209e-11])],\n",
       " [[1, (0, 23)], array([1.72459974e-03, 3.55455636e-09])],\n",
       " [[1, (0, 24)], array([3.38224843e-02, 8.93271364e-09])],\n",
       " [[1, (0, 25)], array([6.73572707e-04, 4.42583784e-09])],\n",
       " [[1, (0, 26)], array([0.00000000e+00, 4.47051763e-10])],\n",
       " [[1, (0, 27)], array([8.36018380e-03, 1.62685554e-09])],\n",
       " [[1, (0, 28)], array([0.00000000e+00, 8.40219712e-11])],\n",
       " [[1, (0, 29)], array([3.07599865e-02, 2.99204518e-09])],\n",
       " [[1, (0, 30)], array([0.00000000e+00, 2.04747765e-10])],\n",
       " [[1, (0, 31)], array([8.22427042e-04, 1.97526264e-09])],\n",
       " [[1, (0, 32)], array([0.00000000e+00, 9.90295886e-11])],\n",
       " [[1, (0, 33)], array([0.00000000e+00, 8.93999869e-11])],\n",
       " [[1, (0, 34)], array([0.00000000e+00, 4.07917448e-11])],\n",
       " [[1, (0, 35)], array([0.00000000e+00, 9.06137851e-11])],\n",
       " [[1, (0, 36)], array([0.0000000e+00, 9.7066389e-09])],\n",
       " [[1, (0, 37)], array([0.00000000e+00, 2.40622993e-09])],\n",
       " [[1, (0, 38)], array([0.00000000e+00, 4.35959091e-11])],\n",
       " [[1, (0, 39)], array([0.00000000e+00, 1.18004203e-10])],\n",
       " [[1, (0, 40)], array([0.00000000e+00, 9.90646612e-10])],\n",
       " [[1, (0, 41)], array([6.59084022e-02, 3.52677073e-09])],\n",
       " [[1, (0, 42)], array([0.00000000e+00, 2.43965004e-10])],\n",
       " [[1, (0, 43)], array([2.89962944e-02, 3.54557585e-09])],\n",
       " [[1, (0, 44)], array([1.20930457e-02, 9.82218778e-09])],\n",
       " [[1, (0, 45)], array([5.42902038e-04, 1.44548169e-08])],\n",
       " [[1, (0, 46)], array([2.39661051e-04, 3.63298697e-09])],\n",
       " [[1, (0, 47)], array([2.24349387e-02, 9.28906558e-09])],\n",
       " [[1, (0, 48)], array([7.05189910e-03, 5.30353154e-09])],\n",
       " [[1, (0, 49)], array([0.00000000e+00, 7.29990566e-10])],\n",
       " [[1, (0, 50)], array([2.30755832e-04, 2.68698451e-09])],\n",
       " [[1, (0, 51)], array([2.28599226e-03, 2.85536003e-09])],\n",
       " [[1, (0, 52)], array([1.97583903e-02, 9.33038707e-10])],\n",
       " [[1, (0, 53)], array([1.58683006e-02, 1.96273843e-09])],\n",
       " [[1, (0, 54)], array([6.22577704e-02, 5.71233062e-11])],\n",
       " [[1, (0, 55)], array([0.00000000e+00, 1.14337116e-08])],\n",
       " [[1, (0, 56)], array([7.09143877e-02, 1.97303938e-10])],\n",
       " [[1, (0, 57)], array([0.00000000e+00, 6.16023575e-11])],\n",
       " [[1, (0, 58)], array([1.34380208e-03, 5.80527232e-10])],\n",
       " [[1, (0, 59)], array([5.71403070e-04, 4.01908007e-10])],\n",
       " [[1, (0, 60)], array([0.00000000e+00, 1.17049334e-10])],\n",
       " [[1, (0, 61)], array([0.00000000e+00, 3.34027616e-11])],\n",
       " [[1, (0, 62)], array([0.00000000e+00, 2.18194386e-09])],\n",
       " [[1, (0, 63)], array([4.75419831e-04, 2.53376180e-09])],\n",
       " [[1, (0, 64)], array([4.19755746e-03, 2.13394688e-09])],\n",
       " [[1, (0, 65)], array([0.00000000e+00, 1.83511752e-09])],\n",
       " [[1, (0, 66)], array([4.55529802e-03, 1.48706891e-09])],\n",
       " [[1, (0, 67)], array([0.00000000e+00, 1.00953329e-08])],\n",
       " [[1, (0, 68)], array([3.46492045e-03, 3.55660485e-09])],\n",
       " [[1, (0, 69)], array([2.09889989e-02, 8.06252010e-09])],\n",
       " [[1, (0, 70)], array([0.00000000e+00, 6.99913685e-10])],\n",
       " [[1, (0, 71)], array([3.80765763e-04, 6.88630976e-09])],\n",
       " [[1, (0, 72)], array([0.00000000e+00, 9.42728623e-11])],\n",
       " [[1, (0, 73)], array([3.61019978e-04, 8.75332578e-09])],\n",
       " [[1, (0, 74)], array([0.00000000e+00, 7.73488896e-09])],\n",
       " [[1, (0, 75)], array([0.00000000e+00, 9.48119799e-11])],\n",
       " [[1, (0, 76)], array([9.43856537e-02, 7.28275987e-09])],\n",
       " [[1, (0, 77)], array([0.00000000e+00, 7.40352781e-11])],\n",
       " [[1, (0, 78)], array([0.00000000e+00, 2.64529008e-10])],\n",
       " [[1, (0, 79)], array([0.00000000e+00, 2.53869266e-10])],\n",
       " [[1, (0, 80)], array([0.00000000e+00, 2.49934914e-10])],\n",
       " [[1, (0, 81)], array([3.27871814e-02, 5.92284323e-09])],\n",
       " [[1, (0, 82)], array([4.55660075e-02, 7.05340974e-09])],\n",
       " [[1, (0, 83)], array([2.15398832e-04, 2.78005137e-09])],\n",
       " [[1, (0, 84)], array([1.23091489e-02, 9.61868681e-09])],\n",
       " [[1, (0, 85)], array([0.00000000e+00, 1.68541257e-10])],\n",
       " [[1, (0, 86)], array([1.02038801e-04, 9.62198799e-09])],\n",
       " [[1, (0, 87)], array([0.00000000e+00, 2.55051228e-14])],\n",
       " [[1, (0, 88)], array([9.31292474e-02, 1.33766410e-09])],\n",
       " [[1, (0, 89)], array([3.01800128e-02, 4.93888059e-09])],\n",
       " [[1, (0, 90)], array([1.14880666e-01, 1.58307831e-09])],\n",
       " [[1, (0, 91)], array([0.00000000e+00, 4.82562156e-09])],\n",
       " [[1, (0, 92)], array([9.41010378e-03, 8.54263312e-10])],\n",
       " [[1, (0, 93)], array([6.58338831e-04, 1.03534860e-09])],\n",
       " [[1, (0, 94)], array([0.00000000e+00, 8.32660976e-10])],\n",
       " [[1, (0, 95)], array([8.06273427e-03, 3.39701368e-09])],\n",
       " [[1, (0, 96)], array([0.00000000e+00, 1.76846781e-10])],\n",
       " [[1, (0, 97)], array([8.88773985e-03, 5.18990011e-10])],\n",
       " [[1, (0, 98)], array([0.00000000e+00, 1.03137506e-09])],\n",
       " [[1, (0, 99)], array([2.17570006e-04, 3.06406662e-09])],\n",
       " [[1, (1, 0)], array([3.54846078e-03, 1.18330523e-09])],\n",
       " [[1, (1, 1)], array([1.56942934e-01, 6.49962407e-09])],\n",
       " [[1, (1, 2)], array([2.33413875e-02, 4.24561561e-09])],\n",
       " [[1, (1, 3)], array([5.64210378e-02, 2.65942819e-09])],\n",
       " [[1, (1, 4)], array([0.00000000e+00, 2.19074146e-09])],\n",
       " [[1, (1, 5)], array([1.63963921e-02, 4.42902131e-09])],\n",
       " [[1, (1, 6)], array([9.38110799e-03, 5.07230955e-09])],\n",
       " [[1, (1, 7)], array([1.08104885e-01, 1.26500432e-08])],\n",
       " [[1, (1, 8)], array([3.43924053e-02, 6.91279186e-09])],\n",
       " [[1, (1, 9)], array([3.01892608e-01, 1.48311805e-09])],\n",
       " [[1, (1, 10)], array([9.09585797e-05, 3.66393709e-09])],\n",
       " [[1, (1, 11)], array([3.49349640e-02, 6.17251991e-09])],\n",
       " [[1, (1, 12)], array([7.62561783e-02, 1.49865224e-08])],\n",
       " [[1, (1, 13)], array([3.28249088e-03, 4.48667181e-10])],\n",
       " [[1, (1, 14)], array([8.27003121e-02, 5.94643457e-09])],\n",
       " [[1, (1, 15)], array([6.33451762e-03, 8.38242732e-11])],\n",
       " [[1, (1, 16)], array([6.94128200e-02, 1.34612551e-09])],\n",
       " [[1, (1, 17)], array([2.03545559e-02, 7.14356237e-09])],\n",
       " [[1, (1, 18)], array([0.00000000e+00, 2.15735213e-09])],\n",
       " [[1, (1, 19)], array([7.48543516e-02, 4.37279863e-09])],\n",
       " [[1, (1, 20)], array([1.56073989e-02, 1.06658966e-08])],\n",
       " [[1, (1, 21)], array([1.45766482e-01, 1.11744749e-08])],\n",
       " [[1, (1, 22)], array([9.78918076e-02, 1.29068970e-09])],\n",
       " [[1, (1, 23)], array([1.82803674e-03, 5.18910513e-09])],\n",
       " [[1, (1, 24)], array([3.20339389e-02, 1.35903704e-08])],\n",
       " [[1, (1, 25)], array([3.98798008e-03, 6.65037546e-09])],\n",
       " [[1, (1, 26)], array([7.29882903e-03, 2.04972041e-09])],\n",
       " [[1, (1, 27)], array([1.36898989e-02, 1.55996073e-09])],\n",
       " [[1, (1, 28)], array([0.00000000e+00, 1.64685425e-09])],\n",
       " [[1, (1, 29)], array([1.31443977e-01, 1.71470714e-09])],\n",
       " [[1, (1, 30)], array([3.24624553e-02, 6.15556339e-11])],\n",
       " [[1, (1, 31)], array([7.19832405e-02, 2.37773849e-09])],\n",
       " [[1, (1, 32)], array([0.00000000e+00, 5.79011667e-10])],\n",
       " [[1, (1, 33)], array([0.00000000e+00, 1.94700479e-09])],\n",
       " [[1, (1, 34)], array([1.18191019e-02, 1.67661597e-10])],\n",
       " [[1, (1, 35)], array([2.10522805e-04, 3.43564437e-09])],\n",
       " [[1, (1, 36)], array([1.29765540e-01, 1.57075774e-08])],\n",
       " [[1, (1, 37)], array([1.20429024e-01, 1.04439940e-08])],\n",
       " [[1, (1, 38)], array([0.00000000e+00, 3.22580454e-09])],\n",
       " [[1, (1, 39)], array([0.0000000e+00, 9.3820843e-10])],\n",
       " [[1, (1, 40)], array([0.00000000e+00, 5.19507074e-09])],\n",
       " [[1, (1, 41)], array([5.99420145e-02, 3.38027645e-08])],\n",
       " [[1, (1, 42)], array([1.45639703e-01, 1.64368688e-09])],\n",
       " [[1, (1, 43)], array([4.46868613e-02, 2.78688984e-09])],\n",
       " [[1, (1, 44)], array([6.65137451e-03, 1.83179877e-08])],\n",
       " [[1, (1, 45)], array([8.32152274e-03, 2.16229122e-08])],\n",
       " [[1, (1, 46)], array([3.98232462e-03, 2.06582083e-09])],\n",
       " [[1, (1, 47)], array([3.82914692e-02, 3.12648355e-09])],\n",
       " [[1, (1, 48)], array([1.15887493e-01, 2.73548627e-09])],\n",
       " [[1, (1, 49)], array([4.59593674e-03, 9.62176777e-11])],\n",
       " [[1, (1, 50)], array([2.33769650e-03, 1.87728304e-09])],\n",
       " [[1, (1, 51)], array([6.83785463e-03, 1.50023059e-08])],\n",
       " [[1, (1, 52)], array([3.36031206e-02, 2.67608931e-09])],\n",
       " [[1, (1, 53)], array([2.88214628e-03, 2.08799887e-09])],\n",
       " [[1, (1, 54)], array([4.68746796e-02, 6.25534097e-10])],\n",
       " [[1, (1, 55)], array([8.64015613e-03, 3.80267230e-08])],\n",
       " [[1, (1, 56)], array([5.15707247e-02, 4.96588986e-10])],\n",
       " [[1, (1, 57)], array([0.00000000e+00, 8.52917995e-11])],\n",
       " [[1, (1, 58)], array([3.81567962e-02, 8.71922067e-10])],\n",
       " [[1, (1, 59)], array([3.64517653e-03, 1.34192780e-09])],\n",
       " [[1, (1, 60)], array([0.00000000e+00, 2.78227908e-09])],\n",
       " [[1, (1, 61)], array([0.00000000e+00, 9.11837628e-11])],\n",
       " [[1, (1, 62)], array([4.97082621e-02, 2.62831032e-09])],\n",
       " [[1, (1, 63)], array([1.88760608e-02, 1.19860793e-09])],\n",
       " [[1, (1, 64)], array([2.16092512e-01, 5.36964644e-10])],\n",
       " [[1, (1, 65)], array([0.00000000e+00, 3.14123814e-09])],\n",
       " [[1, (1, 66)], array([3.22595127e-02, 5.81292116e-09])],\n",
       " [[1, (1, 67)], array([1.83052540e-01, 2.10343694e-08])],\n",
       " [[1, (1, 68)], array([1.23448344e-02, 2.77712254e-08])],\n",
       " [[1, (1, 69)], array([9.57213938e-02, 4.46618411e-09])],\n",
       " [[1, (1, 70)], array([0.00000000e+00, 1.20984714e-09])],\n",
       " [[1, (1, 71)], array([3.88894230e-04, 1.49826604e-10])],\n",
       " [[1, (1, 72)], array([1.04402262e-03, 4.07115967e-09])],\n",
       " [[1, (1, 73)], array([5.14543289e-03, 1.29624932e-08])],\n",
       " [[1, (1, 74)], array([1.62079893e-02, 5.05513034e-09])],\n",
       " [[1, (1, 75)], array([2.84233131e-04, 1.17119686e-09])],\n",
       " [[1, (1, 76)], array([1.44350410e-01, 4.63329514e-09])],\n",
       " [[1, (1, 77)], array([0.00000000e+00, 1.84171192e-10])],\n",
       " [[1, (1, 78)], array([8.66695889e-04, 3.22146939e-09])],\n",
       " [[1, (1, 79)], array([0.00000000e+00, 4.89683265e-10])],\n",
       " [[1, (1, 80)], array([0.00000000e+00, 1.19307007e-09])],\n",
       " [[1, (1, 81)], array([6.39013201e-02, 4.31593974e-09])],\n",
       " [[1, (1, 82)], array([5.78485876e-02, 2.14002755e-08])],\n",
       " [[1, (1, 83)], array([9.69779561e-04, 5.80329660e-10])],\n",
       " [[1, (1, 84)], array([1.96576174e-02, 1.99254740e-08])],\n",
       " [[1, (1, 85)], array([8.62746849e-04, 3.52575220e-10])],\n",
       " [[1, (1, 86)], array([6.02684803e-02, 2.47732392e-08])],\n",
       " [[1, (1, 87)], array([0.00000000e+00, 1.65669636e-14])],\n",
       " [[1, (1, 88)], array([1.17822267e-01, 8.24424773e-10])],\n",
       " [[1, (1, 89)], array([5.88931106e-02, 7.89028308e-09])],\n",
       " [[1, (1, 90)], array([1.3067539e-01, 4.2029152e-09])],\n",
       " [[1, (1, 91)], array([1.77992086e-04, 1.04280310e-09])],\n",
       " [[1, (1, 92)], array([1.38080930e-02, 1.68524733e-09])],\n",
       " [[1, (1, 93)], array([2.45338585e-03, 5.93592241e-09])],\n",
       " [[1, (1, 94)], array([0.00000000e+00, 2.70261533e-09])],\n",
       " [[1, (1, 95)], array([4.48618084e-02, 1.03685987e-08])],\n",
       " [[1, (1, 96)], array([2.91691050e-02, 4.77217689e-10])],\n",
       " [[1, (1, 97)], array([1.49967577e-02, 4.07682302e-09])],\n",
       " [[1, (1, 98)], array([4.92718909e-03, 3.33709420e-09])],\n",
       " [[1, (1, 99)], array([1.61911100e-02, 7.65472234e-09])],\n",
       " [[1, (2, 0)], array([1.69482350e-01, 9.58597872e-08])],\n",
       " [[1, (2, 1)], array([6.58161759e-01, 1.12530999e-07])],\n",
       " [[1, (2, 2)], array([1.65141761e-01, 3.32106809e-08])],\n",
       " [[1, (2, 3)], array([6.09524608e-01, 5.10318677e-08])],\n",
       " [[1, (2, 4)], array([3.41793901e-04, 4.60123550e-08])],\n",
       " [[1, (2, 5)], array([1.19552076e-01, 1.11589560e-07])],\n",
       " [[1, (2, 6)], array([1.54441416e-01, 3.74886670e-08])],\n",
       " [[1, (2, 7)], array([6.24329805e-01, 2.65739168e-08])],\n",
       " [[1, (2, 8)], array([1.17289692e-01, 3.35188922e-08])],\n",
       " [[1, (2, 9)], array([1.83094692e+00, 5.07916101e-08])],\n",
       " [[1, (2, 10)], array([7.16339797e-02, 3.70362278e-08])],\n",
       " [[1, (2, 11)], array([1.69046432e-01, 4.74673746e-08])],\n",
       " [[1, (2, 12)], array([2.02380612e-01, 3.99054379e-08])],\n",
       " [[1, (2, 13)], array([4.21460047e-02, 6.11327378e-09])],\n",
       " [[1, (2, 14)], array([4.40987140e-01, 3.77659682e-08])],\n",
       " [[1, (2, 15)], array([1.72122091e-01, 2.19784107e-10])],\n",
       " [[1, (2, 16)], array([8.52755725e-01, 9.71999150e-10])],\n",
       " [[1, (2, 17)], array([9.02414620e-02, 2.23380472e-08])],\n",
       " [[1, (2, 18)], array([0.00000000e+00, 5.84668576e-09])],\n",
       " [[1, (2, 19)], array([2.30385289e-01, 1.02618048e-07])],\n",
       " [[1, (2, 20)], array([2.74701625e-01, 5.71279681e-08])],\n",
       " [[1, (2, 21)], array([7.35624909e-01, 7.19485629e-08])],\n",
       " [[1, (2, 22)], array([4.65965003e-01, 6.19803818e-08])],\n",
       " [[1, (2, 23)], array([3.79659757e-02, 1.50028622e-08])],\n",
       " [[1, (2, 24)], array([1.52170509e-01, 8.04858090e-08])],\n",
       " [[1, (2, 25)], array([2.07209326e-02, 4.80353650e-08])],\n",
       " [[1, (2, 26)], array([5.27052656e-02, 1.45382118e-09])],\n",
       " [[1, (2, 27)], array([1.06731892e-01, 3.12720114e-08])],\n",
       " [[1, (2, 28)], array([5.73507836e-03, 1.16852088e-08])],\n",
       " [[1, (2, 29)], array([8.15244794e-01, 6.41509850e-08])],\n",
       " [[1, (2, 30)], array([1.56141967e-01, 9.36133806e-09])],\n",
       " [[1, (2, 31)], array([2.34240353e-01, 5.15048024e-09])],\n",
       " [[1, (2, 32)], array([7.40238931e-04, 5.07441312e-08])],\n",
       " [[1, (2, 33)], array([0.00000000e+00, 3.66303346e-09])],\n",
       " [[1, (2, 34)], array([1.47526443e-01, 8.26699322e-09])],\n",
       " [[1, (2, 35)], array([6.83669969e-02, 3.32289050e-09])],\n",
       " [[1, (2, 36)], array([6.91760659e-01, 1.48692703e-07])],\n",
       " [[1, (2, 37)], array([5.66905081e-01, 6.08661959e-08])],\n",
       " [[1, (2, 38)], array([0.00000000e+00, 1.21083532e-08])],\n",
       " [[1, (2, 39)], array([0.00000000e+00, 3.57181532e-09])],\n",
       " [[1, (2, 40)], array([1.35931909e-01, 5.29400150e-09])],\n",
       " [[1, (2, 41)], array([5.88649213e-01, 6.99738164e-08])],\n",
       " [[1, (2, 42)], array([7.06014514e-01, 1.75095917e-08])],\n",
       " [[1, (2, 43)], array([1.74213365e-01, 5.90131945e-09])],\n",
       " [[1, (2, 44)], array([1.39903113e-01, 2.84394055e-08])],\n",
       " [[1, (2, 45)], array([3.89404558e-02, 5.93284517e-08])],\n",
       " [[1, (2, 46)], array([1.10064372e-02, 1.54812272e-08])],\n",
       " [[1, (2, 47)], array([3.19775045e-01, 3.19301034e-08])],\n",
       " [[1, (2, 48)], array([6.85920000e-01, 6.82729149e-08])],\n",
       " [[1, (2, 49)], array([2.38084532e-02, 1.05272918e-08])],\n",
       " [[1, (2, 50)], array([9.43308324e-03, 2.83872959e-07])],\n",
       " [[1, (2, 51)], array([7.21859932e-02, 1.22415123e-07])],\n",
       " [[1, (2, 52)], array([9.84020829e-02, 1.37759786e-07])],\n",
       " [[1, (2, 53)], array([4.06058915e-02, 3.70032145e-08])],\n",
       " [[1, (2, 54)], array([4.79522087e-02, 4.27391361e-09])],\n",
       " [[1, (2, 55)], array([2.58239895e-01, 4.38141533e-08])],\n",
       " [[1, (2, 56)], array([1.19873293e-01, 2.32524719e-09])],\n",
       " [[1, (2, 57)], array([1.24204932e-02, 5.48661069e-09])],\n",
       " [[1, (2, 58)], array([3.49396050e-01, 4.15024781e-08])],\n",
       " [[1, (2, 59)], array([2.87231971e-02, 1.85360807e-08])],\n",
       " [[1, (2, 60)], array([0.00000000e+00, 1.91304242e-08])],\n",
       " [[1, (2, 61)], array([0.00000000e+00, 6.72574225e-10])],\n",
       " [[1, (2, 62)], array([2.03006387e-01, 1.13355516e-07])],\n",
       " [[1, (2, 63)], array([1.56470388e-01, 1.14234826e-07])],\n",
       " [[1, (2, 64)], array([1.12890577e+00, 1.30965028e-07])],\n",
       " [[1, (2, 65)], array([1.03108585e-02, 1.92463789e-08])],\n",
       " [[1, (2, 66)], array([7.99456090e-02, 1.22365314e-07])],\n",
       " [[1, (2, 67)], array([7.21108913e-01, 8.30063519e-08])],\n",
       " [[1, (2, 68)], array([6.61093295e-02, 6.07470892e-08])],\n",
       " [[1, (2, 69)], array([1.07160479e-01, 8.18813620e-09])],\n",
       " [[1, (2, 70)], array([0.00000000e+00, 9.15917832e-09])],\n",
       " [[1, (2, 71)], array([4.74142656e-03, 2.15792371e-07])],\n",
       " [[1, (2, 72)], array([2.37903744e-02, 4.80089950e-09])],\n",
       " [[1, (2, 73)], array([4.52614501e-02, 3.49542382e-08])],\n",
       " [[1, (2, 74)], array([9.47218090e-02, 5.57743907e-08])],\n",
       " [[1, (2, 75)], array([7.89972395e-02, 6.77219821e-08])],\n",
       " [[1, (2, 76)], array([8.36684644e-01, 3.43331900e-08])],\n",
       " [[1, (2, 77)], array([2.43941834e-03, 1.61291507e-08])],\n",
       " [[1, (2, 78)], array([2.25925166e-03, 7.68245753e-09])],\n",
       " [[1, (2, 79)], array([0.00000000e+00, 6.59410253e-09])],\n",
       " [[1, (2, 80)], array([0.00000000e+00, 4.90321174e-08])],\n",
       " [[1, (2, 81)], array([2.20122024e-01, 1.61535740e-08])],\n",
       " [[1, (2, 82)], array([5.09465873e-01, 6.42163593e-08])],\n",
       " [[1, (2, 83)], array([3.57790850e-04, 4.37243372e-08])],\n",
       " [[1, (2, 84)], array([1.28194168e-01, 8.53022965e-08])],\n",
       " [[1, (2, 85)], array([1.76881882e-03, 3.53239440e-11])],\n",
       " [[1, (2, 86)], array([2.70934373e-01, 6.89953486e-08])],\n",
       " [[1, (2, 87)], array([0.00000000e+00, 1.75286376e-13])],\n",
       " [[1, (2, 88)], array([8.1084168e-01, 3.7465702e-08])],\n",
       " [[1, (2, 89)], array([2.17972249e-01, 7.61555235e-09])],\n",
       " [[1, (2, 90)], array([5.91921270e-01, 8.34527963e-08])],\n",
       " [[1, (2, 91)], array([2.25621229e-03, 1.42818155e-07])],\n",
       " [[1, (2, 92)], array([2.08964776e-02, 1.54069881e-08])],\n",
       " [[1, (2, 93)], array([1.63233262e-02, 3.90403726e-07])],\n",
       " [[1, (2, 94)], array([0.00000000e+00, 6.68258786e-08])],\n",
       " [[1, (2, 95)], array([3.44489753e-01, 1.67332537e-08])],\n",
       " [[1, (2, 96)], array([6.39785780e-04, 1.37797392e-08])],\n",
       " [[1, (2, 97)], array([1.07975118e-01, 2.15906376e-08])],\n",
       " [[1, (2, 98)], array([4.66212660e-01, 4.40218357e-08])],\n",
       " [[1, (2, 99)], array([5.16756475e-02, 3.96972266e-09])],\n",
       " [[1, (3, 0)], array([6.97657704e-01, 4.99950957e-08])],\n",
       " [[1, (3, 1)], array([2.54966021e-01, 5.17982218e-07])],\n",
       " [[1, (3, 2)], array([5.13559401e-01, 5.31617328e-08])],\n",
       " [[1, (3, 3)], array([2.57958221e+00, 1.56405051e-07])],\n",
       " [[1, (3, 4)], array([7.81264827e-02, 8.35798142e-09])],\n",
       " [[1, (3, 5)], array([1.18038684e-01, 4.60368052e-07])],\n",
       " [[1, (3, 6)], array([6.36848867e-01, 1.15210777e-07])],\n",
       " [[1, (3, 7)], array([3.03296626e-01, 1.79165099e-07])],\n",
       " [[1, (3, 8)], array([7.99942315e-02, 3.12181225e-07])],\n",
       " [[1, (3, 9)], array([5.14380455e+00, 3.27604143e-07])],\n",
       " [[1, (3, 10)], array([1.12154245e-01, 8.03205896e-08])],\n",
       " [[1, (3, 11)], array([2.87179828e-01, 2.29974860e-07])],\n",
       " [[1, (3, 12)], array([6.28736615e-01, 1.40049640e-07])],\n",
       " [[1, (3, 13)], array([1.33404464e-01, 2.85165994e-08])],\n",
       " [[1, (3, 14)], array([5.00510216e-01, 1.77863949e-07])],\n",
       " [[1, (3, 15)], array([8.22593689e-01, 4.10189123e-09])],\n",
       " [[1, (3, 16)], array([3.86655593e+00, 8.00161913e-08])],\n",
       " [[1, (3, 17)], array([1.23502702e-01, 8.27290289e-09])],\n",
       " [[1, (3, 18)], array([0.00000000e+00, 2.53841358e-08])],\n",
       " [[1, (3, 19)], array([3.02686512e-01, 1.96151444e-07])],\n",
       " [[1, (3, 20)], array([1.62569809e+00, 4.62441896e-08])],\n",
       " [[1, (3, 21)], array([2.21446365e-01, 2.27970633e-07])],\n",
       " [[1, (3, 22)], array([4.85891402e-01, 2.57977443e-07])],\n",
       " [[1, (3, 23)], array([2.19922941e-02, 4.49915550e-07])],\n",
       " [[1, (3, 24)], array([5.01623631e-01, 2.85412699e-07])],\n",
       " [[1, (3, 25)], array([1.87631652e-01, 4.31221265e-08])],\n",
       " [[1, (3, 26)], array([7.04937577e-02, 4.36743431e-08])],\n",
       " [[1, (3, 27)], array([1.79278731e-01, 1.04862499e-07])],\n",
       " [[1, (3, 28)], array([6.50205929e-03, 2.75808685e-08])],\n",
       " [[1, (3, 29)], array([1.82614040e+00, 4.58702573e-07])],\n",
       " [[1, (3, 30)], array([1.79149166e-01, 3.33306165e-08])],\n",
       " [[1, (3, 31)], array([3.11624587e-01, 1.39619888e-07])],\n",
       " [[1, (3, 32)], array([6.89280853e-02, 2.26393726e-08])],\n",
       " [[1, (3, 33)], array([0.00000000e+00, 1.41984097e-08])],\n",
       " [[1, (3, 34)], array([4.23187673e-01, 8.33353113e-09])],\n",
       " [[1, (3, 35)], array([7.41606355e-01, 1.14574611e-07])],\n",
       " [[1, (3, 36)], array([9.05741811e-01, 2.80785398e-07])],\n",
       " [[1, (3, 37)], array([2.44843345e-02, 4.48032792e-08])],\n",
       " [[1, (3, 38)], array([1.11860968e-03, 7.38253365e-08])],\n",
       " [[1, (3, 39)], array([0.00000000e+00, 1.49257122e-08])],\n",
       " [[1, (3, 40)], array([6.70407355e-01, 2.80745719e-08])],\n",
       " [[1, (3, 41)], array([2.67585969e+00, 1.33829711e-07])],\n",
       " [[1, (3, 42)], array([1.24489903e+00, 9.11112350e-08])],\n",
       " [[1, (3, 43)], array([6.53096616e-01, 3.49604267e-08])],\n",
       " [[1, (3, 44)], array([8.08915198e-01, 5.59085245e-08])],\n",
       " [[1, (3, 45)], array([1.09316990e-01, 1.56873587e-07])],\n",
       " [[1, (3, 46)], array([4.77429032e-02, 3.48691766e-08])],\n",
       " [[1, (3, 47)], array([7.10775971e-01, 5.73053146e-08])],\n",
       " [[1, (3, 48)], array([2.11753082e+00, 1.43455598e-07])],\n",
       " [[1, (3, 49)], array([5.39241880e-02, 1.28023164e-08])],\n",
       " [[1, (3, 50)], array([1.38725583e-02, 1.60403434e-08])],\n",
       " [[1, (3, 51)], array([2.38697380e-01, 2.93109077e-07])],\n",
       " [[1, (3, 52)], array([2.22704694e-01, 1.96736248e-08])],\n",
       " [[1, (3, 53)], array([7.35831559e-02, 1.87073974e-08])],\n",
       " [[1, (3, 54)], array([1.05345629e-01, 1.14933132e-08])],\n",
       " [[1, (3, 55)], array([9.33497369e-01, 1.99267922e-07])],\n",
       " [[1, (3, 56)], array([7.74476826e-02, 3.33202304e-08])],\n",
       " [[1, (3, 57)], array([8.74840189e-03, 1.70378330e-08])],\n",
       " [[1, (3, 58)], array([1.15547109e+00, 2.40509341e-07])],\n",
       " [[1, (3, 59)], array([9.55876783e-02, 2.09344076e-09])],\n",
       " [[1, (3, 60)], array([0.00000000e+00, 1.07536986e-07])],\n",
       " [[1, (3, 61)], array([0.00000000e+00, 3.04276585e-08])],\n",
       " [[1, (3, 62)], array([2.58965540e+00, 1.09146088e-07])],\n",
       " [[1, (3, 63)], array([6.19801879e-01, 4.68370041e-08])],\n",
       " [[1, (3, 64)], array([1.37213802e+00, 1.14364696e-07])],\n",
       " [[1, (3, 65)], array([3.90944490e-03, 5.66840592e-08])],\n",
       " [[1, (3, 66)], array([2.81730443e-01, 6.66545996e-07])],\n",
       " [[1, (3, 67)], array([4.94851083e-01, 4.86515297e-07])],\n",
       " [[1, (3, 68)], array([4.13226843e-01, 3.49240515e-07])],\n",
       " [[1, (3, 69)], array([9.27297294e-01, 1.82503055e-07])],\n",
       " [[1, (3, 70)], array([0.00000000e+00, 7.15214384e-08])],\n",
       " [[1, (3, 71)], array([2.15390418e-02, 6.41697280e-08])],\n",
       " [[1, (3, 72)], array([5.71110100e-02, 1.46388051e-07])],\n",
       " [[1, (3, 73)], array([1.27169505e-01, 1.01767114e-08])],\n",
       " [[1, (3, 74)], array([2.50332862e-01, 2.53066431e-07])],\n",
       " [[1, (3, 75)], array([8.57958317e-01, 1.32958279e-07])],\n",
       " [[1, (3, 76)], array([3.38073802e+00, 2.16696392e-07])],\n",
       " [[1, (3, 77)], array([1.15307663e-02, 7.18938522e-09])],\n",
       " [[1, (3, 78)], array([9.57162082e-02, 1.88400644e-08])],\n",
       " [[1, (3, 79)], array([0.00000000e+00, 4.51994561e-08])],\n",
       " [[1, (3, 80)], array([1.55388061e-02, 3.24264720e-07])],\n",
       " [[1, (3, 81)], array([7.53048420e-01, 2.63108273e-07])],\n",
       " [[1, (3, 82)], array([1.58657503e+00, 2.17736361e-08])],\n",
       " [[1, (3, 83)], array([2.09359126e-03, 5.13354052e-08])],\n",
       " [[1, (3, 84)], array([2.93967426e-01, 4.04471719e-07])],\n",
       " [[1, (3, 85)], array([6.40585646e-03, 7.38772555e-09])],\n",
       " [[1, (3, 86)], array([5.65747656e-02, 9.78430345e-07])],\n",
       " [[1, (3, 87)], array([0.00000000e+00, 3.48524826e-13])],\n",
       " [[1, (3, 88)], array([3.96483064e+00, 6.94894176e-08])],\n",
       " [[1, (3, 89)], array([1.29595542e+00, 1.22299042e-07])],\n",
       " [[1, (3, 90)], array([2.82379317e+00, 1.66714596e-07])],\n",
       " [[1, (3, 91)], array([1.09176571e-03, 5.47477638e-07])],\n",
       " [[1, (3, 92)], array([6.27651215e-02, 8.94737391e-08])],\n",
       " [[1, (3, 93)], array([4.42514345e-02, 7.37292232e-07])],\n",
       " [[1, (3, 94)], array([1.83799174e-02, 2.26603275e-08])],\n",
       " [[1, (3, 95)], array([2.19787598e+00, 1.71992723e-07])],\n",
       " [[1, (3, 96)], array([3.01043061e-03, 9.80713313e-09])],\n",
       " [[1, (3, 97)], array([1.14897919e+00, 1.08077272e-08])],\n",
       " [[1, (3, 98)], array([1.82121181e+00, 4.59234055e-08])],\n",
       " [[1, (3, 99)], array([3.25794071e-02, 1.24553474e-08])],\n",
       " [[1, (4, 0)], array([6.55964077e-01, 3.13103123e-07])],\n",
       " [[1, (4, 1)], array([2.65358210e+00, 7.10075921e-07])],\n",
       " [[1, (4, 2)], array([8.21023226e-01, 3.95695523e-07])],\n",
       " [[1, (4, 3)], array([3.75332594e+00, 7.37314040e-08])],\n",
       " [[1, (4, 4)], array([5.48301220e-01, 6.72564758e-07])],\n",
       " [[1, (4, 5)], array([5.32617807e-01, 9.25676762e-08])],\n",
       " [[1, (4, 6)], array([4.04962492e+00, 4.31753419e-07])],\n",
       " [[1, (4, 7)], array([4.46358144e-01, 5.59571932e-07])],\n",
       " [[1, (4, 8)], array([7.37149000e-01, 1.04923146e-06])],\n",
       " [[1, (4, 9)], array([1.12375546e+01, 1.85674827e-07])],\n",
       " [[1, (4, 10)], array([1.43431216e-01, 2.04917454e-07])],\n",
       " [[1, (4, 11)], array([2.50270158e-01, 5.82788736e-07])],\n",
       " [[1, (4, 12)], array([2.03010035e+00, 2.54341893e-07])],\n",
       " [[1, (4, 13)], array([1.92846358e-01, 5.18100821e-07])],\n",
       " [[1, (4, 14)], array([1.61938691e+00, 4.73268931e-07])],\n",
       " [[1, (4, 15)], array([1.03609967e+00, 1.22103727e-08])],\n",
       " [[1, (4, 16)], array([6.93773651e+00, 3.60973573e-07])],\n",
       " [[1, (4, 17)], array([2.51158923e-02, 4.15776358e-07])],\n",
       " [[1, (4, 18)], array([9.20091122e-02, 2.10668924e-07])],\n",
       " [[1, (4, 19)], array([5.15485764e-01, 1.22125878e-07])],\n",
       " [[1, (4, 20)], array([2.05429363e+00, 8.02701812e-08])],\n",
       " [[1, (4, 21)], array([1.77182817e+00, 1.79683077e-07])],\n",
       " [[1, (4, 22)], array([8.61531124e-02, 2.22405300e-07])],\n",
       " [[1, (4, 23)], array([3.46763015e-01, 8.66153451e-07])],\n",
       " [[1, (4, 24)], array([2.34253287e+00, 3.96765593e-07])],\n",
       " [[1, (4, 25)], array([3.47045094e-01, 4.31040082e-07])],\n",
       " [[1, (4, 26)], array([5.99203587e-01, 1.83859688e-08])],\n",
       " [[1, (4, 27)], array([2.66119599e-01, 3.38737615e-07])],\n",
       " [[1, (4, 28)], array([1.10845342e-01, 3.10962372e-09])],\n",
       " [[1, (4, 29)], array([3.64651728e+00, 3.33713659e-07])],\n",
       " [[1, (4, 30)], array([9.71832573e-02, 3.98361960e-08])],\n",
       " [[1, (4, 31)], array([1.85844854e-01, 2.41150117e-07])],\n",
       " [[1, (4, 32)], array([8.53705257e-02, 5.76346592e-07])],\n",
       " [[1, (4, 33)], array([3.05148140e-02, 4.09722042e-07])],\n",
       " [[1, (4, 34)], array([1.32652724e+00, 5.34600131e-08])],\n",
       " [[1, (4, 35)], array([1.79350662e+00, 9.61670716e-08])],\n",
       " [[1, (4, 36)], array([7.11613178e-01, 6.86127257e-07])],\n",
       " [[1, (4, 37)], array([2.75216345e-03, 7.54108960e-08])],\n",
       " [[1, (4, 38)], array([2.11610505e-03, 1.33912643e-07])],\n",
       " [[1, (4, 39)], array([2.51652393e-02, 2.57203507e-08])],\n",
       " [[1, (4, 40)], array([9.97977257e-01, 1.40954447e-07])],\n",
       " [[1, (4, 41)], array([4.02486849e+00, 2.51667163e-07])],\n",
       " [[1, (4, 42)], array([9.95257139e-01, 3.15816244e-07])],\n",
       " [[1, (4, 43)], array([1.08339560e+00, 1.06344109e-08])],\n",
       " [[1, (4, 44)], array([2.00510907e+00, 1.46621778e-06])],\n",
       " [[1, (4, 45)], array([1.60156399e-01, 1.53190018e-06])],\n",
       " [[1, (4, 46)], array([3.83759618e-01, 3.08851485e-07])],\n",
       " [[1, (4, 47)], array([1.38862383e+00, 7.85738823e-08])],\n",
       " [[1, (4, 48)], array([5.45412636e+00, 1.64872026e-07])],\n",
       " [[1, (4, 49)], array([8.14565301e-01, 1.81983721e-07])],\n",
       " [[1, (4, 50)], array([1.48822576e-01, 1.17828830e-06])],\n",
       " [[1, (4, 51)], array([1.01368546e+00, 7.53690607e-08])],\n",
       " [[1, (4, 52)], array([4.44785774e-01, 1.11411886e-07])],\n",
       " [[1, (4, 53)], array([7.71563351e-02, 3.34768256e-08])],\n",
       " [[1, (4, 54)], array([3.06670785e-01, 5.23072685e-09])],\n",
       " [[1, (4, 55)], array([3.14317608e+00, 1.96863986e-06])],\n",
       " [[1, (4, 56)], array([1.97930217e-01, 4.12632350e-08])],\n",
       " [[1, (4, 57)], array([4.14702371e-02, 2.24558199e-08])],\n",
       " [[1, (4, 58)], array([2.33791065e+00, 4.89145925e-07])],\n",
       " [[1, (4, 59)], array([1.83352637e+00, 4.76850508e-08])],\n",
       " [[1, (4, 60)], array([2.93455814e-04, 2.42869694e-07])],\n",
       " [[1, (4, 61)], array([6.86194841e-03, 5.52666863e-08])],\n",
       " [[1, (4, 62)], array([4.59588814e+00, 1.32009385e-06])],\n",
       " [[1, (4, 63)], array([1.43547678e+00, 4.68363712e-07])],\n",
       " [[1, (4, 64)], array([1.21488476e+00, 3.42409550e-07])],\n",
       " [[1, (4, 65)], array([1.50268227e-01, 4.81730904e-08])],\n",
       " [[1, (4, 66)], array([1.96088684e+00, 1.23015927e-06])],\n",
       " [[1, (4, 67)], array([1.75907969e+00, 1.25511089e-06])],\n",
       " [[1, (4, 68)], array([1.55195594e+00, 1.44323852e-06])],\n",
       " [[1, (4, 69)], array([1.51896334e+00, 2.88166179e-07])],\n",
       " [[1, (4, 70)], array([4.81098853e-02, 2.39455733e-08])],\n",
       " [[1, (4, 71)], array([2.54778564e-01, 7.65497679e-07])],\n",
       " [[1, (4, 72)], array([4.68421221e-01, 2.24178966e-07])],\n",
       " [[1, (4, 73)], array([3.00970614e-01, 8.65569821e-07])],\n",
       " [[1, (4, 74)], array([9.67992425e-01, 1.26761002e-06])],\n",
       " [[1, (4, 75)], array([1.19628191e+00, 7.17206715e-07])],\n",
       " [[1, (4, 76)], array([6.66362429e+00, 3.79533977e-07])],\n",
       " [[1, (4, 77)], array([1.66462213e-02, 2.88641713e-08])],\n",
       " [[1, (4, 78)], array([5.91267228e-01, 5.53951920e-08])],\n",
       " [[1, (4, 79)], array([2.82941870e-02, 1.16027836e-07])],\n",
       " [[1, (4, 80)], array([6.23265952e-02, 6.87453568e-08])],\n",
       " [[1, (4, 81)], array([1.80023956e+00, 5.13390350e-09])],\n",
       " [[1, (4, 82)], array([4.25575304e+00, 1.57842864e-08])],\n",
       " [[1, (4, 83)], array([1.85241923e-02, 7.32451432e-09])],\n",
       " [[1, (4, 84)], array([3.26506615e-01, 1.95111944e-07])],\n",
       " [[1, (4, 85)], array([1.44335359e-01, 7.31355668e-09])],\n",
       " [[1, (4, 86)], array([1.40806898e-01, 9.22038849e-07])],\n",
       " [[1, (4, 87)], array([0.00000000e+00, 1.37498665e-13])],\n",
       " [[1, (4, 88)], array([8.37268543e+00, 1.25906743e-07])],\n",
       " [[1, (4, 89)], array([2.01154900e+00, 4.36340508e-07])],\n",
       " [[1, (4, 90)], array([7.85220814e+00, 2.56430058e-07])],\n",
       " [[1, (4, 91)], array([4.51293774e-03, 1.38936892e-06])],\n",
       " [[1, (4, 92)], array([1.36518270e-01, 2.40106124e-07])],\n",
       " [[1, (4, 93)], array([1.15290172e-01, 5.35940102e-07])],\n",
       " [[1, (4, 94)], array([5.89407206e-01, 6.50295522e-07])],\n",
       " [[1, (4, 95)], array([3.17354345e+00, 1.18027840e-08])],\n",
       " [[1, (4, 96)], array([4.65414077e-02, 1.85522059e-08])],\n",
       " [[1, (4, 97)], array([7.67294168e-01, 1.52694771e-07])],\n",
       " [[1, (4, 98)], array([2.46725869e+00, 5.77120220e-07])],\n",
       " [[1, (4, 99)], array([6.50833130e-01, 5.67307557e-07])],\n",
       " [[1, (5, 0)], array([1.87156129e+00, 6.00677229e-07])],\n",
       " [[1, (5, 1)], array([6.94377708e+00, 6.07004067e-07])],\n",
       " [[1, (5, 2)], array([1.38147187e+00, 1.01596738e-06])],\n",
       " [[1, (5, 3)], array([4.61610556e+00, 2.66286929e-07])],\n",
       " [[1, (5, 4)], array([5.53710341e-01, 7.91063490e-07])],\n",
       " [[1, (5, 5)], array([1.86976314e+00, 3.50916532e-07])],\n",
       " [[1, (5, 6)], array([8.06623936e+00, 4.58678127e-07])],\n",
       " [[1, (5, 7)], array([1.70317638e+00, 2.72605996e-07])],\n",
       " [[1, (5, 8)], array([1.06985438e+00, 4.06756949e-07])],\n",
       " [[1, (5, 9)], array([2.38989830e+01, 3.46426386e-07])],\n",
       " [[1, (5, 10)], array([3.7715888e-01, 9.7327911e-07])],\n",
       " [[1, (5, 11)], array([3.54667485e-01, 7.33879218e-07])],\n",
       " [[1, (5, 12)], array([4.81823635e+00, 1.37432952e-07])],\n",
       " [[1, (5, 13)], array([3.77251536e-01, 6.43344905e-07])],\n",
       " [[1, (5, 14)], array([2.18973923e+00, 1.08983975e-06])],\n",
       " [[1, (5, 15)], array([9.65334237e-01, 1.77644897e-08])],\n",
       " [[1, (5, 16)], array([8.74554253e+00, 1.55899381e-07])],\n",
       " [[1, (5, 17)], array([5.31118959e-02, 1.71918797e-07])],\n",
       " [[1, (5, 18)], array([6.95944503e-02, 6.44503829e-08])],\n",
       " [[1, (5, 19)], array([2.04746783e-01, 6.69785119e-07])],\n",
       " [[1, (5, 20)], array([2.65570498e+00, 1.71416439e-07])],\n",
       " [[1, (5, 21)], array([3.93105793e+00, 1.93467241e-07])],\n",
       " [[1, (5, 22)], array([1.23646088e-01, 2.74268897e-07])],\n",
       " [[1, (5, 23)], array([5.09447038e-01, 3.66639739e-07])],\n",
       " [[1, (5, 24)], array([2.19561791e+00, 8.56135313e-07])],\n",
       " [[1, (5, 25)], array([3.13867629e-01, 5.33793666e-07])],\n",
       " [[1, (5, 26)], array([1.29690707e+00, 7.13457310e-08])],\n",
       " [[1, (5, 27)], array([3.41625512e-01, 3.43430427e-07])],\n",
       " [[1, (5, 28)], array([7.98600614e-02, 1.53313752e-07])],\n",
       " [[1, (5, 29)], array([7.49560928e+00, 1.69984631e-06])],\n",
       " [[1, (5, 30)], array([6.00697175e-02, 1.06156214e-07])],\n",
       " [[1, (5, 31)], array([7.26126969e-01, 9.43126581e-07])],\n",
       " [[1, (5, 32)], array([1.46212772e-01, 2.97315573e-08])],\n",
       " [[1, (5, 33)], array([3.00402846e-02, 6.55014470e-07])],\n",
       " [[1, (5, 34)], array([3.75885844e+00, 3.66268651e-08])],\n",
       " [[1, (5, 35)], array([1.83194208e+00, 1.92972108e-07])],\n",
       " [[1, (5, 36)], array([9.14667547e-01, 1.07914490e-07])],\n",
       " [[1, (5, 37)], array([9.63179022e-02, 7.47139017e-07])],\n",
       " [[1, (5, 38)], array([5.0566243e-03, 1.9150905e-07])],\n",
       " [[1, (5, 39)], array([1.02747045e-03, 4.67579973e-08])],\n",
       " [[1, (5, 40)], array([1.27980423e+00, 2.41458744e-07])],\n",
       " [[1, (5, 41)], array([4.69030285e+00, 1.38828432e-06])],\n",
       " [[1, (5, 42)], array([1.07889593e+00, 2.01290996e-07])],\n",
       " [[1, (5, 43)], array([2.41471577e+00, 2.72356223e-07])],\n",
       " [[1, (5, 44)], array([1.69580841e+00, 8.87884123e-07])],\n",
       " [[1, (5, 45)], array([8.80073130e-01, 1.48956302e-06])],\n",
       " [[1, (5, 46)], array([7.64096379e-01, 2.18445659e-07])],\n",
       " [[1, (5, 47)], array([2.06594086e+00, 7.38287862e-07])],\n",
       " [[1, (5, 48)], array([9.75104332e+00, 1.11109808e-08])],\n",
       " [[1, (5, 49)], array([1.84702265e+00, 2.12513418e-07])],\n",
       " [[1, (5, 50)], array([2.24922121e-01, 9.57917171e-07])],\n",
       " [[1, (5, 51)], array([1.38239169e+00, 7.85049922e-07])],\n",
       " [[1, (5, 52)], array([1.02520084e+00, 2.57859777e-07])],\n",
       " [[1, (5, 53)], array([4.96927649e-02, 5.68642859e-07])],\n",
       " [[1, (5, 54)], array([4.19363230e-01, 1.20986369e-07])],\n",
       " [[1, (5, 55)], array([7.12874508e+00, 1.58914325e-06])],\n",
       " [[1, (5, 56)], array([5.49157023e-01, 1.55837398e-07])],\n",
       " [[1, (5, 57)], array([1.65907204e-01, 4.10044285e-08])],\n",
       " [[1, (5, 58)], array([3.08100557e+00, 1.25857693e-06])],\n",
       " [[1, (5, 59)], array([1.49447632e+00, 4.33229711e-08])],\n",
       " [[1, (5, 60)], array([6.57131337e-03, 2.45726172e-07])],\n",
       " [[1, (5, 61)], array([1.76879801e-02, 1.59855014e-07])],\n",
       " [[1, (5, 62)], array([6.66951180e+00, 3.83539197e-09])],\n",
       " [[1, (5, 63)], array([2.44120622e+00, 9.17240358e-07])],\n",
       " [[1, (5, 64)], array([4.09462547e+00, 1.54679914e-08])],\n",
       " [[1, (5, 65)], array([2.91629732e-02, 3.58745638e-07])],\n",
       " [[1, (5, 66)], array([6.37150764e+00, 6.16453838e-07])],\n",
       " [[1, (5, 67)], array([3.86288643e+00, 1.04530840e-06])],\n",
       " [[1, (5, 68)], array([2.05841446e+00, 2.24149509e-06])],\n",
       " [[1, (5, 69)], array([1.75373018e+00, 1.16958510e-07])],\n",
       " [[1, (5, 70)], array([1.47841632e-01, 2.80227430e-07])],\n",
       " [[1, (5, 71)], array([2.29729325e-01, 1.22360662e-06])],\n",
       " [[1, (5, 72)], array([5.15210807e-01, 2.36211067e-07])],\n",
       " [[1, (5, 73)], array([5.85475326e-01, 3.40156180e-07])],\n",
       " [[1, (5, 74)], array([2.40732598e+00, 6.30155314e-07])],\n",
       " [[1, (5, 75)], array([3.27744198e+00, 1.37384789e-07])],\n",
       " [[1, (5, 76)], array([1.26391602e+01, 1.30005382e-06])],\n",
       " [[1, (5, 77)], array([2.57104114e-02, 1.53360924e-08])],\n",
       " [[1, (5, 78)], array([1.60484624e+00, 1.74610609e-07])],\n",
       " [[1, (5, 79)], array([2.09557280e-01, 8.16805444e-08])],\n",
       " [[1, (5, 80)], array([1.72934830e-01, 3.64016892e-08])],\n",
       " [[1, (5, 81)], array([3.89799023e+00, 7.76900226e-07])],\n",
       " [[1, (5, 82)], array([7.43852711e+00, 1.90226842e-07])],\n",
       " [[1, (5, 83)], array([9.12026018e-02, 8.73844272e-07])],\n",
       " [[1, (5, 84)], array([2.22047782e+00, 3.01742530e-07])],\n",
       " [[1, (5, 85)], array([1.33745775e-01, 4.21221929e-08])],\n",
       " [[1, (5, 86)], array([2.11837143e-02, 2.19543785e-06])],\n",
       " [[1, (5, 87)], array([0.00000000e+00, 6.75011707e-12])],\n",
       " [[1, (5, 88)], array([9.05740070e+00, 2.36317278e-07])],\n",
       " [[1, (5, 89)], array([3.16543293e+00, 1.46994036e-08])],\n",
       " [[1, (5, 90)], array([1.57401514e+01, 3.43543645e-07])],\n",
       " [[1, (5, 91)], array([3.63995768e-02, 1.96655850e-06])],\n",
       " [[1, (5, 92)], array([2.04896167e-01, 2.17085410e-07])],\n",
       " [[1, (5, 93)], array([2.21384823e-01, 1.35302710e-07])],\n",
       " [[1, (5, 94)], array([1.03486824e+00, 3.84130152e-07])],\n",
       " [[1, (5, 95)], array([4.25007391e+00, 3.58786059e-07])],\n",
       " [[1, (5, 96)], array([6.50129281e-03, 2.72985755e-07])],\n",
       " [[1, (5, 97)], array([2.37941310e-01, 4.44228076e-07])],\n",
       " [[1, (5, 98)], array([4.54662848e+00, 2.48689154e-07])],\n",
       " [[1, (5, 99)], array([8.10882092e-01, 4.49552781e-07])],\n",
       " [[1, (6, 0)], array([4.41801167e+00, 1.22152209e-06])],\n",
       " [[1, (6, 1)], array([8.61299896e+00, 4.48419996e-06])],\n",
       " [[1, (6, 2)], array([2.73141003e+00, 2.11728802e-06])],\n",
       " [[1, (6, 3)], array([1.11759872e+01, 9.75038601e-07])],\n",
       " [[1, (6, 4)], array([7.17098475e-01, 4.93148900e-07])],\n",
       " [[1, (6, 5)], array([3.32092524e+00, 7.96485246e-06])],\n",
       " [[1, (6, 6)], array([1.61742096e+01, 9.60523646e-07])],\n",
       " [[1, (6, 7)], array([1.24653597e+01, 6.44276447e-07])],\n",
       " [[1, (6, 8)], array([1.87305892e+00, 5.36607364e-06])],\n",
       " [[1, (6, 9)], array([4.77187233e+01, 2.55368864e-06])],\n",
       " [[1, (6, 10)], array([9.12409782e-01, 7.17044697e-06])],\n",
       " [[1, (6, 11)], array([6.93395019e-01, 2.02740930e-06])],\n",
       " [[1, (6, 12)], array([1.36399002e+01, 2.21960677e-07])],\n",
       " [[1, (6, 13)], array([2.19078493e+00, 1.85037840e-06])],\n",
       " [[1, (6, 14)], array([2.49074006e+00, 1.20366696e-06])],\n",
       " [[1, (6, 15)], array([5.84966779e-01, 4.24871919e-08])],\n",
       " [[1, (6, 16)], array([1.89147606e+01, 3.17837984e-07])],\n",
       " [[1, (6, 17)], array([8.26867819e-02, 3.32129367e-07])],\n",
       " [[1, (6, 18)], array([1.02063119e-02, 2.46783795e-07])],\n",
       " [[1, (6, 19)], array([3.20709586e-01, 1.40931579e-06])],\n",
       " [[1, (6, 20)], array([5.64807653e+00, 5.58283244e-07])],\n",
       " [[1, (6, 21)], array([3.10968733e+00, 6.35146618e-07])],\n",
       " [[1, (6, 22)], array([5.79326212e-01, 3.76913512e-08])],\n",
       " [[1, (6, 23)], array([7.56219327e-01, 1.73327499e-06])],\n",
       " [[1, (6, 24)], array([5.93325233e+00, 7.23922756e-07])],\n",
       " [[1, (6, 25)], array([1.18864942e+00, 2.62787797e-06])],\n",
       " [[1, (6, 26)], array([2.80583668e+00, 1.17905599e-07])],\n",
       " [[1, (6, 27)], array([1.46511304e+00, 3.52444638e-07])],\n",
       " [[1, (6, 28)], array([7.41165876e-02, 1.49095498e-07])],\n",
       " [[1, (6, 29)], array([1.34503040e+01, 2.33676532e-06])],\n",
       " [[1, (6, 30)], array([6.87995195e-01, 1.24292909e-07])],\n",
       " [[1, (6, 31)], array([5.42934775e-01, 3.48562128e-06])],\n",
       " [[1, (6, 32)], array([3.54554385e-01, 2.11236679e-06])],\n",
       " [[1, (6, 33)], array([2.96573713e-02, 1.25457442e-06])],\n",
       " [[1, (6, 34)], array([6.47977829e+00, 5.78464483e-08])],\n",
       " [[1, (6, 35)], array([4.08077431e+00, 2.77677113e-07])],\n",
       " [[1, (6, 36)], array([1.51811171e+00, 1.53452880e-06])],\n",
       " [[1, (6, 37)], array([1.19326875e-01, 1.33014445e-06])],\n",
       " [[1, (6, 38)], array([1.05832703e-02, 4.69072072e-07])],\n",
       " [[1, (6, 39)], array([2.14162953e-02, 7.95917690e-08])],\n",
       " [[1, (6, 40)], array([2.59804106e+00, 6.53961029e-07])],\n",
       " [[1, (6, 41)], array([1.23654222e+01, 4.12628988e-06])],\n",
       " [[1, (6, 42)], array([3.06566447e-01, 1.37849505e-07])],\n",
       " [[1, (6, 43)], array([6.02676344e+00, 2.62172246e-08])],\n",
       " [[1, (6, 44)], array([1.87461567e+00, 2.38167678e-06])],\n",
       " [[1, (6, 45)], array([2.05504417e+00, 7.47793023e-06])],\n",
       " [[1, (6, 46)], array([7.71257281e-01, 4.97998452e-07])],\n",
       " [[1, (6, 47)], array([4.62843943e+00, 1.45545033e-07])],\n",
       " [[1, (6, 48)], array([1.76180153e+01, 7.68135609e-07])],\n",
       " [[1, (6, 49)], array([3.49709558e+00, 7.21325433e-08])],\n",
       " [[1, (6, 50)], array([3.20541620e-01, 6.16035392e-06])],\n",
       " [[1, (6, 51)], array([2.93213749e+00, 2.64719211e-06])],\n",
       " [[1, (6, 52)], array([4.56106758e+00, 1.39415901e-06])],\n",
       " [[1, (6, 53)], array([2.06487179e+00, 1.69096195e-06])],\n",
       " [[1, (6, 54)], array([3.20872903e+00, 1.03436106e-07])],\n",
       " [[1, (6, 55)], array([1.44060926e+01, 6.49695458e-06])],\n",
       " [[1, (6, 56)], array([1.90852749e+00, 9.37847336e-08])],\n",
       " [[1, (6, 57)], array([1.26104981e-01, 3.25906241e-08])],\n",
       " [[1, (6, 58)], array([3.49645090e+00, 2.77955226e-06])],\n",
       " [[1, (6, 59)], array([1.54795110e+00, 5.26999806e-08])],\n",
       " [[1, (6, 60)], array([2.16646884e-02, 2.52222640e-07])],\n",
       " [[1, (6, 61)], array([1.78636849e-01, 4.78901083e-07])],\n",
       " [[1, (6, 62)], array([1.08993511e+01, 6.42677218e-07])],\n",
       " [[1, (6, 63)], array([4.46951199e+00, 1.81737007e-06])],\n",
       " [[1, (6, 64)], array([3.11152148e+00, 2.43491733e-07])],\n",
       " [[1, (6, 65)], array([3.13282430e-01, 7.96014466e-07])],\n",
       " [[1, (6, 66)], array([1.64818478e+01, 1.78364272e-06])],\n",
       " [[1, (6, 67)], array([1.01686392e+01, 4.84066441e-06])],\n",
       " [[1, (6, 68)], array([7.15041304e+00, 3.84901089e-06])],\n",
       " [[1, (6, 69)], array([4.24005651e+00, 3.26841082e-07])],\n",
       " [[1, (6, 70)], array([1.34999841e-01, 9.36459386e-08])],\n",
       " [[1, (6, 71)], array([1.28095895e-01, 5.53678742e-06])],\n",
       " [[1, (6, 72)], array([1.63295627e+00, 1.08438147e-06])],\n",
       " [[1, (6, 73)], array([1.22049880e+00, 2.23151272e-06])],\n",
       " [[1, (6, 74)], array([1.52467299e+00, 6.06877438e-06])],\n",
       " [[1, (6, 75)], array([9.75305176e+00, 8.03991961e-07])],\n",
       " [[1, (6, 76)], array([2.83656502e+01, 7.58821276e-07])],\n",
       " [[1, (6, 77)], array([4.47128899e-02, 7.72813919e-07])],\n",
       " [[1, (6, 78)], array([1.92878389e+00, 3.22930924e-07])],\n",
       " [[1, (6, 79)], array([1.12077689e+00, 1.87406268e-07])],\n",
       " [[1, (6, 80)], array([6.00704625e-02, 2.75790857e-06])],\n",
       " [[1, (6, 81)], array([1.01302452e+01, 1.44341287e-06])],\n",
       " [[1, (6, 82)], array([1.58049908e+01, 2.22652858e-06])],\n",
       " [[1, (6, 83)], array([4.76270206e-02, 1.33933235e-06])],\n",
       " [[1, (6, 84)], array([2.66113663e+00, 1.33718368e-06])],\n",
       " [[1, (6, 85)], array([3.56175900e-01, 1.10158961e-08])],\n",
       " [[1, (6, 86)], array([3.88719022e-01, 9.85067610e-06])],\n",
       " [[1, (6, 87)], array([0.00000000e+00, 3.10135348e-12])],\n",
       " [[1, (6, 88)], array([1.72860603e+01, 2.04414220e-08])],\n",
       " [[1, (6, 89)], array([8.58981228e+00, 3.45342303e-06])],\n",
       " [[1, (6, 90)], array([2.00536346e+01, 2.50469625e-07])],\n",
       " [[1, (6, 91)], array([2.02896237e-01, 5.93972639e-06])],\n",
       " [[1, (6, 92)], array([3.00691366e-01, 6.07411364e-07])],\n",
       " [[1, (6, 93)], array([4.25976068e-01, 5.97770545e-06])],\n",
       " [[1, (6, 94)], array([2.4737885e+00, 5.8083469e-07])],\n",
       " [[1, (6, 95)], array([6.98232031e+00, 4.78912535e-06])],\n",
       " [[1, (6, 96)], array([2.60297712e-02, 3.90126344e-07])],\n",
       " [[1, (6, 97)], array([8.97969782e-01, 6.37904877e-07])],\n",
       " [[1, (6, 98)], array([1.12983990e+01, 3.03704878e-08])],\n",
       " [[1, (6, 99)], array([5.90515971e-01, 2.14878122e-07])],\n",
       " [[1, (7, 0)], array([8.70315552e+00, 1.74259214e-06])],\n",
       " [[1, (7, 1)], array([1.90907879e+01, 3.84385929e-06])],\n",
       " [[1, (7, 2)], array([9.28744888e+00, 4.83870761e-06])],\n",
       " [[1, (7, 3)], array([2.52222939e+01, 5.95726102e-07])],\n",
       " [[1, (7, 4)], array([1.10750198e+00, 2.53136725e-06])],\n",
       " [[1, (7, 5)], array([9.70824242e+00, 2.38653046e-05])],\n",
       " [[1, (7, 6)], array([2.78894119e+01, 5.43930352e-07])],\n",
       " [[1, (7, 7)], array([3.55680847e+01, 1.98832307e-06])],\n",
       " [[1, (7, 8)], array([5.79432583e+00, 1.39676219e-05])],\n",
       " [[1, (7, 9)], array([9.01976166e+01, 6.49980435e-06])],\n",
       " [[1, (7, 10)], array([4.93049145e+00, 7.57714514e-06])],\n",
       " [[1, (7, 11)], array([2.47197866e+00, 4.78070985e-06])],\n",
       " [[1, (7, 12)], array([2.75156021e+01, 3.25504433e-06])],\n",
       " [[1, (7, 13)], array([2.72278929e+00, 5.55425174e-07])],\n",
       " [[1, (7, 14)], array([5.91544390e+00, 4.81724534e-06])],\n",
       " [[1, (7, 15)], array([1.09960079e+00, 1.52754045e-07])],\n",
       " [[1, (7, 16)], array([3.99290085e+01, 1.12132953e-06])],\n",
       " [[1, (7, 17)], array([6.76341474e-01, 1.53763139e-06])],\n",
       " [[1, (7, 18)], array([1.03326333e+00, 3.49439776e-06])],\n",
       " [[1, (7, 19)], array([3.44802189e+00, 1.07951063e-06])],\n",
       " [[1, (7, 20)], array([8.09685898e+00, 3.90592276e-07])],\n",
       " [[1, (7, 21)], array([6.63143253e+00, 7.48312177e-06])],\n",
       " [[1, (7, 22)], array([6.80061102e-01, 4.23778692e-06])],\n",
       " [[1, (7, 23)], array([5.44082105e-01, 1.87398847e-06])],\n",
       " [[1, (7, 24)], array([1.78737335e+01, 4.30150849e-07])],\n",
       " [[1, (7, 25)], array([2.08171797e+00, 3.07213803e-06])],\n",
       " [[1, (7, 26)], array([7.11610317e+00, 1.12114460e-07])],\n",
       " [[1, (7, 27)], array([4.70187378e+00, 3.85253894e-07])],\n",
       " [[1, (7, 28)], array([2.62096524e-02, 2.83690087e-06])],\n",
       " [[1, (7, 29)], array([2.54874878e+01, 6.23416574e-06])],\n",
       " [[1, (7, 30)], array([1.33310342e+00, 4.35404662e-08])],\n",
       " [[1, (7, 31)], array([6.45356059e-01, 6.85006509e-06])],\n",
       " [[1, (7, 32)], array([2.58814096e-01, 4.06775942e-06])],\n",
       " [[1, (7, 33)], array([2.86166947e-02, 2.28964764e-06])],\n",
       " [[1, (7, 34)], array([8.36264420e+00, 1.58163196e-07])],\n",
       " [[1, (7, 35)], array([8.95022011e+00, 2.19272266e-07])],\n",
       " [[1, (7, 36)], array([1.70787060e+00, 7.30727918e-06])],\n",
       " [[1, (7, 37)], array([7.17670202e-01, 3.57672111e-06])],\n",
       " [[1, (7, 38)], array([3.35200280e-02, 1.43709014e-06])],\n",
       " [[1, (7, 39)], array([7.07505822e-01, 4.21472902e-07])],\n",
       " [[1, (7, 40)], array([2.61188507e+00, 3.51448667e-06])],\n",
       " [[1, (7, 41)], array([3.06422577e+01, 3.16261052e-08])],\n",
       " [[1, (7, 42)], array([8.45760763e-01, 1.79998550e-06])],\n",
       " [[1, (7, 43)], array([1.23980818e+01, 1.71292740e-06])],\n",
       " [[1, (7, 44)], array([5.90695143e+00, 9.27498374e-06])],\n",
       " [[1, (7, 45)], array([3.56546211e+00, 1.23802081e-05])],\n",
       " [[1, (7, 46)], array([4.18709755e+00, 2.82965811e-06])],\n",
       " [[1, (7, 47)], array([1.01389608e+01, 2.69802830e-07])],\n",
       " [[1, (7, 48)], array([3.41437225e+01, 3.09506470e-08])],\n",
       " [[1, (7, 49)], array([9.85593033e+00, 7.21488658e-08])],\n",
       " [[1, (7, 50)], array([5.63315988e-01, 1.14944308e-05])],\n",
       " [[1, (7, 51)], array([2.78568506e+00, 4.28228412e-07])],\n",
       " [[1, (7, 52)], array([1.12922163e+01, 6.96083991e-06])],\n",
       " [[1, (7, 53)], array([9.98560333e+00, 1.07725426e-07])],\n",
       " [[1, (7, 54)], array([7.52864599e+00, 8.75425755e-07])],\n",
       " [[1, (7, 55)], array([3.73657532e+01, 2.63654893e-06])],\n",
       " [[1, (7, 56)], array([4.90157413e+00, 7.52947125e-08])],\n",
       " [[1, (7, 57)], array([1.69748962e-01, 1.52339226e-07])],\n",
       " [[1, (7, 58)], array([3.89794350e+00, 3.25205053e-06])],\n",
       " [[1, (7, 59)], array([8.44394326e-01, 3.39066417e-07])],\n",
       " [[1, (7, 60)], array([2.05448598e-01, 1.13692966e-06])],\n",
       " [[1, (7, 61)], array([1.27040291e+00, 5.36954248e-07])],\n",
       " [[1, (7, 62)], array([3.59672699e+01, 7.21797689e-06])],\n",
       " [[1, (7, 63)], array([7.91355228e+00, 4.63395461e-07])],\n",
       " [[1, (7, 64)], array([2.26087570e-01, 7.63766895e-06])],\n",
       " [[1, (7, 65)], array([2.36680317e+00, 1.51434352e-06])],\n",
       " [[1, (7, 66)], array([2.53377647e+01, 4.04218001e-06])],\n",
       " [[1, (7, 67)], array([3.41894150e+01, 2.42581343e-06])],\n",
       " [[1, (7, 68)], array([1.47866535e+01, 3.73959266e-06])],\n",
       " [[1, (7, 69)], array([1.45039558e-01, 1.61757089e-06])],\n",
       " [[1, (7, 70)], array([2.45310366e-01, 2.02701756e-06])],\n",
       " [[1, (7, 71)], array([1.12364642e-01, 8.86516344e-06])],\n",
       " [[1, (7, 72)], array([4.99734116e+00, 3.58201573e-06])],\n",
       " [[1, (7, 73)], array([3.40585542e+00, 5.16012040e-06])],\n",
       " [[1, (7, 74)], array([3.81789541e+00, 1.03172899e-05])],\n",
       " [[1, (7, 75)], array([2.30050850e+01, 5.39407331e-08])],\n",
       " [[1, (7, 76)], array([7.34892426e+01, 2.66083186e-06])],\n",
       " [[1, (7, 77)], array([3.95566136e-01, 3.65204248e-06])],\n",
       " [[1, (7, 78)], array([2.25422764e+00, 6.05593008e-07])],\n",
       " [[1, (7, 79)], array([2.54327703e+00, 8.13735010e-07])],\n",
       " [[1, (7, 80)], array([4.95724082e-02, 3.82933996e-06])],\n",
       " [[1, (7, 81)], array([2.63533707e+01, 3.79419336e-06])],\n",
       " [[1, (7, 82)], array([3.55965004e+01, 2.54469341e-06])],\n",
       " [[1, (7, 83)], array([2.13587284e-01, 3.76165639e-06])],\n",
       " [[1, (7, 84)], array([6.40916586e-01, 2.76050523e-06])],\n",
       " [[1, (7, 85)], array([3.8781330e-01, 2.0081076e-07])],\n",
       " [[1, (7, 86)], array([5.56973362e+00, 1.13745932e-05])],\n",
       " [[1, (7, 87)], array([0.00000000e+00, 9.91521426e-12])],\n",
       " [[1, (7, 88)], array([4.63586349e+01, 4.86561654e-08])],\n",
       " [[1, (7, 89)], array([2.08676758e+01, 3.58720180e-06])],\n",
       " [[1, (7, 90)], array([3.07004147e+01, 3.44164554e-06])],\n",
       " [[1, (7, 91)], array([8.03426653e-02, 1.06577807e-05])],\n",
       " [[1, (7, 92)], array([1.76738167e+00, 1.12988851e-06])],\n",
       " [[1, (7, 93)], array([8.39129567e-01, 9.95556601e-06])],\n",
       " [[1, (7, 94)], array([5.18702126e+00, 5.43749624e-07])],\n",
       " [[1, (7, 95)], array([2.53039551e+01, 6.89128963e-07])],\n",
       " [[1, (7, 96)], array([6.42851964e-02, 1.18298632e-06])],\n",
       " [[1, (7, 97)], array([1.00596344e+00, 1.75830735e-06])],\n",
       " [[1, (7, 98)], array([1.79829350e+01, 4.83887979e-06])],\n",
       " [[1, (7, 99)], array([2.25207090e-01, 3.75367069e-06])],\n",
       " [[1, (8, 0)], array([7.94522858e+00, 1.75437255e-06])],\n",
       " [[1, (8, 1)], array([3.34609261e+01, 1.43976953e-05])],\n",
       " [[1, (8, 2)], array([3.22148666e+01, 7.03515558e-07])],\n",
       " [[1, (8, 3)], array([4.27277641e+01, 2.21829107e-06])],\n",
       " [[1, (8, 4)], array([1.75985658e+00, 6.30072754e-06])],\n",
       " [[1, (8, 5)], array([1.99708023e+01, 1.65222149e-05])],\n",
       " [[1, (8, 6)], array([3.93784866e+01, 2.54645678e-06])],\n",
       " [[1, (8, 7)], array([5.95809708e+01, 1.87211436e-06])],\n",
       " [[1, (8, 8)], array([1.81827164e+01, 9.21494014e-06])],\n",
       " [[1, (8, 9)], array([1.14091827e+02, 2.15498984e-05])],\n",
       " [[1, (8, 10)], array([1.02229786e+01, 7.47911961e-06])],\n",
       " [[1, (8, 11)], array([2.92434669e+00, 2.14585537e-05])],\n",
       " [[1, (8, 12)], array([2.83348198e+01, 2.56768537e-06])],\n",
       " [[1, (8, 13)], array([2.37091613e+00, 8.52331795e-06])],\n",
       " [[1, (8, 14)], array([9.91263199e+00, 4.85776528e-07])],\n",
       " [[1, (8, 15)], array([3.55337620e+00, 6.89264549e-08])],\n",
       " [[1, (8, 16)], array([8.73557739e+01, 6.40406075e-06])],\n",
       " [[1, (8, 17)], array([8.55116487e-01, 2.75594474e-06])],\n",
       " [[1, (8, 18)], array([2.27977395e+00, 6.40977111e-06])],\n",
       " [[1, (8, 19)], array([1.49029207e+01, 1.85972695e-06])],\n",
       " [[1, (8, 20)], array([8.19036102e+00, 2.56624829e-06])],\n",
       " [[1, (8, 21)], array([1.32709589e+01, 2.03105098e-05])],\n",
       " [[1, (8, 22)], array([5.22498488e-01, 2.72652092e-07])],\n",
       " [[1, (8, 23)], array([4.85119611e-01, 6.55347044e-06])],\n",
       " [[1, (8, 24)], array([4.13973618e+01, 1.34221971e-06])],\n",
       " [[1, (8, 25)], array([2.92231798e+00, 1.66859786e-06])],\n",
       " [[1, (8, 26)], array([1.08167467e+01, 1.40942576e-07])],\n",
       " [[1, (8, 27)], array([3.69655561e+00, 2.11585753e-06])],\n",
       " [[1, (8, 28)], array([4.79950815e-01, 5.48941941e-06])],\n",
       " [[1, (8, 29)], array([3.37795181e+01, 1.27315877e-05])],\n",
       " [[1, (8, 30)], array([3.01573777e+00, 8.28363096e-07])],\n",
       " [[1, (8, 31)], array([4.78344154e+00, 6.18127267e-06])],\n",
       " [[1, (8, 32)], array([3.42035913e+00, 6.33568528e-07])],\n",
       " [[1, (8, 33)], array([2.62440462e-02, 4.33716701e-06])],\n",
       " [[1, (8, 34)], array([7.87121773e+00, 4.94273091e-07])],\n",
       " [[1, (8, 35)], array([1.43494911e+01, 4.29910423e-06])],\n",
       " [[1, (8, 36)], array([6.44264412e+00, 3.53950428e-06])],\n",
       " [[1, (8, 37)], array([1.04488668e+01, 4.73424101e-06])],\n",
       " [[1, (8, 38)], array([3.85834157e-01, 1.24330203e-06])],\n",
       " [[1, (8, 39)], array([2.47109032e+00, 1.02149116e-06])],\n",
       " [[1, (8, 40)], array([7.21233988e+00, 5.82583474e-06])],\n",
       " [[1, (8, 41)], array([6.02318726e+01, 2.02598403e-05])],\n",
       " [[1, (8, 42)], array([1.76427102e+00, 2.91233182e-06])],\n",
       " [[1, (8, 43)], array([1.37911806e+01, 1.03629753e-06])],\n",
       " [[1, (8, 44)], array([2.49319572e+01, 6.30183164e-06])],\n",
       " [[1, (8, 45)], array([4.35729313e+00, 5.58628865e-06])],\n",
       " [[1, (8, 46)], array([1.95065632e+01, 3.65002782e-06])],\n",
       " [[1, (8, 47)], array([2.60230522e+01, 4.95509348e-06])],\n",
       " [[1, (8, 48)], array([6.20325279e+01, 2.33003660e-06])],\n",
       " [[1, (8, 49)], array([2.12687950e+01, 2.18852615e-07])],\n",
       " [[1, (8, 50)], array([5.49317658e-01, 2.56306416e-05])],\n",
       " [[1, (8, 51)], array([1.09890485e+00, 3.16930392e-06])],\n",
       " [[1, (8, 52)], array([1.48640079e+01, 1.05382074e-05])],\n",
       " [[1, (8, 53)], array([3.25035477e+01, 4.08029490e-07])],\n",
       " [[1, (8, 54)], array([3.05387998e+00, 3.57760342e-07])],\n",
       " [[1, (8, 55)], array([5.24737320e+01, 7.46756096e-06])],\n",
       " [[1, (8, 56)], array([1.28068819e+01, 7.46307783e-07])],\n",
       " [[1, (8, 57)], array([5.35222173e-01, 6.56041365e-08])],\n",
       " [[1, (8, 58)], array([3.80628109e-02, 6.78111843e-06])],\n",
       " [[1, (8, 59)], array([1.11758804e+00, 2.06693932e-07])],\n",
       " [[1, (8, 60)], array([6.47627175e-01, 3.61119508e-06])],\n",
       " [[1, (8, 61)], array([1.40568316e-01, 6.00386829e-07])],\n",
       " [[1, (8, 62)], array([1.05345940e+02, 7.52402852e-06])],\n",
       " [[1, (8, 63)], array([6.28925896e+00, 9.08123032e-06])],\n",
       " [[1, (8, 64)], array([2.51208534e+01, 1.56255536e-05])],\n",
       " [[1, (8, 65)], array([9.27744293e+00, 1.22933309e-07])],\n",
       " [[1, (8, 66)], array([1.38564339e+01, 2.67024401e-05])],\n",
       " [[1, (8, 67)], array([5.41909752e+01, 3.65313732e-05])],\n",
       " [[1, (8, 68)], array([2.52656898e+01, 1.49674181e-06])],\n",
       " [[1, (8, 69)], array([1.31309586e+01, 5.10522014e-06])],\n",
       " [[1, (8, 70)], array([4.07699108e-01, 2.35144528e-06])],\n",
       " [[1, (8, 71)], array([5.33412039e-01, 1.27217068e-05])],\n",
       " [[1, (8, 72)], array([1.36830540e+01, 2.41875593e-06])],\n",
       " [[1, (8, 73)], array([5.48309898e+00, 2.71322985e-07])],\n",
       " [[1, (8, 74)], array([1.07576866e+01, 1.44583839e-05])],\n",
       " [[1, (8, 75)], array([4.81524277e+01, 4.15996363e-08])],\n",
       " [[1, (8, 76)], array([1.50506897e+02, 2.59718047e-06])],\n",
       " [[1, (8, 77)], array([1.51630330e+00, 3.45491839e-06])],\n",
       " [[1, (8, 78)], array([2.57670712e+00, 3.93699791e-06])],\n",
       " [[1, (8, 79)], array([5.69898224e+00, 3.12220910e-06])],\n",
       " [[1, (8, 80)], array([1.17490315e+00, 3.56829604e-06])],\n",
       " [[1, (8, 81)], array([4.08182869e+01, 9.02434345e-06])],\n",
       " [[1, (8, 82)], array([6.48272247e+01, 4.77875207e-06])],\n",
       " [[1, (8, 83)], array([1.23679578e+00, 3.18679860e-06])],\n",
       " [[1, (8, 84)], array([9.81993675e+00, 2.01282113e-06])],\n",
       " [[1, (8, 85)], array([7.89629221e-01, 3.16864899e-07])],\n",
       " [[1, (8, 86)], array([2.99394302e+01, 6.23093166e-06])],\n",
       " [[1, (8, 87)], array([0.00000000e+00, 5.11958049e-11])],\n",
       " [[1, (8, 88)], array([9.61584091e+01, 5.23708059e-07])],\n",
       " [[1, (8, 89)], array([3.02242088e+01, 5.40601857e-06])],\n",
       " [[1, (8, 90)], array([4.91132736e+01, 2.37562688e-06])],\n",
       " [[1, (8, 91)], array([1.30810213e+00, 2.10026841e-05])],\n",
       " [[1, (8, 92)], array([4.27882576e+00, 1.27742538e-06])],\n",
       " [[1, (8, 93)], array([1.21181035e+00, 1.38605331e-05])],\n",
       " [[1, (8, 94)], array([1.12266359e+01, 4.23303618e-07])],\n",
       " [[1, (8, 95)], array([3.96380005e+01, 1.08546698e-05])],\n",
       " [[1, (8, 96)], array([4.61358070e-01, 2.48535934e-06])],\n",
       " [[1, (8, 97)], array([7.07765007e+00, 3.86418282e-06])],\n",
       " [[1, (8, 98)], array([2.19438286e+01, 6.20320961e-06])],\n",
       " [[1, (8, 99)], array([1.45651817e+00, 1.44129112e-06])],\n",
       " [[1, (9, 0)], array([1.46027317e+01, 5.32917635e-06])],\n",
       " [[1, (9, 1)], array([3.83755722e+01, 4.21445047e-05])],\n",
       " [[1, (9, 2)], array([7.51531067e+01, 5.74513772e-06])],\n",
       " [[1, (9, 3)], array([4.90476875e+01, 1.30019883e-06])],\n",
       " [[1, (9, 4)], array([1.62537694e-01, 1.13664091e-05])],\n",
       " [[1, (9, 5)], array([1.1007515e+01, 2.4605430e-06])],\n",
       " [[1, (9, 6)], array([4.49827805e+01, 3.76564963e-06])],\n",
       " [[1, (9, 7)], array([9.50851288e+01, 1.41894964e-06])],\n",
       " [[1, (9, 8)], array([2.62648506e+01, 3.40560596e-07])],\n",
       " [[1, (9, 9)], array([1.23674683e+02, 7.92508058e-06])],\n",
       " [[1, (9, 10)], array([1.57491150e+01, 4.73773572e-06])],\n",
       " [[1, (9, 11)], array([6.24343443e+00, 4.46447776e-05])],\n",
       " [[1, (9, 12)], array([2.32856255e+01, 1.31778468e-05])],\n",
       " [[1, (9, 13)], array([8.87071896e+00, 2.47256415e-06])],\n",
       " [[1, (9, 14)], array([1.53309765e+01, 2.28215940e-05])],\n",
       " [[1, (9, 15)], array([7.01263475e+00, 9.60310948e-08])],\n",
       " [[1, (9, 16)], array([1.55600739e+02, 7.68306971e-06])],\n",
       " [[1, (9, 17)], array([9.17780304e+00, 2.78358919e-06])],\n",
       " [[1, (9, 18)], array([8.52852058e+00, 1.44102823e-06])],\n",
       " [[1, (9, 19)], array([3.29331131e+01, 1.60424937e-06])],\n",
       " [[1, (9, 20)], array([1.75653851e+00, 2.20038844e-06])],\n",
       " [[1, (9, 21)], array([3.75382576e+01, 1.28367180e-05])],\n",
       " [[1, (9, 22)], array([5.28358042e-01, 1.60405121e-05])],\n",
       " [[1, (9, 23)], array([1.09667075e+00, 6.80890936e-06])],\n",
       " [[1, (9, 24)], array([6.71566238e+01, 2.88877939e-06])],\n",
       " [[1, (9, 25)], array([5.89540434e+00, 4.28759056e-06])],\n",
       " [[1, (9, 26)], array([1.72466927e+01, 4.96230778e-07])],\n",
       " [[1, (9, 27)], array([2.07692575e+00, 8.44949202e-06])],\n",
       " [[1, (9, 28)], array([9.42684650e-01, 2.66865585e-06])],\n",
       " [[1, (9, 29)], array([2.70825500e+01, 7.87022368e-06])],\n",
       " [[1, (9, 30)], array([3.44432259e+00, 9.35342702e-07])],\n",
       " [[1, (9, 31)], array([1.55347986e+01, 2.45414786e-06])],\n",
       " [[1, (9, 32)], array([1.63848648e+01, 7.02874592e-06])],\n",
       " [[1, (9, 33)], array([1.77957118e-04, 1.05553271e-06])],\n",
       " [[1, (9, 34)], array([8.67748642e+00, 1.82786946e-06])],\n",
       " [[1, (9, 35)], array([2.60755272e+01, 2.41285212e-07])],\n",
       " [[1, (9, 36)], array([1.22185278e+01, 8.23205904e-06])],\n",
       " [[1, (9, 37)], array([2.70157089e+01, 2.62135657e-06])],\n",
       " [[1, (9, 38)], array([1.87388098e+00, 2.55694397e-06])],\n",
       " [[1, (9, 39)], array([4.30271435e+00, 1.23364216e-06])],\n",
       " [[1, (9, 40)], array([1.64179440e+01, 5.22776427e-06])],\n",
       " [[1, (9, 41)], array([1.09491302e+02, 7.76876199e-07])],\n",
       " [[1, (9, 42)], array([2.01798463e+00, 2.99900997e-06])],\n",
       " [[1, (9, 43)], array([1.00686646e+01, 1.10768827e-05])],\n",
       " [[1, (9, 44)], array([3.33746262e+01, 1.58938940e-05])],\n",
       " [[1, (9, 45)], array([1.18299799e+01, 1.02394735e-05])],\n",
       " [[1, (9, 46)], array([6.01946793e+01, 3.25795213e-06])],\n",
       " [[1, (9, 47)], array([4.64861679e+01, 1.53515007e-06])],\n",
       " [[1, (9, 48)], array([1.40454056e+02, 6.79113807e-06])],\n",
       " [[1, (9, 49)], array([3.98567505e+01, 2.81284286e-07])],\n",
       " [[1, (9, 50)], array([4.07832950e-01, 7.27187756e-06])],\n",
       " [[1, (9, 51)], array([4.54510689e+00, 1.12229701e-05])],\n",
       " [[1, (9, 52)], array([1.57687302e+01, 1.11957655e-05])],\n",
       " [[1, (9, 53)], array([6.22368240e+01, 4.83244606e-06])],\n",
       " [[1, (9, 54)], array([1.56309962e+00, 6.94608987e-08])],\n",
       " [[1, (9, 55)], array([6.41216736e+01, 3.66522282e-05])],\n",
       " [[1, (9, 56)], array([2.11691589e+01, 2.54803948e-07])],\n",
       " [[1, (9, 57)], array([2.89339042e+00, 2.62476274e-07])],\n",
       " [[1, (9, 58)], array([1.82787170e+01, 2.20053565e-05])],\n",
       " [[1, (9, 59)], array([1.64569359e+01, 4.19979794e-07])],\n",
       " [[1, (9, 60)], array([3.02470148e-01, 3.92082550e-06])],\n",
       " [[1, (9, 61)], array([1.76163733e+00, 7.69806840e-07])],\n",
       " [[1, (9, 62)], array([1.87780899e+02, 5.78223336e-06])],\n",
       " [[1, (9, 63)], array([8.18173504e+00, 2.12098736e-05])],\n",
       " [[1, (9, 64)], array([8.49974289e+01, 3.67618547e-06])],\n",
       " [[1, (9, 65)], array([2.51133690e+01, 1.93849146e-07])],\n",
       " [[1, (9, 66)], array([1.59056778e+01, 1.06116762e-05])],\n",
       " [[1, (9, 67)], array([5.83648262e+01, 1.02097829e-04])],\n",
       " [[1, (9, 68)], array([4.06412163e+01, 3.95954228e-06])],\n",
       " [[1, (9, 69)], array([4.72388840e+00, 5.73878846e-06])],\n",
       " [[1, (9, 70)], array([3.13073015e+00, 1.10624113e-06])],\n",
       " [[1, (9, 71)], array([2.79682517e-01, 5.51548550e-06])],\n",
       " [[1, (9, 72)], array([1.99661751e+01, 5.70735238e-06])],\n",
       " [[1, (9, 73)], array([1.06464767e+01, 1.70420060e-06])],\n",
       " [[1, (9, 74)], array([1.76389008e+01, 6.67407973e-06])],\n",
       " [[1, (9, 75)], array([6.15929108e+01, 2.28491080e-06])],\n",
       " [[1, (9, 76)], array([2.30598816e+02, 5.21259687e-06])],\n",
       " [[1, (9, 77)], array([2.71997714e+00, 9.37247373e-08])],\n",
       " [[1, (9, 78)], array([2.44069099e+00, 1.44294574e-06])],\n",
       " [[1, (9, 79)], array([8.58303070e+00, 2.20442803e-06])],\n",
       " [[1, (9, 80)], array([9.16945457e+00, 5.11170924e-06])],\n",
       " [[1, (9, 81)], array([5.20365448e+01, 8.42549863e-06])],\n",
       " [[1, (9, 82)], array([9.78433533e+01, 5.97192611e-06])],\n",
       " [[1, (9, 83)], array([2.50579405e+00, 1.42461825e-05])],\n",
       " [[1, (9, 84)], array([1.28476315e+01, 1.07661400e-05])],\n",
       " [[1, (9, 85)], array([6.79040253e-02, 3.34218387e-07])],\n",
       " [[1, (9, 86)], array([6.20816727e+01, 1.71262513e-05])],\n",
       " [[1, (9, 87)], array([0.0000000e+00, 8.2816254e-11])],\n",
       " [[1, (9, 88)], array([1.43748016e+02, 1.92465895e-06])],\n",
       " [[1, (9, 89)], array([3.89066315e+01, 1.64222838e-06])],\n",
       " [[1, (9, 90)], array([7.09942703e+01, 1.95300468e-05])],\n",
       " [[1, (9, 91)], array([5.10732937e+00, 1.12945470e-05])],\n",
       " [[1, (9, 92)], array([1.00066490e+01, 4.80611822e-06])],\n",
       " [[1, (9, 93)], array([1.35997427e+00, 1.49529853e-05])],\n",
       " [[1, (9, 94)], array([1.94194565e+01, 1.76429158e-06])],\n",
       " [[1, (9, 95)], array([3.10622444e+01, 2.23967320e-05])],\n",
       " [[1, (9, 96)], array([4.61267185e+00, 2.67399770e-06])],\n",
       " [[1, (9, 97)], array([1.46711693e+01, 1.17837017e-07])],\n",
       " [[1, (9, 98)], array([1.95217896e+01, 7.70698314e-07])],\n",
       " [[1, (9, 99)], array([2.16065550e+00, 1.02489186e-06])],\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/rq1/all_layers/simple_fm/grad/loc.all_cost.loc.0.1.grad.pkl\", 'rb') as f:\n",
    "    grad_locs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([3, (93, 6)], 14614.842),\n",
       " ([3, (93, 4)], 9396.044),\n",
       " ([3, (93, 8)], 6033.9316),\n",
       " ([3, (93, 0)], 5806.341),\n",
       " ([3, (9, 6)], 5498.6074),\n",
       " ([3, (93, 2)], 4745.653),\n",
       " ([3, (45, 6)], 4572.8706),\n",
       " ([3, (50, 6)], 4295.22),\n",
       " ([3, (71, 6)], 4265.6543),\n",
       " ([3, (45, 4)], 3572.9094),\n",
       " ([3, (9, 4)], 3434.061),\n",
       " ([3, (9, 8)], 3323.628),\n",
       " ([3, (5, 4)], 2947.9844),\n",
       " ([3, (5, 6)], 2673.6934),\n",
       " ([3, (45, 8)], 2503.706),\n",
       " ([3, (46, 7)], 2474.5686),\n",
       " ([3, (27, 7)], 2474.4722),\n",
       " ([3, (37, 7)], 2395.8098),\n",
       " ([3, (33, 7)], 2303.5208),\n",
       " ([3, (86, 4)], 2232.5571),\n",
       " ([3, (67, 6)], 2217.7637),\n",
       " ([3, (74, 4)], 2179.2095),\n",
       " ([3, (42, 7)], 2129.6577),\n",
       " ([3, (71, 4)], 2101.9414),\n",
       " ([3, (74, 6)], 2086.6382),\n",
       " ([3, (86, 6)], 2050.6292),\n",
       " ([3, (50, 4)], 2048.1226),\n",
       " ([3, (67, 4)], 2032.7578),\n",
       " ([3, (9, 2)], 1962.869),\n",
       " ([3, (50, 8)], 1961.8867),\n",
       " ([3, (45, 2)], 1959.9155),\n",
       " ([3, (1, 6)], 1951.5448),\n",
       " ([3, (71, 8)], 1945.7554),\n",
       " ([1, (343, 48)], 1933.6929),\n",
       " ([1, (371, 48)], 1929.2078),\n",
       " ([1, (315, 48)], 1922.9739),\n",
       " ([3, (34, 7)], 1919.3209),\n",
       " ([3, (55, 6)], 1909.739),\n",
       " ([1, (399, 48)], 1905.4373),\n",
       " ([1, (287, 48)], 1897.5898),\n",
       " ([3, (50, 0)], 1897.0603),\n",
       " ([1, (288, 48)], 1891.9346),\n",
       " ([1, (441, 48)], 1889.0779),\n",
       " ([1, (427, 48)], 1885.5095),\n",
       " ([1, (469, 48)], 1885.1481),\n",
       " ([1, (413, 48)], 1883.0422),\n",
       " ([1, (316, 48)], 1881.2915),\n",
       " ([1, (426, 48)], 1880.2167),\n",
       " ([1, (385, 48)], 1876.675),\n",
       " ([1, (259, 48)], 1874.2831),\n",
       " ([1, (454, 48)], 1873.9937),\n",
       " ([1, (497, 48)], 1870.8721),\n",
       " ([1, (398, 48)], 1869.2386),\n",
       " ([1, (482, 48)], 1868.5414),\n",
       " ([1, (260, 48)], 1865.6833),\n",
       " ([1, (510, 48)], 1865.0183),\n",
       " ([1, (538, 48)], 1864.1943),\n",
       " ([1, (455, 48)], 1863.7479),\n",
       " ([1, (328, 48)], 1863.3245),\n",
       " ([1, (370, 48)], 1862.9279),\n",
       " ([3, (59, 6)], 1862.0586),\n",
       " ([1, (566, 48)], 1859.8015),\n",
       " ([1, (541, 48)], 1859.4207),\n",
       " ([1, (300, 48)], 1858.138),\n",
       " ([1, (569, 48)], 1855.1227),\n",
       " ([1, (344, 48)], 1853.0613),\n",
       " ([1, (342, 48)], 1849.9442),\n",
       " ([1, (357, 48)], 1849.1722),\n",
       " ([1, (594, 48)], 1845.549),\n",
       " ([1, (231, 48)], 1845.1257),\n",
       " ([1, (458, 48)], 1843.5488),\n",
       " ([1, (486, 48)], 1841.6986),\n",
       " ([1, (525, 48)], 1841.6707),\n",
       " ([1, (542, 48)], 1840.7122),\n",
       " ([1, (356, 48)], 1840.5294),\n",
       " ([1, (329, 48)], 1840.5256),\n",
       " ([1, (514, 48)], 1839.0293),\n",
       " ([1, (314, 48)], 1837.8843),\n",
       " ([1, (430, 48)], 1834.3795),\n",
       " ([1, (544, 48)], 1832.7714),\n",
       " ([3, (23, 7)], 1830.7268),\n",
       " ([1, (513, 48)], 1830.3737),\n",
       " ([1, (543, 48)], 1829.4857),\n",
       " ([1, (516, 48)], 1828.7893),\n",
       " ([1, (550, 48)], 1827.7362),\n",
       " ([1, (570, 48)], 1825.3522),\n",
       " ([1, (622, 48)], 1824.9924),\n",
       " ([1, (597, 48)], 1824.4938),\n",
       " ([1, (488, 48)], 1824.0728),\n",
       " ([1, (515, 48)], 1822.2222),\n",
       " ([1, (483, 48)], 1821.6921),\n",
       " ([1, (232, 48)], 1821.0546),\n",
       " ([1, (286, 48)], 1820.7589),\n",
       " ([1, (272, 48)], 1820.7062),\n",
       " ([1, (547, 48)], 1820.3958),\n",
       " ([1, (487, 48)], 1820.1683),\n",
       " ([3, (93, 3)], 1819.9073),\n",
       " ([1, (494, 48)], 1819.7961),\n",
       " ([1, (301, 48)], 1818.9878),\n",
       " ([1, (571, 48)], 1818.875),\n",
       " ([1, (459, 48)], 1818.6432),\n",
       " ([1, (522, 48)], 1818.4072),\n",
       " ([1, (572, 48)], 1817.9778),\n",
       " ([1, (402, 48)], 1817.0938),\n",
       " ([1, (625, 48)], 1816.9308),\n",
       " ([1, (553, 48)], 1815.505),\n",
       " ([1, (374, 48)], 1815.3046),\n",
       " ([1, (466, 48)], 1814.8123),\n",
       " ([1, (548, 48)], 1814.5942),\n",
       " ([1, (578, 48)], 1813.628),\n",
       " ([1, (460, 48)], 1811.4359),\n",
       " ([1, (545, 48)], 1810.1912),\n",
       " ([1, (519, 48)], 1810.0215),\n",
       " ([1, (575, 48)], 1809.5571),\n",
       " ([1, (485, 48)], 1807.8351),\n",
       " ([1, (576, 48)], 1806.7458),\n",
       " ([1, (431, 48)], 1806.5686),\n",
       " ([1, (573, 48)], 1806.2461),\n",
       " ([1, (517, 48)], 1806.2217),\n",
       " ([1, (520, 48)], 1806.0894),\n",
       " ([1, (273, 48)], 1805.5764),\n",
       " ([1, (491, 48)], 1804.3381),\n",
       " ([1, (492, 48)], 1804.279),\n",
       " ([1, (432, 48)], 1804.1252),\n",
       " ([1, (372, 48)], 1802.1252),\n",
       " ([1, (384, 48)], 1800.9716),\n",
       " ([1, (346, 48)], 1800.2964),\n",
       " ([1, (489, 48)], 1800.0288),\n",
       " ([1, (549, 48)], 1799.9583),\n",
       " ([1, (546, 48)], 1798.2955),\n",
       " ([1, (464, 48)], 1798.1915),\n",
       " ([1, (438, 48)], 1797.5398),\n",
       " ([1, (203, 48)], 1797.3328),\n",
       " ([1, (258, 48)], 1795.5833),\n",
       " ([1, (577, 48)], 1795.3231),\n",
       " ([1, (493, 48)], 1793.9082),\n",
       " ([1, (574, 48)], 1793.3601),\n",
       " ([1, (299, 48)], 1792.5242),\n",
       " ([1, (461, 48)], 1792.3264),\n",
       " ([1, (442, 48)], 1792.2966),\n",
       " ([1, (463, 48)], 1791.718),\n",
       " ([1, (465, 48)], 1790.5986),\n",
       " ([1, (600, 48)], 1788.7859),\n",
       " ([1, (518, 48)], 1788.6963),\n",
       " ([1, (521, 48)], 1788.4801),\n",
       " ([1, (289, 48)], 1787.9756),\n",
       " ([1, (436, 48)], 1787.8842),\n",
       " ([1, (403, 48)], 1786.7202),\n",
       " ([1, (599, 48)], 1786.5947),\n",
       " ([1, (490, 48)], 1786.4891),\n",
       " ([1, (470, 48)], 1786.438),\n",
       " ([1, (404, 48)], 1786.2117),\n",
       " ([1, (318, 48)], 1784.9009),\n",
       " ([1, (204, 48)], 1783.5856),\n",
       " ([1, (457, 48)], 1783.3687),\n",
       " ([1, (376, 48)], 1782.3057),\n",
       " ([1, (375, 48)], 1781.8533),\n",
       " ([1, (601, 48)], 1781.6111),\n",
       " ([1, (435, 48)], 1781.1863),\n",
       " ([1, (598, 48)], 1780.8925),\n",
       " ([1, (511, 48)], 1780.7109),\n",
       " ([1, (414, 48)], 1780.4121),\n",
       " ([1, (410, 48)], 1780.3052),\n",
       " ([1, (462, 48)], 1780.2261),\n",
       " ([1, (433, 48)], 1780.0107),\n",
       " ([1, (581, 48)], 1779.9073),\n",
       " ([1, (603, 48)], 1779.1333),\n",
       " ([1, (498, 48)], 1778.7599),\n",
       " ([1, (317, 48)], 1778.1127),\n",
       " ([1, (245, 48)], 1776.8843),\n",
       " ([1, (437, 48)], 1776.7455),\n",
       " ([1, (244, 48)], 1776.2064),\n",
       " ([1, (628, 48)], 1775.8862),\n",
       " ([1, (526, 48)], 1773.7692),\n",
       " ([1, (380, 48)], 1773.6573),\n",
       " ([1, (381, 48)], 1773.5398),\n",
       " ([1, (408, 48)], 1773.324),\n",
       " ([1, (271, 48)], 1773.2378),\n",
       " ([1, (627, 48)], 1773.0579),\n",
       " ([1, (606, 48)], 1772.3628),\n",
       " ([1, (554, 48)], 1771.8667),\n",
       " ([1, (604, 48)], 1770.8647),\n",
       " ([1, (409, 48)], 1770.5627),\n",
       " ([1, (602, 48)], 1770.0271),\n",
       " ([1, (261, 48)], 1769.0134),\n",
       " ([1, (382, 48)], 1768.6145),\n",
       " ([1, (434, 48)], 1768.1575),\n",
       " ([1, (327, 48)], 1766.7961),\n",
       " ([1, (582, 48)], 1766.4092),\n",
       " ([1, (650, 48)], 1766.3815),\n",
       " ([1, (626, 48)], 1764.5962),\n",
       " ([1, (631, 48)], 1764.468),\n",
       " ([1, (290, 48)], 1764.3162),\n",
       " ([1, (386, 48)], 1763.6912),\n",
       " ([1, (629, 48)], 1762.5615),\n",
       " ([1, (407, 48)], 1762.4888),\n",
       " ([1, (176, 48)], 1760.3181),\n",
       " ([1, (405, 48)], 1759.4802),\n",
       " ([1, (632, 48)], 1758.2913),\n",
       " ([1, (377, 48)], 1758.0276),\n",
       " ([1, (347, 48)], 1757.9988),\n",
       " ([1, (605, 48)], 1757.9606),\n",
       " ([1, (348, 48)], 1757.3853),\n",
       " ([1, (610, 48)], 1756.8175),\n",
       " ([1, (634, 48)], 1756.7839),\n",
       " ([1, (429, 48)], 1756.3671),\n",
       " ([1, (379, 48)], 1755.7949),\n",
       " ([1, (630, 48)], 1755.7883),\n",
       " ([1, (243, 48)], 1755.0786),\n",
       " ([1, (345, 48)], 1753.5546),\n",
       " ([1, (205, 48)], 1752.9907),\n",
       " ([1, (177, 48)], 1750.9612),\n",
       " ([1, (373, 48)], 1748.6749),\n",
       " ([1, (406, 48)], 1748.6504),\n",
       " ([1, (353, 48)], 1748.5273),\n",
       " ([1, (354, 48)], 1748.3508),\n",
       " ([1, (326, 48)], 1747.0295),\n",
       " ([1, (233, 48)], 1746.4927),\n",
       " ([1, (325, 48)], 1744.9808),\n",
       " ([1, (633, 48)], 1744.749),\n",
       " ([1, (378, 48)], 1743.1555),\n",
       " ([1, (349, 48)], 1742.9861),\n",
       " ([1, (401, 48)], 1741.9819),\n",
       " ([1, (319, 48)], 1741.4685),\n",
       " ([1, (149, 48)], 1741.4293),\n",
       " ([1, (262, 48)], 1740.7686),\n",
       " ([1, (175, 48)], 1740.2202),\n",
       " ([1, (291, 48)], 1739.7472),\n",
       " ([1, (352, 48)], 1738.7698),\n",
       " ([1, (653, 48)], 1738.5629),\n",
       " ([1, (215, 48)], 1738.4863),\n",
       " ([1, (638, 48)], 1738.009),\n",
       " ([1, (122, 48)], 1736.1913),\n",
       " ([1, (216, 48)], 1736.1637),\n",
       " ([1, (350, 48)], 1736.0247),\n",
       " ([1, (206, 48)], 1733.7607),\n",
       " ([1, (320, 48)], 1732.2377),\n",
       " ([1, (355, 48)], 1732.0715),\n",
       " ([1, (539, 48)], 1732.0573),\n",
       " ([1, (351, 48)], 1731.9756),\n",
       " ([1, (358, 48)], 1731.1263),\n",
       " ([3, (71, 0)], 1729.97),\n",
       " ([1, (230, 48)], 1729.8673),\n",
       " ([1, (412, 48)], 1729.8132),\n",
       " ([1, (298, 48)], 1729.6316),\n",
       " ([1, (178, 48)], 1729.1155),\n",
       " ([1, (217, 48)], 1728.2999),\n",
       " ([3, (1, 4)], 1725.0447),\n",
       " ([1, (579, 48)], 1724.748),\n",
       " ([1, (187, 48)], 1724.7018),\n",
       " ([1, (150, 48)], 1723.8634),\n",
       " ([1, (188, 48)], 1723.2789),\n",
       " ([1, (234, 48)], 1722.0042),\n",
       " ([1, (158, 48)], 1721.448),\n",
       " ([1, (148, 48)], 1720.2017),\n",
       " ([1, (324, 48)], 1719.8228),\n",
       " ([1, (321, 48)], 1719.0408),\n",
       " ([1, (159, 48)], 1718.9089),\n",
       " ([1, (270, 48)], 1718.8308),\n",
       " ([1, (123, 48)], 1717.9692),\n",
       " ([1, (609, 48)], 1716.7065),\n",
       " ([1, (129, 48)], 1716.3767),\n",
       " ([1, (323, 48)], 1715.7632),\n",
       " ([1, (186, 48)], 1715.4731),\n",
       " ([1, (551, 48)], 1715.2856),\n",
       " ([1, (400, 48)], 1715.0437),\n",
       " ([1, (151, 48)], 1714.2754),\n",
       " ([1, (185, 48)], 1713.8291),\n",
       " ([1, (99, 48)], 1712.6116),\n",
       " ([1, (322, 48)], 1712.269),\n",
       " ([1, (153, 48)], 1711.584),\n",
       " ([1, (157, 48)], 1711.5181),\n",
       " ([1, (295, 48)], 1709.5468),\n",
       " ([1, (214, 48)], 1708.8779),\n",
       " ([1, (96, 48)], 1708.2502),\n",
       " ([1, (297, 48)], 1708.2213),\n",
       " ([1, (95, 48)], 1707.5813),\n",
       " ([1, (127, 48)], 1706.7571),\n",
       " ([1, (292, 48)], 1706.134),\n",
       " ([1, (263, 48)], 1705.8356),\n",
       " ([1, (296, 48)], 1705.8088),\n",
       " ([1, (152, 48)], 1705.5393),\n",
       " ([1, (124, 48)], 1704.5801),\n",
       " ([1, (330, 48)], 1703.9519),\n",
       " ([1, (659, 48)], 1702.9061),\n",
       " ([1, (155, 48)], 1702.834),\n",
       " ([1, (154, 48)], 1702.6493),\n",
       " ([1, (156, 48)], 1702.2782),\n",
       " ([1, (656, 48)], 1701.411),\n",
       " ([1, (241, 48)], 1701.273),\n",
       " ([1, (125, 48)], 1700.7826),\n",
       " ([1, (607, 48)], 1700.4481),\n",
       " ([1, (383, 48)], 1700.166),\n",
       " ([1, (126, 48)], 1700.0642),\n",
       " ([1, (179, 48)], 1700.0271),\n",
       " ([1, (128, 48)], 1699.722),\n",
       " ([1, (657, 48)], 1698.8955),\n",
       " ([1, (655, 48)], 1697.629),\n",
       " ([1, (242, 48)], 1696.4893),\n",
       " ([1, (264, 48)], 1695.8436),\n",
       " ([1, (294, 48)], 1695.6309),\n",
       " ([1, (182, 48)], 1694.4324),\n",
       " ([1, (293, 48)], 1693.6925),\n",
       " ([1, (207, 48)], 1693.3772),\n",
       " ([1, (660, 48)], 1692.9126),\n",
       " ([1, (654, 48)], 1692.8533),\n",
       " ([1, (267, 48)], 1692.8223),\n",
       " ([1, (130, 48)], 1692.791),\n",
       " ([1, (235, 48)], 1691.392),\n",
       " ([1, (213, 48)], 1691.18),\n",
       " ([1, (236, 48)], 1690.7393),\n",
       " ([1, (181, 48)], 1690.3735),\n",
       " ([1, (183, 48)], 1690.2437),\n",
       " ([1, (658, 48)], 1689.8335),\n",
       " ([1, (94, 48)], 1689.5605),\n",
       " ([1, (635, 48)], 1689.1927),\n",
       " ([1, (678, 48)], 1688.612),\n",
       " ([1, (666, 48)], 1688.5051),\n",
       " ([1, (184, 48)], 1688.3318),\n",
       " ([1, (269, 48)], 1687.2456),\n",
       " ([1, (239, 48)], 1686.603),\n",
       " ([1, (662, 48)], 1686.469),\n",
       " ([1, (523, 48)], 1686.3633),\n",
       " ([1, (240, 48)], 1686.2014),\n",
       " ([1, (180, 48)], 1685.2578),\n",
       " ([1, (237, 48)], 1684.7826),\n",
       " ([1, (71, 48)], 1684.1663),\n",
       " ([1, (211, 48)], 1683.2175),\n",
       " ([1, (100, 48)], 1682.229),\n",
       " ([1, (268, 48)], 1680.8618),\n",
       " ([1, (68, 48)], 1680.7756),\n",
       " ([1, (101, 48)], 1680.5723),\n",
       " ([1, (97, 48)], 1680.276),\n",
       " ([1, (661, 48)], 1678.7319),\n",
       " ([1, (72, 48)], 1677.897),\n",
       " ([1, (266, 48)], 1674.4265),\n",
       " ([1, (238, 48)], 1673.9138),\n",
       " ([1, (212, 48)], 1673.5831),\n",
       " ([1, (121, 48)], 1672.728),\n",
       " ([1, (98, 48)], 1672.3488),\n",
       " ([1, (209, 48)], 1671.3546),\n",
       " ([1, (210, 48)], 1671.0449),\n",
       " ([1, (265, 48)], 1670.406),\n",
       " ([1, (208, 48)], 1669.5809),\n",
       " ([1, (567, 48)], 1669.5135),\n",
       " ([1, (160, 48)], 1668.4685),\n",
       " ([1, (440, 48)], 1668.2649),\n",
       " ([1, (411, 48)], 1665.1277),\n",
       " ([1, (467, 48)], 1664.5696),\n",
       " ([1, (495, 48)], 1663.186),\n",
       " ([1, (439, 48)], 1659.025),\n",
       " ([1, (637, 48)], 1652.5253),\n",
       " ([1, (428, 48)], 1651.975),\n",
       " ([1, (302, 48)], 1646.821),\n",
       " ([1, (69, 48)], 1643.626),\n",
       " ([3, (8, 4)], 1640.5754),\n",
       " ([1, (481, 48)], 1639.188),\n",
       " ([1, (147, 48)], 1638.6025),\n",
       " ([1, (509, 48)], 1637.2952),\n",
       " ([1, (189, 48)], 1634.7793),\n",
       " ([1, (202, 48)], 1632.9479),\n",
       " ([1, (663, 48)], 1628.2212),\n",
       " ([1, (67, 48)], 1626.6506),\n",
       " ([1, (453, 48)], 1625.0813),\n",
       " ([3, (40, 7)], 1623.9254),\n",
       " ([1, (565, 48)], 1622.1505),\n",
       " ([1, (537, 48)], 1620.9729),\n",
       " ([3, (70, 7)], 1618.7427),\n",
       " ([1, (694, 48)], 1617.7957),\n",
       " ([1, (468, 48)], 1616.2225),\n",
       " ([1, (425, 48)], 1613.4419),\n",
       " ([1, (706, 48)], 1611.961),\n",
       " ([1, (456, 48)], 1611.2922),\n",
       " ([1, (70, 48)], 1609.9692),\n",
       " ([1, (593, 48)], 1609.5563),\n",
       " ([1, (102, 48)], 1603.531),\n",
       " ([1, (40, 48)], 1597.5664),\n",
       " ([1, (44, 48)], 1597.1299),\n",
       " ([1, (131, 48)], 1596.0441),\n",
       " ([1, (43, 48)], 1594.1873),\n",
       " ([1, (73, 48)], 1589.3508),\n",
       " ([1, (595, 48)], 1585.0276),\n",
       " ([1, (621, 48)], 1583.8126),\n",
       " ([1, (681, 48)], 1583.583),\n",
       " ([1, (397, 48)], 1579.9038),\n",
       " ([3, (14, 4)], 1577.3097),\n",
       " ([3, (62, 7)], 1576.8689),\n",
       " ([1, (484, 48)], 1574.9188),\n",
       " ([1, (41, 48)], 1572.9966),\n",
       " ([1, (274, 48)], 1567.6404),\n",
       " ([1, (496, 48)], 1566.2507),\n",
       " ([1, (541, 76)], 1565.5448),\n",
       " ([1, (120, 48)], 1564.002),\n",
       " ([1, (665, 48)], 1562.732),\n",
       " ([1, (687, 48)], 1559.8108),\n",
       " ([1, (569, 76)], 1559.7023),\n",
       " ([1, (684, 48)], 1558.124),\n",
       " ([1, (688, 48)], 1557.8132),\n",
       " ([1, (512, 48)], 1555.6934),\n",
       " ([1, (685, 48)], 1554.7625),\n",
       " ([1, (686, 48)], 1552.8088),\n",
       " ([1, (683, 48)], 1550.019),\n",
       " ([1, (682, 48)], 1547.6318),\n",
       " ([1, (690, 48)], 1544.2185),\n",
       " ([1, (513, 76)], 1543.4248),\n",
       " ([1, (722, 48)], 1542.8068),\n",
       " ([1, (540, 48)], 1540.6213),\n",
       " ([1, (649, 48)], 1540.0369),\n",
       " ([1, (42, 48)], 1539.7567),\n",
       " ([1, (546, 76)], 1539.2761),\n",
       " ([1, (544, 76)], 1538.429),\n",
       " ([1, (545, 76)], 1537.2413),\n",
       " ([1, (689, 48)], 1535.6526),\n",
       " ([1, (547, 76)], 1535.2761),\n",
       " ([1, (369, 48)], 1534.2035),\n",
       " ([1, (543, 76)], 1532.4094),\n",
       " ([1, (548, 76)], 1529.4304),\n",
       " ([1, (66, 48)], 1528.4443),\n",
       " ([1, (549, 76)], 1528.195),\n",
       " ([1, (568, 48)], 1526.3049),\n",
       " ([1, (300, 76)], 1525.4889),\n",
       " ([1, (571, 76)], 1525.4668),\n",
       " ([1, (597, 76)], 1525.3545),\n",
       " ([1, (572, 76)], 1525.1436),\n",
       " ([1, (518, 76)], 1524.5022),\n",
       " ([1, (570, 76)], 1524.2124),\n",
       " ([1, (574, 76)], 1524.0411),\n",
       " ([1, (485, 76)], 1523.0642),\n",
       " ([1, (519, 76)], 1523.0166),\n",
       " ([1, (575, 76)], 1522.44),\n",
       " ([1, (516, 76)], 1522.3257),\n",
       " ([1, (517, 76)], 1522.3076),\n",
       " ([1, (542, 76)], 1521.645),\n",
       " ([1, (573, 76)], 1521.4502),\n",
       " ([1, (93, 48)], 1519.6741),\n",
       " ([1, (524, 48)], 1519.6238),\n",
       " ([1, (576, 76)], 1514.9408),\n",
       " ([1, (486, 76)], 1511.9622),\n",
       " ([1, (514, 76)], 1511.9124),\n",
       " ([1, (328, 76)], 1511.2542),\n",
       " ([1, (272, 76)], 1510.921),\n",
       " ([1, (623, 48)], 1510.7402),\n",
       " ([1, (520, 76)], 1510.6919),\n",
       " ([1, (462, 76)], 1510.4685),\n",
       " ([1, (522, 76)], 1509.8452),\n",
       " ([1, (577, 76)], 1508.5359),\n",
       " ([1, (521, 76)], 1507.7131),\n",
       " ([1, (515, 76)], 1507.6482),\n",
       " ([1, (491, 76)], 1506.8262),\n",
       " ([1, (490, 76)], 1504.7136),\n",
       " ([1, (550, 76)], 1504.6942),\n",
       " ([1, (489, 76)], 1502.9379),\n",
       " ([1, (596, 48)], 1502.0544),\n",
       " ([1, (487, 76)], 1500.8398),\n",
       " ([1, (522, 90)], 1500.6555),\n",
       " ([1, (457, 76)], 1499.4275),\n",
       " ([1, (463, 76)], 1499.3542),\n",
       " ([1, (599, 76)], 1498.5876),\n",
       " ([1, (601, 76)], 1498.4868),\n",
       " ([1, (494, 76)], 1498.4062),\n",
       " ([1, (602, 76)], 1497.5159),\n",
       " ([1, (488, 76)], 1497.3403),\n",
       " ([1, (578, 76)], 1496.5032),\n",
       " ([1, (600, 76)], 1496.3987),\n",
       " ([1, (299, 76)], 1496.2997),\n",
       " ([1, (327, 76)], 1495.9324),\n",
       " ([3, (27, 9)], 1493.4175),\n",
       " ([1, (598, 76)], 1493.2644),\n",
       " ([1, (493, 76)], 1492.3472),\n",
       " ([1, (603, 76)], 1491.6128),\n",
       " ([1, (174, 48)], 1491.3562),\n",
       " ([1, (461, 76)], 1490.0317),\n",
       " ([1, (356, 76)], 1488.999),\n",
       " ([1, (459, 76)], 1488.6377),\n",
       " ([1, (492, 76)], 1488.5564),\n",
       " ([1, (458, 76)], 1488.001),\n",
       " ([1, (271, 76)], 1487.888),\n",
       " ([1, (434, 76)], 1487.234),\n",
       " ([3, (66, 4)], 1486.9763),\n",
       " ([1, (460, 76)], 1486.743),\n",
       " ([1, (435, 76)], 1484.9053),\n",
       " ([1, (466, 76)], 1484.7778),\n",
       " ([1, (552, 48)], 1484.7676),\n",
       " ([1, (518, 62)], 1484.5498),\n",
       " ([1, (161, 48)], 1484.0432),\n",
       " ([1, (355, 76)], 1483.9836),\n",
       " ([1, (604, 76)], 1483.7861),\n",
       " ([1, (518, 90)], 1483.3513),\n",
       " ([1, (625, 76)], 1483.3499),\n",
       " ([1, (244, 76)], 1480.9553),\n",
       " ([1, (517, 90)], 1480.4734),\n",
       " ([1, (465, 76)], 1480.2229),\n",
       " ([1, (132, 48)], 1479.7822),\n",
       " ([1, (433, 76)], 1479.6328),\n",
       " ([1, (551, 76)], 1479.4695),\n",
       " ([1, (382, 76)], 1479.1909),\n",
       " ([1, (519, 90)], 1478.6277),\n",
       " ([1, (519, 62)], 1478.227),\n",
       " ([1, (410, 76)], 1478.1025),\n",
       " ([1, (431, 76)], 1477.9299),\n",
       " ([1, (438, 76)], 1477.8629),\n",
       " ([1, (523, 62)], 1477.3472),\n",
       " ([1, (325, 76)], 1477.1968),\n",
       " ([1, (429, 76)], 1476.0514),\n",
       " ([1, (677, 48)], 1475.931),\n",
       " ([1, (379, 76)], 1475.9142),\n",
       " ([1, (407, 76)], 1475.7498),\n",
       " ([1, (341, 48)], 1475.5771),\n",
       " ([1, (436, 76)], 1475.0533),\n",
       " ([1, (605, 76)], 1474.9867),\n",
       " ([1, (522, 62)], 1474.8438),\n",
       " ([1, (494, 90)], 1474.7544),\n",
       " ([1, (734, 48)], 1474.7131),\n",
       " ([1, (579, 76)], 1474.3456),\n",
       " ([1, (430, 76)], 1473.9382),\n",
       " ([1, (432, 76)], 1473.797),\n",
       " ([1, (297, 76)], 1473.4613),\n",
       " ([1, (406, 76)], 1472.9185),\n",
       " ([1, (624, 48)], 1472.4722),\n",
       " ([1, (437, 76)], 1471.8538),\n",
       " ([1, (464, 76)], 1471.4783),\n",
       " ([1, (523, 76)], 1471.3389),\n",
       " ([1, (521, 62)], 1470.6611),\n",
       " ([1, (606, 76)], 1470.6167),\n",
       " ([1, (288, 76)], 1470.5746),\n",
       " ([1, (517, 62)], 1470.2041),\n",
       " ([3, (55, 4)], 1470.0194),\n",
       " ([1, (354, 76)], 1469.7852),\n",
       " ([1, (353, 76)], 1469.6489),\n",
       " ([1, (381, 76)], 1468.258),\n",
       " ([1, (351, 76)], 1468.2554),\n",
       " ([1, (243, 76)], 1467.8513),\n",
       " ([1, (409, 76)], 1467.4756),\n",
       " ([1, (693, 48)], 1466.5875),\n",
       " ([1, (520, 90)], 1466.4907),\n",
       " ([1, (629, 76)], 1466.365),\n",
       " ([1, (691, 48)], 1466.268),\n",
       " ([1, (326, 76)], 1465.5106),\n",
       " ([1, (630, 76)], 1465.084),\n",
       " ([1, (494, 62)], 1465.02),\n",
       " ([1, (466, 90)], 1464.9915),\n",
       " ([1, (408, 76)], 1464.9443),\n",
       " ([1, (260, 76)], 1464.6531),\n",
       " ([1, (521, 90)], 1464.5842),\n",
       " ([1, (298, 76)], 1464.389),\n",
       " ([1, (352, 76)], 1463.6782),\n",
       " ([1, (384, 76)], 1463.0657),\n",
       " ([1, (378, 76)], 1462.8616),\n",
       " ([1, (493, 62)], 1461.8667),\n",
       " ([1, (246, 48)], 1459.9329),\n",
       " ([1, (628, 76)], 1459.342),\n",
       " ([1, (466, 62)], 1459.0245),\n",
       " ([1, (405, 76)], 1458.3794),\n",
       " ([1, (438, 90)], 1458.3193),\n",
       " ([1, (607, 76)], 1458.1813),\n",
       " ([1, (627, 76)], 1458.0769),\n",
       " ([1, (520, 62)], 1457.9724),\n",
       " ([1, (316, 76)], 1457.6628),\n",
       " ([1, (495, 62)], 1457.5952),\n",
       " ([3, (33, 9)], 1456.6974),\n",
       " ([1, (383, 76)], 1456.5),\n",
       " ([1, (580, 48)], 1456.46),\n",
       " ([1, (631, 76)], 1456.4419),\n",
       " ([1, (380, 76)], 1456.3206),\n",
       " ([1, (377, 76)], 1456.314),\n",
       " ([1, (404, 76)], 1455.771),\n",
       " ([1, (324, 76)], 1455.7612),\n",
       " ([1, (490, 62)], 1455.0472),\n",
       " ([1, (491, 62)], 1454.8741),\n",
       " ([1, (490, 90)], 1452.9082),\n",
       " ([1, (270, 76)], 1452.3005),\n",
       " ([1, (546, 90)], 1452.2625),\n",
       " ([1, (516, 90)], 1452.0574),\n",
       " ([1, (495, 76)], 1451.7219),\n",
       " ([3, (99, 7)], 1451.4498),\n",
       " ([1, (403, 76)], 1451.2046),\n",
       " ([1, (382, 62)], 1450.59),\n",
       " ([1, (626, 76)], 1450.2069),\n",
       " ([1, (545, 90)], 1449.3881),\n",
       " ([1, (232, 76)], 1448.8955),\n",
       " ([1, (462, 90)], 1448.8873),\n",
       " ([1, (438, 62)], 1448.7007),\n",
       " ([1, (39, 48)], 1448.3799),\n",
       " ([1, (402, 76)], 1448.0012),\n",
       " ([1, (269, 76)], 1447.3218),\n",
       " ([1, (491, 90)], 1446.7094),\n",
       " ([1, (410, 62)], 1446.5283),\n",
       " ([1, (410, 90)], 1446.4568),\n",
       " ([1, (462, 62)], 1446.001),\n",
       " ([1, (382, 90)], 1445.7593),\n",
       " ([1, (492, 62)], 1444.8451),\n",
       " ([1, (493, 90)], 1444.7341),\n",
       " ([1, (632, 76)], 1443.8835),\n",
       " ([1, (411, 76)], 1443.8396),\n",
       " ([1, (547, 90)], 1443.8281),\n",
       " ([1, (323, 76)], 1443.8098),\n",
       " ([1, (489, 62)], 1443.7565),\n",
       " ([1, (489, 90)], 1442.909),\n",
       " ([1, (541, 90)], 1442.5623),\n",
       " ([1, (467, 62)], 1441.2181),\n",
       " ([1, (272, 62)], 1440.8284),\n",
       " ([1, (376, 76)], 1440.5197),\n",
       " ([1, (465, 62)], 1440.3254),\n",
       " ([1, (350, 76)], 1439.9626),\n",
       " ([1, (492, 90)], 1439.5422),\n",
       " ([1, (344, 76)], 1439.338),\n",
       " ([1, (653, 76)], 1439.2902),\n",
       " ([1, (467, 76)], 1439.2583),\n",
       " ([1, (401, 76)], 1439.2021),\n",
       " ([1, (384, 90)], 1436.8644),\n",
       " ([1, (463, 62)], 1436.8207),\n",
       " ([1, (513, 90)], 1436.8076),\n",
       " ([1, (242, 76)], 1436.31),\n",
       " ([1, (515, 90)], 1436.2903),\n",
       " ([1, (349, 76)], 1435.3778),\n",
       " ([1, (463, 90)], 1434.7712),\n",
       " ([1, (657, 76)], 1433.7148),\n",
       " ([1, (544, 90)], 1433.5669),\n",
       " ([1, (523, 90)], 1433.3035),\n",
       " ([1, (296, 76)], 1433.2334),\n",
       " ([1, (300, 62)], 1432.7649),\n",
       " ([1, (295, 76)], 1432.3414),\n",
       " ([1, (543, 90)], 1431.75),\n",
       " ([1, (633, 76)], 1431.7468),\n",
       " ([1, (215, 76)], 1431.5498),\n",
       " ([1, (411, 62)], 1431.3003),\n",
       " ([1, (465, 90)], 1430.9675),\n",
       " ([1, (439, 76)], 1430.8789),\n",
       " ([1, (464, 62)], 1430.1147),\n",
       " ([1, (439, 62)], 1430.0703),\n",
       " ([1, (516, 62)], 1429.2272),\n",
       " ([1, (550, 90)], 1428.9517),\n",
       " ([1, (656, 76)], 1428.258),\n",
       " ([1, (412, 76)], 1428.1877),\n",
       " ([1, (658, 76)], 1427.7993),\n",
       " ([1, (750, 48)], 1427.6799),\n",
       " ([1, (546, 62)], 1427.4902),\n",
       " ([1, (634, 76)], 1426.5092),\n",
       " ([1, (548, 90)], 1426.2117),\n",
       " ([1, (436, 62)], 1426.0377),\n",
       " ([1, (635, 76)], 1425.7759),\n",
       " ([1, (383, 62)], 1425.7152),\n",
       " ([1, (464, 90)], 1425.3633),\n",
       " ([1, (545, 62)], 1424.5725),\n",
       " ([1, (513, 62)], 1424.3975),\n",
       " ([1, (659, 76)], 1424.2546),\n",
       " ([1, (435, 90)], 1423.9114),\n",
       " ([1, (436, 90)], 1423.8569),\n",
       " ([1, (241, 76)], 1423.5508),\n",
       " ([1, (461, 90)], 1423.0706),\n",
       " ([1, (461, 62)], 1422.9431),\n",
       " ([1, (514, 90)], 1422.7554),\n",
       " ([1, (216, 76)], 1422.5669),\n",
       " ([1, (681, 76)], 1422.52),\n",
       " ([1, (434, 90)], 1422.0812),\n",
       " ([1, (354, 62)], 1421.8448),\n",
       " ([1, (322, 76)], 1421.4424),\n",
       " ([1, (488, 90)], 1419.3569),\n",
       " ([1, (375, 76)], 1418.9973),\n",
       " ([1, (655, 76)], 1418.3215),\n",
       " ([1, (435, 62)], 1418.0964),\n",
       " ([1, (437, 62)], 1418.0028),\n",
       " ([1, (547, 62)], 1417.7871),\n",
       " ([1, (685, 76)], 1417.5436),\n",
       " ([1, (686, 76)], 1417.4978),\n",
       " ([1, (549, 90)], 1417.4509),\n",
       " ([1, (437, 90)], 1417.3531),\n",
       " ([1, (214, 76)], 1416.9951),\n",
       " ([1, (412, 90)], 1416.6514),\n",
       " ([1, (268, 76)], 1416.5933),\n",
       " ([1, (373, 76)], 1415.9386),\n",
       " ([1, (383, 90)], 1415.4253),\n",
       " ([1, (289, 76)], 1414.5105),\n",
       " ([1, (374, 76)], 1414.3591),\n",
       " ([1, (495, 90)], 1414.133),\n",
       " ([1, (204, 76)], 1413.8357),\n",
       " ([1, (356, 90)], 1413.6199),\n",
       " ([1, (408, 62)], 1413.1536),\n",
       " ([1, (488, 62)], 1412.9629),\n",
       " ([3, (19, 4)], 1412.6267),\n",
       " ([1, (327, 90)], 1412.5936),\n",
       " ([1, (684, 76)], 1412.5217),\n",
       " ([1, (355, 90)], 1412.323),\n",
       " ([1, (326, 62)], 1411.9221),\n",
       " ([1, (348, 76)], 1411.8218),\n",
       " ([1, (485, 90)], 1411.6483),\n",
       " ([1, (542, 90)], 1410.6953),\n",
       " ([1, (74, 48)], 1409.6666),\n",
       " ([1, (487, 90)], 1409.5042),\n",
       " ([1, (515, 62)], 1409.235),\n",
       " ([1, (355, 62)], 1409.0001),\n",
       " ([1, (654, 76)], 1408.8086),\n",
       " ([1, (434, 62)], 1408.2457),\n",
       " ([1, (313, 48)], 1407.9313),\n",
       " ([1, (261, 76)], 1407.7053),\n",
       " ([1, (407, 62)], 1407.7048),\n",
       " ([1, (317, 76)], 1407.1384),\n",
       " ([1, (287, 76)], 1406.9817),\n",
       " ([1, (408, 90)], 1406.57),\n",
       " ([1, (660, 76)], 1406.5581),\n",
       " ([1, (345, 76)], 1406.4706),\n",
       " ([1, (267, 76)], 1405.9539),\n",
       " ([1, (409, 62)], 1405.8861),\n",
       " ([1, (687, 76)], 1405.7783),\n",
       " ([1, (651, 48)], 1405.3313),\n",
       " ([1, (549, 62)], 1404.8217),\n",
       " ([1, (381, 62)], 1404.468),\n",
       " ([1, (468, 90)], 1404.3062),\n",
       " ([1, (354, 90)], 1403.8962),\n",
       " ([1, (259, 76)], 1403.7544),\n",
       " ([1, (294, 76)], 1403.56),\n",
       " ([1, (409, 90)], 1403.5208),\n",
       " ([1, (433, 90)], 1403.0289),\n",
       " ([1, (548, 62)], 1402.9886),\n",
       " ([1, (372, 76)], 1402.4121),\n",
       " ([1, (688, 76)], 1402.2485),\n",
       " ([1, (440, 90)], 1402.0277),\n",
       " ([1, (381, 90)], 1402.0082),\n",
       " ([1, (661, 76)], 1401.881),\n",
       " ([1, (467, 90)], 1401.835),\n",
       " ([1, (321, 76)], 1401.3752),\n",
       " ([1, (315, 76)], 1401.3749),\n",
       " ([1, (683, 76)], 1401.1602),\n",
       " ([1, (411, 90)], 1400.8816),\n",
       " ([1, (544, 62)], 1400.4485),\n",
       " ([1, (487, 62)], 1400.3674),\n",
       " ([1, (353, 62)], 1400.0137),\n",
       " ([1, (299, 90)], 1399.7524),\n",
       " ([1, (439, 90)], 1399.2194),\n",
       " ([1, (119, 48)], 1399.0284),\n",
       " ([1, (407, 90)], 1398.3762),\n",
       " ([1, (608, 48)], 1398.2166),\n",
       " ([1, (233, 76)], 1397.6646),\n",
       " ([1, (486, 90)], 1397.621),\n",
       " ([1, (514, 62)], 1397.2673),\n",
       " ([1, (541, 62)], 1396.6046),\n",
       " ([1, (347, 76)], 1395.7947),\n",
       " ([1, (689, 76)], 1395.0797),\n",
       " ([1, (231, 76)], 1394.7981),\n",
       " ([1, (540, 76)], 1394.5483),\n",
       " ([1, (353, 90)], 1394.5148),\n",
       " ([1, (326, 90)], 1394.3629),\n",
       " ([1, (682, 76)], 1394.2266),\n",
       " ([1, (568, 76)], 1394.2034),\n",
       " ([1, (380, 90)], 1393.4873),\n",
       " ([1, (485, 62)], 1393.4233),\n",
       " ([1, (328, 90)], 1393.19),\n",
       " ([1, (187, 76)], 1392.7136),\n",
       " ([1, (551, 62)], 1392.6884),\n",
       " ([1, (379, 90)], 1392.6565),\n",
       " ([1, (705, 48)], 1392.5645),\n",
       " ([1, (325, 62)], 1392.5089),\n",
       " ([1, (325, 90)], 1392.2396),\n",
       " ([1, (244, 62)], 1392.0459),\n",
       " ([1, (320, 76)], 1391.6313),\n",
       " ([1, (240, 76)], 1391.5995),\n",
       " ([1, (346, 76)], 1391.4988),\n",
       " ([1, (440, 76)], 1391.0138),\n",
       " ([1, (460, 90)], 1390.2162),\n",
       " ([1, (652, 48)], 1390.0867),\n",
       " ([1, (524, 90)], 1389.8531),\n",
       " ([1, (543, 62)], 1389.254),\n",
       " ([1, (406, 90)], 1389.2441),\n",
       " ([3, (66, 6)], 1388.5654),\n",
       " ([1, (298, 62)], 1388.3992),\n",
       " ([3, (42, 9)], 1387.3315),\n",
       " ([1, (406, 62)], 1387.1616),\n",
       " ([1, (496, 90)], 1386.7644),\n",
       " ([1, (328, 62)], 1386.4539),\n",
       " ([1, (663, 76)], 1386.084),\n",
       " ([1, (266, 76)], 1385.0017),\n",
       " ([1, (380, 62)], 1384.2871),\n",
       " ([1, (318, 76)], 1383.1321),\n",
       " ([1, (327, 62)], 1382.9827),\n",
       " ([1, (213, 76)], 1382.9363),\n",
       " ([1, (352, 62)], 1382.7687),\n",
       " ([1, (459, 90)], 1382.6819),\n",
       " ([1, (352, 90)], 1382.5791),\n",
       " ([1, (290, 76)], 1382.4188),\n",
       " ([1, (379, 62)], 1382.3184),\n",
       " ([1, (433, 62)], 1381.982),\n",
       " ([1, (273, 62)], 1381.8817),\n",
       " ([1, (460, 62)], 1380.4537),\n",
       " ([1, (690, 76)], 1380.0017),\n",
       " ([1, (324, 62)], 1379.8171),\n",
       " ([1, (550, 62)], 1379.3477),\n",
       " ([1, (596, 76)], 1379.0684),\n",
       " ([1, (662, 76)], 1379.0051),\n",
       " ([1, (512, 76)], 1378.6816),\n",
       " ([1, (239, 76)], 1378.3344),\n",
       " ([1, (186, 76)], 1377.459),\n",
       " ([1, (262, 76)], 1377.1854),\n",
       " ([1, (205, 76)], 1376.6501),\n",
       " ([1, (176, 76)], 1376.343),\n",
       " ([1, (569, 90)], 1375.2299),\n",
       " ([1, (484, 76)], 1374.4905),\n",
       " ([1, (486, 62)], 1374.3696),\n",
       " ([1, (324, 90)], 1374.179),\n",
       " ([1, (691, 76)], 1373.996),\n",
       " ([1, (292, 76)], 1373.6001),\n",
       " ([1, (319, 76)], 1373.5967),\n",
       " ([1, (378, 90)], 1373.5476),\n",
       " ([1, (271, 90)], 1373.2457),\n",
       " ([1, (468, 76)], 1373.1605),\n",
       " ([1, (400, 76)], 1373.0566),\n",
       " ([1, (293, 76)], 1372.922),\n",
       " ([1, (573, 90)], 1372.0659),\n",
       " ([1, (456, 76)], 1370.9661),\n",
       " ([1, (297, 62)], 1370.8806),\n",
       " ([1, (103, 48)], 1370.814),\n",
       " ([1, (291, 76)], 1369.7815),\n",
       " ([1, (351, 90)], 1369.263),\n",
       " ([1, (299, 62)], 1368.5521),\n",
       " ([1, (300, 90)], 1368.5498),\n",
       " ([1, (551, 90)], 1368.3804),\n",
       " ([1, (574, 90)], 1368.1106),\n",
       " ([1, (428, 76)], 1367.5052),\n",
       " ([1, (264, 76)], 1366.986),\n",
       " ([1, (457, 90)], 1366.1301),\n",
       " ([1, (265, 76)], 1366.0818),\n",
       " ([1, (301, 62)], 1365.8296),\n",
       " ([1, (542, 62)], 1364.0542),\n",
       " ([1, (458, 90)], 1363.9414),\n",
       " ([1, (234, 76)], 1363.1042),\n",
       " ([1, (203, 76)], 1362.873),\n",
       " ([1, (263, 76)], 1362.3687),\n",
       " ([1, (149, 76)], 1362.241),\n",
       " ([1, (298, 90)], 1362.032),\n",
       " ([1, (271, 62)], 1361.9609),\n",
       " ([1, (343, 76)], 1361.8713),\n",
       " ([1, (351, 62)], 1361.4523),\n",
       " ([1, (459, 62)], 1360.7778),\n",
       " ([1, (238, 76)], 1359.812),\n",
       " ([1, (457, 62)], 1358.5078),\n",
       " ([1, (624, 76)], 1358.3059),\n",
       " ([1, (177, 76)], 1358.2799),\n",
       " ([1, (378, 62)], 1358.1799),\n",
       " ([1, (572, 90)], 1358.1512),\n",
       " ([3, (46, 9)], 1357.1923),\n",
       " ([1, (212, 76)], 1357.1787),\n",
       " ([1, (432, 90)], 1356.8665),\n",
       " ([1, (297, 90)], 1356.4811),\n",
       " ([1, (188, 76)], 1355.6147),\n",
       " ([1, (571, 90)], 1355.1489),\n",
       " ([1, (185, 76)], 1355.1274),\n",
       " ([1, (405, 90)], 1354.5753),\n",
       " ([1, (570, 90)], 1353.3619),\n",
       " ([1, (210, 76)], 1353.0852),\n",
       " ([1, (511, 76)], 1352.7844),\n",
       " ([1, (211, 76)], 1352.7711),\n",
       " ([1, (525, 90)], 1351.8022),\n",
       " ([1, (158, 76)], 1351.5754),\n",
       " ([1, (182, 76)], 1351.0483),\n",
       " ([1, (575, 90)], 1351.0244),\n",
       " ([1, (483, 76)], 1350.9082),\n",
       " ([1, (496, 76)], 1350.5012),\n",
       " ([1, (206, 76)], 1350.175),\n",
       " ([1, (159, 76)], 1349.3746),\n",
       " ([1, (583, 48)], 1349.1455),\n",
       " ([1, (45, 48)], 1348.6068),\n",
       " ([1, (235, 76)], 1348.324),\n",
       " ([1, (178, 76)], 1347.4767),\n",
       " ([1, (721, 48)], 1346.9192),\n",
       " ([1, (150, 76)], 1345.9829),\n",
       " ([1, (243, 62)], 1345.8542),\n",
       " ([1, (236, 76)], 1345.8132),\n",
       " ([1, (329, 62)], 1344.7507),\n",
       " ([1, (237, 76)], 1344.2031),\n",
       " ([1, (455, 76)], 1343.8293),\n",
       " ([1, (524, 76)], 1343.1838),\n",
       " ([1, (431, 90)], 1342.8875),\n",
       " ([1, (611, 48)], 1342.4392),\n",
       " ([1, (209, 76)], 1342.1428),\n",
       " ([1, (148, 76)], 1341.4453),\n",
       " ([1, (377, 90)], 1341.4055),\n",
       " ([1, (273, 76)], 1341.3242),\n",
       " ([1, (154, 76)], 1340.8542),\n",
       " ([1, (323, 90)], 1340.5557),\n",
       " ([1, (555, 48)], 1340.3208),\n",
       " ([1, (713, 76)], 1339.9889),\n",
       " ([1, (469, 90)], 1339.9615),\n",
       " ([1, (458, 62)], 1339.8522),\n",
       " ([1, (270, 62)], 1339.554),\n",
       " ([1, (578, 90)], 1339.4907),\n",
       " ([1, (207, 76)], 1339.2052),\n",
       " ([1, (539, 76)], 1338.8135),\n",
       " ([1, (153, 76)], 1338.1494),\n",
       " ([1, (497, 90)], 1338.0317),\n",
       " ([1, (714, 76)], 1337.9128),\n",
       " ([1, (709, 76)], 1337.8501),\n",
       " ([1, (181, 76)], 1337.2952),\n",
       " ([1, (576, 90)], 1337.2451),\n",
       " ([1, (126, 76)], 1336.7173),\n",
       " ([1, (512, 90)], 1336.415),\n",
       " ([1, (511, 90)], 1335.6661),\n",
       " ([1, (636, 48)], 1335.3511),\n",
       " ([1, (712, 76)], 1334.9236),\n",
       " ([1, (296, 90)], 1334.481),\n",
       " ([1, (301, 76)], 1334.406),\n",
       " ([1, (124, 76)], 1334.3657),\n",
       " ([1, (208, 76)], 1334.363),\n",
       " ([1, (179, 76)], 1332.9348),\n",
       " ([1, (552, 76)], 1332.8776),\n",
       " ([1, (405, 62)], 1332.2625),\n",
       " ([1, (183, 76)], 1331.6853),\n",
       " ([1, (285, 48)], 1331.523),\n",
       " ([1, (527, 48)], 1331.206),\n",
       " ([1, (184, 76)], 1330.7446),\n",
       " ([1, (157, 76)], 1330.6643),\n",
       " ([1, (243, 90)], 1329.51),\n",
       " ([1, (125, 76)], 1329.034),\n",
       " ([1, (569, 62)], 1328.5195),\n",
       " ([1, (432, 62)], 1328.5037),\n",
       " ([1, (441, 90)], 1328.3164),\n",
       " ([1, (577, 90)], 1328.2355),\n",
       " ([1, (427, 76)], 1327.8403),\n",
       " ([1, (127, 76)], 1327.4553),\n",
       " ([1, (270, 90)], 1327.2279),\n",
       " ([1, (639, 48)], 1327.0582),\n",
       " ([1, (323, 62)], 1326.905),\n",
       " ([1, (296, 62)], 1326.7086),\n",
       " ([1, (413, 90)], 1326.5608),\n",
       " ([1, (152, 76)], 1326.4342),\n",
       " ([1, (371, 76)], 1326.3391),\n",
       " ([1, (350, 90)], 1326.0542),\n",
       " ([1, (245, 76)], 1326.0444),\n",
       " ([1, (715, 76)], 1325.6204),\n",
       " ([1, (597, 90)], 1325.4723),\n",
       " ([1, (540, 90)], 1325.0642),\n",
       " ([1, (272, 90)], 1324.7888),\n",
       " ([1, (155, 76)], 1324.266),\n",
       " ([1, (68, 76)], 1324.1194),\n",
       " ([1, (711, 76)], 1324.0808),\n",
       " ([1, (180, 76)], 1323.9194),\n",
       " ([1, (385, 90)], 1323.1572),\n",
       " ([1, (356, 62)], 1322.8802),\n",
       " ([1, (242, 62)], 1322.8684),\n",
       " ([1, (430, 90)], 1322.4585),\n",
       " ([1, (652, 76)], 1322.3145),\n",
       " ([1, (40, 76)], 1322.0238),\n",
       " ([1, (121, 76)], 1321.8525),\n",
       " ([1, (404, 90)], 1321.7346),\n",
       " ([1, (269, 62)], 1321.5287),\n",
       " ([1, (329, 76)], 1320.6002),\n",
       " ([1, (71, 76)], 1320.4141),\n",
       " ([1, (156, 76)], 1319.9579),\n",
       " ([1, (483, 90)], 1319.9072),\n",
       " ([1, (710, 76)], 1319.715),\n",
       " ([1, (601, 90)], 1319.6799),\n",
       " ([1, (574, 62)], 1318.3914),\n",
       " ([1, (151, 76)], 1318.1772),\n",
       " ([1, (245, 62)], 1318.1523),\n",
       " ([1, (175, 76)], 1318.1227),\n",
       " ([1, (96, 76)], 1317.9316),\n",
       " ([1, (716, 76)], 1317.5326),\n",
       " ([1, (218, 48)], 1316.7578),\n",
       " ([1, (499, 48)], 1315.9521),\n",
       " ([1, (573, 62)], 1315.7687),\n",
       " ([1, (99, 76)], 1314.4813),\n",
       " ([1, (399, 76)], 1313.6089),\n",
       " ([1, (120, 76)], 1310.9246),\n",
       " ([1, (575, 62)], 1310.6453),\n",
       " ([1, (602, 90)], 1309.7175),\n",
       " ([1, (122, 76)], 1309.562),\n",
       " ([1, (718, 76)], 1309.4131),\n",
       " ([1, (269, 90)], 1308.5667),\n",
       " ([1, (484, 90)], 1308.4065),\n",
       " ([1, (431, 62)], 1308.1907),\n",
       " ([1, (717, 76)], 1307.3365),\n",
       " ([1, (123, 76)], 1307.2749),\n",
       " ([1, (95, 76)], 1305.3784),\n",
       " ([1, (680, 76)], 1304.9775),\n",
       " ([1, (552, 90)], 1304.821),\n",
       " ([1, (567, 76)], 1304.779),\n",
       " ([1, (131, 76)], 1304.582),\n",
       " ([1, (242, 90)], 1304.3303),\n",
       " ([1, (130, 76)], 1304.25),\n",
       " ([1, (600, 90)], 1304.2261),\n",
       " ([1, (128, 76)], 1304.0042),\n",
       " ([1, (599, 90)], 1303.5559),\n",
       " ([1, (97, 76)], 1301.2482),\n",
       " ([1, (572, 62)], 1300.3335),\n",
       " ([1, (598, 90)], 1299.8568),\n",
       " ([3, (25, 6)], 1298.9314),\n",
       " ([1, (160, 76)], 1298.2739),\n",
       " ([1, (709, 48)], 1297.4832),\n",
       " ([1, (580, 76)], 1296.4795),\n",
       " ([1, (384, 62)], 1296.4617),\n",
       " ([1, (350, 62)], 1296.4202),\n",
       " ([1, (43, 76)], 1296.4192),\n",
       " ([1, (579, 90)], 1296.1576),\n",
       " ([1, (576, 62)], 1296.107),\n",
       " ([1, (129, 76)], 1295.6301),\n",
       " ([1, (404, 62)], 1295.543),\n",
       " ([1, (98, 76)], 1295.4829),\n",
       " ([1, (577, 62)], 1295.3374),\n",
       " ([1, (67, 76)], 1294.9375),\n",
       " ([1, (539, 90)], 1294.459),\n",
       " ([1, (94, 76)], 1294.0339),\n",
       " ([1, (571, 62)], 1293.5287),\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/rq1/all_layers/simple_fm/random/loc.all_cost.loc.0.1.random.pkl\", 'rb') as f:\n",
    "    random_locs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (0, 0)),\n",
       " (1, (0, 1)),\n",
       " (1, (0, 2)),\n",
       " (1, (0, 3)),\n",
       " (1, (0, 4)),\n",
       " (1, (0, 5)),\n",
       " (1, (0, 6)),\n",
       " (1, (0, 7)),\n",
       " (1, (0, 8)),\n",
       " (1, (0, 9)),\n",
       " (1, (0, 10)),\n",
       " (1, (0, 11)),\n",
       " (1, (0, 12)),\n",
       " (1, (0, 13)),\n",
       " (1, (0, 14)),\n",
       " (1, (0, 15)),\n",
       " (1, (0, 16)),\n",
       " (1, (0, 17)),\n",
       " (1, (0, 18)),\n",
       " (1, (0, 19)),\n",
       " (1, (0, 20)),\n",
       " (1, (0, 21)),\n",
       " (1, (0, 22)),\n",
       " (1, (0, 23)),\n",
       " (1, (0, 24)),\n",
       " (1, (0, 25)),\n",
       " (1, (0, 26)),\n",
       " (1, (0, 27)),\n",
       " (1, (0, 28)),\n",
       " (1, (0, 29)),\n",
       " (1, (0, 30)),\n",
       " (1, (0, 31)),\n",
       " (1, (0, 32)),\n",
       " (1, (0, 33)),\n",
       " (1, (0, 34)),\n",
       " (1, (0, 35)),\n",
       " (1, (0, 36)),\n",
       " (1, (0, 37)),\n",
       " (1, (0, 38)),\n",
       " (1, (0, 39)),\n",
       " (1, (0, 40)),\n",
       " (1, (0, 41)),\n",
       " (1, (0, 42)),\n",
       " (1, (0, 43)),\n",
       " (1, (0, 44)),\n",
       " (1, (0, 45)),\n",
       " (1, (0, 46)),\n",
       " (1, (0, 47)),\n",
       " (1, (0, 48)),\n",
       " (1, (0, 49)),\n",
       " (1, (0, 50)),\n",
       " (1, (0, 51)),\n",
       " (1, (0, 52)),\n",
       " (1, (0, 53)),\n",
       " (1, (0, 54)),\n",
       " (1, (0, 55)),\n",
       " (1, (0, 56)),\n",
       " (1, (0, 57)),\n",
       " (1, (0, 58)),\n",
       " (1, (0, 59)),\n",
       " (1, (0, 60)),\n",
       " (1, (0, 61)),\n",
       " (1, (0, 62)),\n",
       " (1, (0, 63)),\n",
       " (1, (0, 64)),\n",
       " (1, (0, 65)),\n",
       " (1, (0, 66)),\n",
       " (1, (0, 67)),\n",
       " (1, (0, 68)),\n",
       " (1, (0, 69)),\n",
       " (1, (0, 70)),\n",
       " (1, (0, 71)),\n",
       " (1, (0, 72)),\n",
       " (1, (0, 73)),\n",
       " (1, (0, 74)),\n",
       " (1, (0, 75)),\n",
       " (1, (0, 76)),\n",
       " (1, (0, 77)),\n",
       " (1, (0, 78)),\n",
       " (1, (0, 79)),\n",
       " (1, (0, 80)),\n",
       " (1, (0, 81)),\n",
       " (1, (0, 82)),\n",
       " (1, (0, 83)),\n",
       " (1, (0, 84)),\n",
       " (1, (0, 85)),\n",
       " (1, (0, 86)),\n",
       " (1, (0, 87)),\n",
       " (1, (0, 88)),\n",
       " (1, (0, 89)),\n",
       " (1, (0, 90)),\n",
       " (1, (0, 91)),\n",
       " (1, (0, 92)),\n",
       " (1, (0, 93)),\n",
       " (1, (0, 94)),\n",
       " (1, (0, 95)),\n",
       " (1, (0, 96)),\n",
       " (1, (0, 97)),\n",
       " (1, (0, 98)),\n",
       " (1, (0, 99)),\n",
       " (1, (1, 0)),\n",
       " (1, (1, 1)),\n",
       " (1, (1, 2)),\n",
       " (1, (1, 3)),\n",
       " (1, (1, 4)),\n",
       " (1, (1, 5)),\n",
       " (1, (1, 6)),\n",
       " (1, (1, 7)),\n",
       " (1, (1, 8)),\n",
       " (1, (1, 9)),\n",
       " (1, (1, 10)),\n",
       " (1, (1, 11)),\n",
       " (1, (1, 12)),\n",
       " (1, (1, 13)),\n",
       " (1, (1, 14)),\n",
       " (1, (1, 15)),\n",
       " (1, (1, 16)),\n",
       " (1, (1, 17)),\n",
       " (1, (1, 18)),\n",
       " (1, (1, 19)),\n",
       " (1, (1, 20)),\n",
       " (1, (1, 21)),\n",
       " (1, (1, 22)),\n",
       " (1, (1, 23)),\n",
       " (1, (1, 24)),\n",
       " (1, (1, 25)),\n",
       " (1, (1, 26)),\n",
       " (1, (1, 27)),\n",
       " (1, (1, 28)),\n",
       " (1, (1, 29)),\n",
       " (1, (1, 30)),\n",
       " (1, (1, 31)),\n",
       " (1, (1, 32)),\n",
       " (1, (1, 33)),\n",
       " (1, (1, 34)),\n",
       " (1, (1, 35)),\n",
       " (1, (1, 36)),\n",
       " (1, (1, 37)),\n",
       " (1, (1, 38)),\n",
       " (1, (1, 39)),\n",
       " (1, (1, 40)),\n",
       " (1, (1, 41)),\n",
       " (1, (1, 42)),\n",
       " (1, (1, 43)),\n",
       " (1, (1, 44)),\n",
       " (1, (1, 45)),\n",
       " (1, (1, 46)),\n",
       " (1, (1, 47)),\n",
       " (1, (1, 48)),\n",
       " (1, (1, 49)),\n",
       " (1, (1, 50)),\n",
       " (1, (1, 51)),\n",
       " (1, (1, 52)),\n",
       " (1, (1, 53)),\n",
       " (1, (1, 54)),\n",
       " (1, (1, 55)),\n",
       " (1, (1, 56)),\n",
       " (1, (1, 57)),\n",
       " (1, (1, 58)),\n",
       " (1, (1, 59)),\n",
       " (1, (1, 60)),\n",
       " (1, (1, 61)),\n",
       " (1, (1, 62)),\n",
       " (1, (1, 63)),\n",
       " (1, (1, 64)),\n",
       " (1, (1, 65)),\n",
       " (1, (1, 66)),\n",
       " (1, (1, 67)),\n",
       " (1, (1, 68)),\n",
       " (1, (1, 69)),\n",
       " (1, (1, 70)),\n",
       " (1, (1, 71)),\n",
       " (1, (1, 72)),\n",
       " (1, (1, 73)),\n",
       " (1, (1, 74)),\n",
       " (1, (1, 75)),\n",
       " (1, (1, 76)),\n",
       " (1, (1, 77)),\n",
       " (1, (1, 78)),\n",
       " (1, (1, 79)),\n",
       " (1, (1, 80)),\n",
       " (1, (1, 81)),\n",
       " (1, (1, 82)),\n",
       " (1, (1, 83)),\n",
       " (1, (1, 84)),\n",
       " (1, (1, 85)),\n",
       " (1, (1, 86)),\n",
       " (1, (1, 87)),\n",
       " (1, (1, 88)),\n",
       " (1, (1, 89)),\n",
       " (1, (1, 90)),\n",
       " (1, (1, 91)),\n",
       " (1, (1, 92)),\n",
       " (1, (1, 93)),\n",
       " (1, (1, 94)),\n",
       " (1, (1, 95)),\n",
       " (1, (1, 96)),\n",
       " (1, (1, 97)),\n",
       " (1, (1, 98)),\n",
       " (1, (1, 99)),\n",
       " (1, (2, 0)),\n",
       " (1, (2, 1)),\n",
       " (1, (2, 2)),\n",
       " (1, (2, 3)),\n",
       " (1, (2, 4)),\n",
       " (1, (2, 5)),\n",
       " (1, (2, 6)),\n",
       " (1, (2, 7)),\n",
       " (1, (2, 8)),\n",
       " (1, (2, 9)),\n",
       " (1, (2, 10)),\n",
       " (1, (2, 11)),\n",
       " (1, (2, 12)),\n",
       " (1, (2, 13)),\n",
       " (1, (2, 14)),\n",
       " (1, (2, 15)),\n",
       " (1, (2, 16)),\n",
       " (1, (2, 17)),\n",
       " (1, (2, 18)),\n",
       " (1, (2, 19)),\n",
       " (1, (2, 20)),\n",
       " (1, (2, 21)),\n",
       " (1, (2, 22)),\n",
       " (1, (2, 23)),\n",
       " (1, (2, 24)),\n",
       " (1, (2, 25)),\n",
       " (1, (2, 26)),\n",
       " (1, (2, 27)),\n",
       " (1, (2, 28)),\n",
       " (1, (2, 29)),\n",
       " (1, (2, 30)),\n",
       " (1, (2, 31)),\n",
       " (1, (2, 32)),\n",
       " (1, (2, 33)),\n",
       " (1, (2, 34)),\n",
       " (1, (2, 35)),\n",
       " (1, (2, 36)),\n",
       " (1, (2, 37)),\n",
       " (1, (2, 38)),\n",
       " (1, (2, 39)),\n",
       " (1, (2, 40)),\n",
       " (1, (2, 41)),\n",
       " (1, (2, 42)),\n",
       " (1, (2, 43)),\n",
       " (1, (2, 44)),\n",
       " (1, (2, 45)),\n",
       " (1, (2, 46)),\n",
       " (1, (2, 47)),\n",
       " (1, (2, 48)),\n",
       " (1, (2, 49)),\n",
       " (1, (2, 50)),\n",
       " (1, (2, 51)),\n",
       " (1, (2, 52)),\n",
       " (1, (2, 53)),\n",
       " (1, (2, 54)),\n",
       " (1, (2, 55)),\n",
       " (1, (2, 56)),\n",
       " (1, (2, 57)),\n",
       " (1, (2, 58)),\n",
       " (1, (2, 59)),\n",
       " (1, (2, 60)),\n",
       " (1, (2, 61)),\n",
       " (1, (2, 62)),\n",
       " (1, (2, 63)),\n",
       " (1, (2, 64)),\n",
       " (1, (2, 65)),\n",
       " (1, (2, 66)),\n",
       " (1, (2, 67)),\n",
       " (1, (2, 68)),\n",
       " (1, (2, 69)),\n",
       " (1, (2, 70)),\n",
       " (1, (2, 71)),\n",
       " (1, (2, 72)),\n",
       " (1, (2, 73)),\n",
       " (1, (2, 74)),\n",
       " (1, (2, 75)),\n",
       " (1, (2, 76)),\n",
       " (1, (2, 77)),\n",
       " (1, (2, 78)),\n",
       " (1, (2, 79)),\n",
       " (1, (2, 80)),\n",
       " (1, (2, 81)),\n",
       " (1, (2, 82)),\n",
       " (1, (2, 83)),\n",
       " (1, (2, 84)),\n",
       " (1, (2, 85)),\n",
       " (1, (2, 86)),\n",
       " (1, (2, 87)),\n",
       " (1, (2, 88)),\n",
       " (1, (2, 89)),\n",
       " (1, (2, 90)),\n",
       " (1, (2, 91)),\n",
       " (1, (2, 92)),\n",
       " (1, (2, 93)),\n",
       " (1, (2, 94)),\n",
       " (1, (2, 95)),\n",
       " (1, (2, 96)),\n",
       " (1, (2, 97)),\n",
       " (1, (2, 98)),\n",
       " (1, (2, 99)),\n",
       " (1, (3, 0)),\n",
       " (1, (3, 1)),\n",
       " (1, (3, 2)),\n",
       " (1, (3, 3)),\n",
       " (1, (3, 4)),\n",
       " (1, (3, 5)),\n",
       " (1, (3, 6)),\n",
       " (1, (3, 7)),\n",
       " (1, (3, 8)),\n",
       " (1, (3, 9)),\n",
       " (1, (3, 10)),\n",
       " (1, (3, 11)),\n",
       " (1, (3, 12)),\n",
       " (1, (3, 13)),\n",
       " (1, (3, 14)),\n",
       " (1, (3, 15)),\n",
       " (1, (3, 16)),\n",
       " (1, (3, 17)),\n",
       " (1, (3, 18)),\n",
       " (1, (3, 19)),\n",
       " (1, (3, 20)),\n",
       " (1, (3, 21)),\n",
       " (1, (3, 22)),\n",
       " (1, (3, 23)),\n",
       " (1, (3, 24)),\n",
       " (1, (3, 25)),\n",
       " (1, (3, 26)),\n",
       " (1, (3, 27)),\n",
       " (1, (3, 28)),\n",
       " (1, (3, 29)),\n",
       " (1, (3, 30)),\n",
       " (1, (3, 31)),\n",
       " (1, (3, 32)),\n",
       " (1, (3, 33)),\n",
       " (1, (3, 34)),\n",
       " (1, (3, 35)),\n",
       " (1, (3, 36)),\n",
       " (1, (3, 37)),\n",
       " (1, (3, 38)),\n",
       " (1, (3, 39)),\n",
       " (1, (3, 40)),\n",
       " (1, (3, 41)),\n",
       " (1, (3, 42)),\n",
       " (1, (3, 43)),\n",
       " (1, (3, 44)),\n",
       " (1, (3, 45)),\n",
       " (1, (3, 46)),\n",
       " (1, (3, 47)),\n",
       " (1, (3, 48)),\n",
       " (1, (3, 49)),\n",
       " (1, (3, 50)),\n",
       " (1, (3, 51)),\n",
       " (1, (3, 52)),\n",
       " (1, (3, 53)),\n",
       " (1, (3, 54)),\n",
       " (1, (3, 55)),\n",
       " (1, (3, 56)),\n",
       " (1, (3, 57)),\n",
       " (1, (3, 58)),\n",
       " (1, (3, 59)),\n",
       " (1, (3, 60)),\n",
       " (1, (3, 61)),\n",
       " (1, (3, 62)),\n",
       " (1, (3, 63)),\n",
       " (1, (3, 64)),\n",
       " (1, (3, 65)),\n",
       " (1, (3, 66)),\n",
       " (1, (3, 67)),\n",
       " (1, (3, 68)),\n",
       " (1, (3, 69)),\n",
       " (1, (3, 70)),\n",
       " (1, (3, 71)),\n",
       " (1, (3, 72)),\n",
       " (1, (3, 73)),\n",
       " (1, (3, 74)),\n",
       " (1, (3, 75)),\n",
       " (1, (3, 76)),\n",
       " (1, (3, 77)),\n",
       " (1, (3, 78)),\n",
       " (1, (3, 79)),\n",
       " (1, (3, 80)),\n",
       " (1, (3, 81)),\n",
       " (1, (3, 82)),\n",
       " (1, (3, 83)),\n",
       " (1, (3, 84)),\n",
       " (1, (3, 85)),\n",
       " (1, (3, 86)),\n",
       " (1, (3, 87)),\n",
       " (1, (3, 88)),\n",
       " (1, (3, 89)),\n",
       " (1, (3, 90)),\n",
       " (1, (3, 91)),\n",
       " (1, (3, 92)),\n",
       " (1, (3, 93)),\n",
       " (1, (3, 94)),\n",
       " (1, (3, 95)),\n",
       " (1, (3, 96)),\n",
       " (1, (3, 97)),\n",
       " (1, (3, 98)),\n",
       " (1, (3, 99)),\n",
       " (1, (4, 0)),\n",
       " (1, (4, 1)),\n",
       " (1, (4, 2)),\n",
       " (1, (4, 3)),\n",
       " (1, (4, 4)),\n",
       " (1, (4, 5)),\n",
       " (1, (4, 6)),\n",
       " (1, (4, 7)),\n",
       " (1, (4, 8)),\n",
       " (1, (4, 9)),\n",
       " (1, (4, 10)),\n",
       " (1, (4, 11)),\n",
       " (1, (4, 12)),\n",
       " (1, (4, 13)),\n",
       " (1, (4, 14)),\n",
       " (1, (4, 15)),\n",
       " (1, (4, 16)),\n",
       " (1, (4, 17)),\n",
       " (1, (4, 18)),\n",
       " (1, (4, 19)),\n",
       " (1, (4, 20)),\n",
       " (1, (4, 21)),\n",
       " (1, (4, 22)),\n",
       " (1, (4, 23)),\n",
       " (1, (4, 24)),\n",
       " (1, (4, 25)),\n",
       " (1, (4, 26)),\n",
       " (1, (4, 27)),\n",
       " (1, (4, 28)),\n",
       " (1, (4, 29)),\n",
       " (1, (4, 30)),\n",
       " (1, (4, 31)),\n",
       " (1, (4, 32)),\n",
       " (1, (4, 33)),\n",
       " (1, (4, 34)),\n",
       " (1, (4, 35)),\n",
       " (1, (4, 36)),\n",
       " (1, (4, 37)),\n",
       " (1, (4, 38)),\n",
       " (1, (4, 39)),\n",
       " (1, (4, 40)),\n",
       " (1, (4, 41)),\n",
       " (1, (4, 42)),\n",
       " (1, (4, 43)),\n",
       " (1, (4, 44)),\n",
       " (1, (4, 45)),\n",
       " (1, (4, 46)),\n",
       " (1, (4, 47)),\n",
       " (1, (4, 48)),\n",
       " (1, (4, 49)),\n",
       " (1, (4, 50)),\n",
       " (1, (4, 51)),\n",
       " (1, (4, 52)),\n",
       " (1, (4, 53)),\n",
       " (1, (4, 54)),\n",
       " (1, (4, 55)),\n",
       " (1, (4, 56)),\n",
       " (1, (4, 57)),\n",
       " (1, (4, 58)),\n",
       " (1, (4, 59)),\n",
       " (1, (4, 60)),\n",
       " (1, (4, 61)),\n",
       " (1, (4, 62)),\n",
       " (1, (4, 63)),\n",
       " (1, (4, 64)),\n",
       " (1, (4, 65)),\n",
       " (1, (4, 66)),\n",
       " (1, (4, 67)),\n",
       " (1, (4, 68)),\n",
       " (1, (4, 69)),\n",
       " (1, (4, 70)),\n",
       " (1, (4, 71)),\n",
       " (1, (4, 72)),\n",
       " (1, (4, 73)),\n",
       " (1, (4, 74)),\n",
       " (1, (4, 75)),\n",
       " (1, (4, 76)),\n",
       " (1, (4, 77)),\n",
       " (1, (4, 78)),\n",
       " (1, (4, 79)),\n",
       " (1, (4, 80)),\n",
       " (1, (4, 81)),\n",
       " (1, (4, 82)),\n",
       " (1, (4, 83)),\n",
       " (1, (4, 84)),\n",
       " (1, (4, 85)),\n",
       " (1, (4, 86)),\n",
       " (1, (4, 87)),\n",
       " (1, (4, 88)),\n",
       " (1, (4, 89)),\n",
       " (1, (4, 90)),\n",
       " (1, (4, 91)),\n",
       " (1, (4, 92)),\n",
       " (1, (4, 93)),\n",
       " (1, (4, 94)),\n",
       " (1, (4, 95)),\n",
       " (1, (4, 96)),\n",
       " (1, (4, 97)),\n",
       " (1, (4, 98)),\n",
       " (1, (4, 99)),\n",
       " (1, (5, 0)),\n",
       " (1, (5, 1)),\n",
       " (1, (5, 2)),\n",
       " (1, (5, 3)),\n",
       " (1, (5, 4)),\n",
       " (1, (5, 5)),\n",
       " (1, (5, 6)),\n",
       " (1, (5, 7)),\n",
       " (1, (5, 8)),\n",
       " (1, (5, 9)),\n",
       " (1, (5, 10)),\n",
       " (1, (5, 11)),\n",
       " (1, (5, 12)),\n",
       " (1, (5, 13)),\n",
       " (1, (5, 14)),\n",
       " (1, (5, 15)),\n",
       " (1, (5, 16)),\n",
       " (1, (5, 17)),\n",
       " (1, (5, 18)),\n",
       " (1, (5, 19)),\n",
       " (1, (5, 20)),\n",
       " (1, (5, 21)),\n",
       " (1, (5, 22)),\n",
       " (1, (5, 23)),\n",
       " (1, (5, 24)),\n",
       " (1, (5, 25)),\n",
       " (1, (5, 26)),\n",
       " (1, (5, 27)),\n",
       " (1, (5, 28)),\n",
       " (1, (5, 29)),\n",
       " (1, (5, 30)),\n",
       " (1, (5, 31)),\n",
       " (1, (5, 32)),\n",
       " (1, (5, 33)),\n",
       " (1, (5, 34)),\n",
       " (1, (5, 35)),\n",
       " (1, (5, 36)),\n",
       " (1, (5, 37)),\n",
       " (1, (5, 38)),\n",
       " (1, (5, 39)),\n",
       " (1, (5, 40)),\n",
       " (1, (5, 41)),\n",
       " (1, (5, 42)),\n",
       " (1, (5, 43)),\n",
       " (1, (5, 44)),\n",
       " (1, (5, 45)),\n",
       " (1, (5, 46)),\n",
       " (1, (5, 47)),\n",
       " (1, (5, 48)),\n",
       " (1, (5, 49)),\n",
       " (1, (5, 50)),\n",
       " (1, (5, 51)),\n",
       " (1, (5, 52)),\n",
       " (1, (5, 53)),\n",
       " (1, (5, 54)),\n",
       " (1, (5, 55)),\n",
       " (1, (5, 56)),\n",
       " (1, (5, 57)),\n",
       " (1, (5, 58)),\n",
       " (1, (5, 59)),\n",
       " (1, (5, 60)),\n",
       " (1, (5, 61)),\n",
       " (1, (5, 62)),\n",
       " (1, (5, 63)),\n",
       " (1, (5, 64)),\n",
       " (1, (5, 65)),\n",
       " (1, (5, 66)),\n",
       " (1, (5, 67)),\n",
       " (1, (5, 68)),\n",
       " (1, (5, 69)),\n",
       " (1, (5, 70)),\n",
       " (1, (5, 71)),\n",
       " (1, (5, 72)),\n",
       " (1, (5, 73)),\n",
       " (1, (5, 74)),\n",
       " (1, (5, 75)),\n",
       " (1, (5, 76)),\n",
       " (1, (5, 77)),\n",
       " (1, (5, 78)),\n",
       " (1, (5, 79)),\n",
       " (1, (5, 80)),\n",
       " (1, (5, 81)),\n",
       " (1, (5, 82)),\n",
       " (1, (5, 83)),\n",
       " (1, (5, 84)),\n",
       " (1, (5, 85)),\n",
       " (1, (5, 86)),\n",
       " (1, (5, 87)),\n",
       " (1, (5, 88)),\n",
       " (1, (5, 89)),\n",
       " (1, (5, 90)),\n",
       " (1, (5, 91)),\n",
       " (1, (5, 92)),\n",
       " (1, (5, 93)),\n",
       " (1, (5, 94)),\n",
       " (1, (5, 95)),\n",
       " (1, (5, 96)),\n",
       " (1, (5, 97)),\n",
       " (1, (5, 98)),\n",
       " (1, (5, 99)),\n",
       " (1, (6, 0)),\n",
       " (1, (6, 1)),\n",
       " (1, (6, 2)),\n",
       " (1, (6, 3)),\n",
       " (1, (6, 4)),\n",
       " (1, (6, 5)),\n",
       " (1, (6, 6)),\n",
       " (1, (6, 7)),\n",
       " (1, (6, 8)),\n",
       " (1, (6, 9)),\n",
       " (1, (6, 10)),\n",
       " (1, (6, 11)),\n",
       " (1, (6, 12)),\n",
       " (1, (6, 13)),\n",
       " (1, (6, 14)),\n",
       " (1, (6, 15)),\n",
       " (1, (6, 16)),\n",
       " (1, (6, 17)),\n",
       " (1, (6, 18)),\n",
       " (1, (6, 19)),\n",
       " (1, (6, 20)),\n",
       " (1, (6, 21)),\n",
       " (1, (6, 22)),\n",
       " (1, (6, 23)),\n",
       " (1, (6, 24)),\n",
       " (1, (6, 25)),\n",
       " (1, (6, 26)),\n",
       " (1, (6, 27)),\n",
       " (1, (6, 28)),\n",
       " (1, (6, 29)),\n",
       " (1, (6, 30)),\n",
       " (1, (6, 31)),\n",
       " (1, (6, 32)),\n",
       " (1, (6, 33)),\n",
       " (1, (6, 34)),\n",
       " (1, (6, 35)),\n",
       " (1, (6, 36)),\n",
       " (1, (6, 37)),\n",
       " (1, (6, 38)),\n",
       " (1, (6, 39)),\n",
       " (1, (6, 40)),\n",
       " (1, (6, 41)),\n",
       " (1, (6, 42)),\n",
       " (1, (6, 43)),\n",
       " (1, (6, 44)),\n",
       " (1, (6, 45)),\n",
       " (1, (6, 46)),\n",
       " (1, (6, 47)),\n",
       " (1, (6, 48)),\n",
       " (1, (6, 49)),\n",
       " (1, (6, 50)),\n",
       " (1, (6, 51)),\n",
       " (1, (6, 52)),\n",
       " (1, (6, 53)),\n",
       " (1, (6, 54)),\n",
       " (1, (6, 55)),\n",
       " (1, (6, 56)),\n",
       " (1, (6, 57)),\n",
       " (1, (6, 58)),\n",
       " (1, (6, 59)),\n",
       " (1, (6, 60)),\n",
       " (1, (6, 61)),\n",
       " (1, (6, 62)),\n",
       " (1, (6, 63)),\n",
       " (1, (6, 64)),\n",
       " (1, (6, 65)),\n",
       " (1, (6, 66)),\n",
       " (1, (6, 67)),\n",
       " (1, (6, 68)),\n",
       " (1, (6, 69)),\n",
       " (1, (6, 70)),\n",
       " (1, (6, 71)),\n",
       " (1, (6, 72)),\n",
       " (1, (6, 73)),\n",
       " (1, (6, 74)),\n",
       " (1, (6, 75)),\n",
       " (1, (6, 76)),\n",
       " (1, (6, 77)),\n",
       " (1, (6, 78)),\n",
       " (1, (6, 79)),\n",
       " (1, (6, 80)),\n",
       " (1, (6, 81)),\n",
       " (1, (6, 82)),\n",
       " (1, (6, 83)),\n",
       " (1, (6, 84)),\n",
       " (1, (6, 85)),\n",
       " (1, (6, 86)),\n",
       " (1, (6, 87)),\n",
       " (1, (6, 88)),\n",
       " (1, (6, 89)),\n",
       " (1, (6, 90)),\n",
       " (1, (6, 91)),\n",
       " (1, (6, 92)),\n",
       " (1, (6, 93)),\n",
       " (1, (6, 94)),\n",
       " (1, (6, 95)),\n",
       " (1, (6, 96)),\n",
       " (1, (6, 97)),\n",
       " (1, (6, 98)),\n",
       " (1, (6, 99)),\n",
       " (1, (7, 0)),\n",
       " (1, (7, 1)),\n",
       " (1, (7, 2)),\n",
       " (1, (7, 3)),\n",
       " (1, (7, 4)),\n",
       " (1, (7, 5)),\n",
       " (1, (7, 6)),\n",
       " (1, (7, 7)),\n",
       " (1, (7, 8)),\n",
       " (1, (7, 9)),\n",
       " (1, (7, 10)),\n",
       " (1, (7, 11)),\n",
       " (1, (7, 12)),\n",
       " (1, (7, 13)),\n",
       " (1, (7, 14)),\n",
       " (1, (7, 15)),\n",
       " (1, (7, 16)),\n",
       " (1, (7, 17)),\n",
       " (1, (7, 18)),\n",
       " (1, (7, 19)),\n",
       " (1, (7, 20)),\n",
       " (1, (7, 21)),\n",
       " (1, (7, 22)),\n",
       " (1, (7, 23)),\n",
       " (1, (7, 24)),\n",
       " (1, (7, 25)),\n",
       " (1, (7, 26)),\n",
       " (1, (7, 27)),\n",
       " (1, (7, 28)),\n",
       " (1, (7, 29)),\n",
       " (1, (7, 30)),\n",
       " (1, (7, 31)),\n",
       " (1, (7, 32)),\n",
       " (1, (7, 33)),\n",
       " (1, (7, 34)),\n",
       " (1, (7, 35)),\n",
       " (1, (7, 36)),\n",
       " (1, (7, 37)),\n",
       " (1, (7, 38)),\n",
       " (1, (7, 39)),\n",
       " (1, (7, 40)),\n",
       " (1, (7, 41)),\n",
       " (1, (7, 42)),\n",
       " (1, (7, 43)),\n",
       " (1, (7, 44)),\n",
       " (1, (7, 45)),\n",
       " (1, (7, 46)),\n",
       " (1, (7, 47)),\n",
       " (1, (7, 48)),\n",
       " (1, (7, 49)),\n",
       " (1, (7, 50)),\n",
       " (1, (7, 51)),\n",
       " (1, (7, 52)),\n",
       " (1, (7, 53)),\n",
       " (1, (7, 54)),\n",
       " (1, (7, 55)),\n",
       " (1, (7, 56)),\n",
       " (1, (7, 57)),\n",
       " (1, (7, 58)),\n",
       " (1, (7, 59)),\n",
       " (1, (7, 60)),\n",
       " (1, (7, 61)),\n",
       " (1, (7, 62)),\n",
       " (1, (7, 63)),\n",
       " (1, (7, 64)),\n",
       " (1, (7, 65)),\n",
       " (1, (7, 66)),\n",
       " (1, (7, 67)),\n",
       " (1, (7, 68)),\n",
       " (1, (7, 69)),\n",
       " (1, (7, 70)),\n",
       " (1, (7, 71)),\n",
       " (1, (7, 72)),\n",
       " (1, (7, 73)),\n",
       " (1, (7, 74)),\n",
       " (1, (7, 75)),\n",
       " (1, (7, 76)),\n",
       " (1, (7, 77)),\n",
       " (1, (7, 78)),\n",
       " (1, (7, 79)),\n",
       " (1, (7, 80)),\n",
       " (1, (7, 81)),\n",
       " (1, (7, 82)),\n",
       " (1, (7, 83)),\n",
       " (1, (7, 84)),\n",
       " (1, (7, 85)),\n",
       " (1, (7, 86)),\n",
       " (1, (7, 87)),\n",
       " (1, (7, 88)),\n",
       " (1, (7, 89)),\n",
       " (1, (7, 90)),\n",
       " (1, (7, 91)),\n",
       " (1, (7, 92)),\n",
       " (1, (7, 93)),\n",
       " (1, (7, 94)),\n",
       " (1, (7, 95)),\n",
       " (1, (7, 96)),\n",
       " (1, (7, 97)),\n",
       " (1, (7, 98)),\n",
       " (1, (7, 99)),\n",
       " (1, (8, 0)),\n",
       " (1, (8, 1)),\n",
       " (1, (8, 2)),\n",
       " (1, (8, 3)),\n",
       " (1, (8, 4)),\n",
       " (1, (8, 5)),\n",
       " (1, (8, 6)),\n",
       " (1, (8, 7)),\n",
       " (1, (8, 8)),\n",
       " (1, (8, 9)),\n",
       " (1, (8, 10)),\n",
       " (1, (8, 11)),\n",
       " (1, (8, 12)),\n",
       " (1, (8, 13)),\n",
       " (1, (8, 14)),\n",
       " (1, (8, 15)),\n",
       " (1, (8, 16)),\n",
       " (1, (8, 17)),\n",
       " (1, (8, 18)),\n",
       " (1, (8, 19)),\n",
       " (1, (8, 20)),\n",
       " (1, (8, 21)),\n",
       " (1, (8, 22)),\n",
       " (1, (8, 23)),\n",
       " (1, (8, 24)),\n",
       " (1, (8, 25)),\n",
       " (1, (8, 26)),\n",
       " (1, (8, 27)),\n",
       " (1, (8, 28)),\n",
       " (1, (8, 29)),\n",
       " (1, (8, 30)),\n",
       " (1, (8, 31)),\n",
       " (1, (8, 32)),\n",
       " (1, (8, 33)),\n",
       " (1, (8, 34)),\n",
       " (1, (8, 35)),\n",
       " (1, (8, 36)),\n",
       " (1, (8, 37)),\n",
       " (1, (8, 38)),\n",
       " (1, (8, 39)),\n",
       " (1, (8, 40)),\n",
       " (1, (8, 41)),\n",
       " (1, (8, 42)),\n",
       " (1, (8, 43)),\n",
       " (1, (8, 44)),\n",
       " (1, (8, 45)),\n",
       " (1, (8, 46)),\n",
       " (1, (8, 47)),\n",
       " (1, (8, 48)),\n",
       " (1, (8, 49)),\n",
       " (1, (8, 50)),\n",
       " (1, (8, 51)),\n",
       " (1, (8, 52)),\n",
       " (1, (8, 53)),\n",
       " (1, (8, 54)),\n",
       " (1, (8, 55)),\n",
       " (1, (8, 56)),\n",
       " (1, (8, 57)),\n",
       " (1, (8, 58)),\n",
       " (1, (8, 59)),\n",
       " (1, (8, 60)),\n",
       " (1, (8, 61)),\n",
       " (1, (8, 62)),\n",
       " (1, (8, 63)),\n",
       " (1, (8, 64)),\n",
       " (1, (8, 65)),\n",
       " (1, (8, 66)),\n",
       " (1, (8, 67)),\n",
       " (1, (8, 68)),\n",
       " (1, (8, 69)),\n",
       " (1, (8, 70)),\n",
       " (1, (8, 71)),\n",
       " (1, (8, 72)),\n",
       " (1, (8, 73)),\n",
       " (1, (8, 74)),\n",
       " (1, (8, 75)),\n",
       " (1, (8, 76)),\n",
       " (1, (8, 77)),\n",
       " (1, (8, 78)),\n",
       " (1, (8, 79)),\n",
       " (1, (8, 80)),\n",
       " (1, (8, 81)),\n",
       " (1, (8, 82)),\n",
       " (1, (8, 83)),\n",
       " (1, (8, 84)),\n",
       " (1, (8, 85)),\n",
       " (1, (8, 86)),\n",
       " (1, (8, 87)),\n",
       " (1, (8, 88)),\n",
       " (1, (8, 89)),\n",
       " (1, (8, 90)),\n",
       " (1, (8, 91)),\n",
       " (1, (8, 92)),\n",
       " (1, (8, 93)),\n",
       " (1, (8, 94)),\n",
       " (1, (8, 95)),\n",
       " (1, (8, 96)),\n",
       " (1, (8, 97)),\n",
       " (1, (8, 98)),\n",
       " (1, (8, 99)),\n",
       " (1, (9, 0)),\n",
       " (1, (9, 1)),\n",
       " (1, (9, 2)),\n",
       " (1, (9, 3)),\n",
       " (1, (9, 4)),\n",
       " (1, (9, 5)),\n",
       " (1, (9, 6)),\n",
       " (1, (9, 7)),\n",
       " (1, (9, 8)),\n",
       " (1, (9, 9)),\n",
       " (1, (9, 10)),\n",
       " (1, (9, 11)),\n",
       " (1, (9, 12)),\n",
       " (1, (9, 13)),\n",
       " (1, (9, 14)),\n",
       " (1, (9, 15)),\n",
       " (1, (9, 16)),\n",
       " (1, (9, 17)),\n",
       " (1, (9, 18)),\n",
       " (1, (9, 19)),\n",
       " (1, (9, 20)),\n",
       " (1, (9, 21)),\n",
       " (1, (9, 22)),\n",
       " (1, (9, 23)),\n",
       " (1, (9, 24)),\n",
       " (1, (9, 25)),\n",
       " (1, (9, 26)),\n",
       " (1, (9, 27)),\n",
       " (1, (9, 28)),\n",
       " (1, (9, 29)),\n",
       " (1, (9, 30)),\n",
       " (1, (9, 31)),\n",
       " (1, (9, 32)),\n",
       " (1, (9, 33)),\n",
       " (1, (9, 34)),\n",
       " (1, (9, 35)),\n",
       " (1, (9, 36)),\n",
       " (1, (9, 37)),\n",
       " (1, (9, 38)),\n",
       " (1, (9, 39)),\n",
       " (1, (9, 40)),\n",
       " (1, (9, 41)),\n",
       " (1, (9, 42)),\n",
       " (1, (9, 43)),\n",
       " (1, (9, 44)),\n",
       " (1, (9, 45)),\n",
       " (1, (9, 46)),\n",
       " (1, (9, 47)),\n",
       " (1, (9, 48)),\n",
       " (1, (9, 49)),\n",
       " (1, (9, 50)),\n",
       " (1, (9, 51)),\n",
       " (1, (9, 52)),\n",
       " (1, (9, 53)),\n",
       " (1, (9, 54)),\n",
       " (1, (9, 55)),\n",
       " (1, (9, 56)),\n",
       " (1, (9, 57)),\n",
       " (1, (9, 58)),\n",
       " (1, (9, 59)),\n",
       " (1, (9, 60)),\n",
       " (1, (9, 61)),\n",
       " (1, (9, 62)),\n",
       " (1, (9, 63)),\n",
       " (1, (9, 64)),\n",
       " (1, (9, 65)),\n",
       " (1, (9, 66)),\n",
       " (1, (9, 67)),\n",
       " (1, (9, 68)),\n",
       " (1, (9, 69)),\n",
       " (1, (9, 70)),\n",
       " (1, (9, 71)),\n",
       " (1, (9, 72)),\n",
       " (1, (9, 73)),\n",
       " (1, (9, 74)),\n",
       " (1, (9, 75)),\n",
       " (1, (9, 76)),\n",
       " (1, (9, 77)),\n",
       " (1, (9, 78)),\n",
       " (1, (9, 79)),\n",
       " (1, (9, 80)),\n",
       " (1, (9, 81)),\n",
       " (1, (9, 82)),\n",
       " (1, (9, 83)),\n",
       " (1, (9, 84)),\n",
       " (1, (9, 85)),\n",
       " (1, (9, 86)),\n",
       " (1, (9, 87)),\n",
       " (1, (9, 88)),\n",
       " (1, (9, 89)),\n",
       " (1, (9, 90)),\n",
       " (1, (9, 91)),\n",
       " (1, (9, 92)),\n",
       " (1, (9, 93)),\n",
       " (1, (9, 94)),\n",
       " (1, (9, 95)),\n",
       " (1, (9, 96)),\n",
       " (1, (9, 97)),\n",
       " (1, (9, 98)),\n",
       " (1, (9, 99)),\n",
       " ...]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_and_cost(loc_which, seed, loc_file, target_weights, method = 'max'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    from scipy.stats import rankdata\n",
    "    \n",
    "    with open(loc_file, 'rb') as f:\n",
    "        locs = pickle.load(f)\n",
    "    \n",
    "    if loc_which == 'localiser':\n",
    "        new_locs = []\n",
    "        for loc in locs:\n",
    "            indices, cost = loc\n",
    "            idx_to_l, local_idx = indices\n",
    "            local_idx = np.unravel_index(local_idx, target_weights[idx_to_l][0].shape)\n",
    "            new_locs.append([[idx_to_l, local_idx], cost])\n",
    "        \n",
    "        costs = [vs[1] for vs in new_locs]\n",
    "        ranks = rankdata(costs, method = method)\n",
    "        indices = [vs[0] for vs in new_locs]\n",
    "        \n",
    "        #print (len(ranks), len(indices))\n",
    "        ret_lst = compute_pareto(np.asarray(costs), indices)\n",
    "        \n",
    "        pairs = {}\n",
    "        for i,r in enumerate(ret_lst):\n",
    "            #rint (indices[i])\n",
    "            pairs[r] = i+1 # 1 ~ num\n",
    "            \n",
    "    elif loc_which == 'gradient_loss':\n",
    "        costs = [-vs[-1] for vs in locs]\n",
    "        ranks = rankdata(costs, method = method)\n",
    "        indices = [vs[0] for vs in locs]\n",
    "        \n",
    "        pairs = {}\n",
    "        for i,r in enumerate(ranks):\n",
    "            pairs[tuple(indices[i])] = r\n",
    "    else:\n",
    "        np.random.seed(seed)\n",
    "        nindices = np.arange(len(locs))\n",
    "        np.random.shuffle(nindices)\n",
    "        \n",
    "        pairs = {}\n",
    "        for i,aloc in enumerate(nindices):\n",
    "            pairs[tuple(locs[aloc])] = i+1 # 1 ~ num\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pareto(costs, curr_nodes_to_lookat):\n",
    "    ret_lst = []\n",
    "    ret_front_lst = []\n",
    "     \n",
    "    while len(curr_nodes_to_lookat) > 0:\n",
    "        _costs = costs.copy()\n",
    "        is_efficient = np.arange(costs.shape[0])\n",
    "        next_point_index = 0 # Next index in the is_efficient array to search for\n",
    "\n",
    "        while next_point_index < len(_costs):\n",
    "            nondominated_point_mask = np.any(_costs > _costs[next_point_index], axis=1)\n",
    "            nondominated_point_mask[next_point_index] = True\n",
    "            is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "            _costs = _costs[nondominated_point_mask]\n",
    "            next_point_index = np.sum(nondominated_point_mask[:next_point_index])+1\n",
    "            \n",
    "        current_ret = [tuple(v) for v in np.asarray(curr_nodes_to_lookat)[is_efficient]]\n",
    "        ret_lst.extend(current_ret)\n",
    "            \n",
    "        ret_front_lst.append(current_ret)\n",
    "        # remove selected items (non-dominated ones)\n",
    "        curr_nodes_to_lookat = np.delete(curr_nodes_to_lookat, is_efficient, 0)\n",
    "        costs = np.delete(costs, is_efficient, 0)\n",
    "    \n",
    "    return ret_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, (0, 0))</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>2.672062e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, (0, 1))</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>7.222229e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, (0, 2))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.731891e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, (0, 3))</td>\n",
       "      <td>0.047518</td>\n",
       "      <td>6.299856e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, (0, 4))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.932539e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, (0, 5))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.249465e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, (0, 6))</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>2.513270e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, (0, 7))</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>5.171194e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, (0, 8))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.826234e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, (0, 9))</td>\n",
       "      <td>0.067332</td>\n",
       "      <td>5.273305e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1, (0, 10))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.378855e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1, (0, 11))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.205965e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1, (0, 12))</td>\n",
       "      <td>0.047206</td>\n",
       "      <td>6.133855e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1, (0, 13))</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>2.183975e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1, (0, 14))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.130722e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1, (0, 15))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.555431e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(1, (0, 16))</td>\n",
       "      <td>0.065865</td>\n",
       "      <td>1.856802e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(1, (0, 17))</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>3.436139e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(1, (0, 18))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.413559e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1, (0, 19))</td>\n",
       "      <td>0.014055</td>\n",
       "      <td>2.923762e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(1, (0, 20))</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>2.300111e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(1, (0, 21))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.406826e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(1, (0, 22))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.613162e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(1, (0, 23))</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>3.554556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(1, (0, 24))</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>8.932714e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(1, (0, 25))</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>4.425838e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(1, (0, 26))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.470518e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(1, (0, 27))</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>1.626856e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(1, (0, 28))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.402197e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(1, (0, 29))</td>\n",
       "      <td>0.030760</td>\n",
       "      <td>2.992045e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79370</th>\n",
       "      <td>(3, (97, 0))</td>\n",
       "      <td>117.585655</td>\n",
       "      <td>2.299783e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79371</th>\n",
       "      <td>(3, (97, 1))</td>\n",
       "      <td>1.443860</td>\n",
       "      <td>2.597187e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79372</th>\n",
       "      <td>(3, (97, 2))</td>\n",
       "      <td>58.677158</td>\n",
       "      <td>3.294331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79373</th>\n",
       "      <td>(3, (97, 3))</td>\n",
       "      <td>12.787089</td>\n",
       "      <td>8.176657e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79374</th>\n",
       "      <td>(3, (97, 4))</td>\n",
       "      <td>61.387772</td>\n",
       "      <td>3.388613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79375</th>\n",
       "      <td>(3, (97, 5))</td>\n",
       "      <td>20.472462</td>\n",
       "      <td>1.922097e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79376</th>\n",
       "      <td>(3, (97, 6))</td>\n",
       "      <td>172.311600</td>\n",
       "      <td>1.984100e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79377</th>\n",
       "      <td>(3, (97, 7))</td>\n",
       "      <td>87.871277</td>\n",
       "      <td>2.354889e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79378</th>\n",
       "      <td>(3, (97, 8))</td>\n",
       "      <td>69.182236</td>\n",
       "      <td>3.038300e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79379</th>\n",
       "      <td>(3, (97, 9))</td>\n",
       "      <td>64.462852</td>\n",
       "      <td>1.382862e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79380</th>\n",
       "      <td>(3, (98, 0))</td>\n",
       "      <td>92.146904</td>\n",
       "      <td>5.428764e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79381</th>\n",
       "      <td>(3, (98, 1))</td>\n",
       "      <td>0.568987</td>\n",
       "      <td>1.950139e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79382</th>\n",
       "      <td>(3, (98, 2))</td>\n",
       "      <td>532.335632</td>\n",
       "      <td>5.835434e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79383</th>\n",
       "      <td>(3, (98, 3))</td>\n",
       "      <td>1.308121</td>\n",
       "      <td>3.387573e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79384</th>\n",
       "      <td>(3, (98, 4))</td>\n",
       "      <td>1203.965454</td>\n",
       "      <td>5.495626e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79385</th>\n",
       "      <td>(3, (98, 5))</td>\n",
       "      <td>85.406700</td>\n",
       "      <td>4.457662e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79386</th>\n",
       "      <td>(3, (98, 6))</td>\n",
       "      <td>835.815735</td>\n",
       "      <td>4.682966e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79387</th>\n",
       "      <td>(3, (98, 7))</td>\n",
       "      <td>285.317902</td>\n",
       "      <td>1.745778e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79388</th>\n",
       "      <td>(3, (98, 8))</td>\n",
       "      <td>73.108215</td>\n",
       "      <td>2.249275e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79389</th>\n",
       "      <td>(3, (98, 9))</td>\n",
       "      <td>199.580627</td>\n",
       "      <td>1.745652e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79390</th>\n",
       "      <td>(3, (99, 0))</td>\n",
       "      <td>159.157013</td>\n",
       "      <td>1.864389e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79391</th>\n",
       "      <td>(3, (99, 1))</td>\n",
       "      <td>1.288106</td>\n",
       "      <td>2.534857e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79392</th>\n",
       "      <td>(3, (99, 2))</td>\n",
       "      <td>3.463109</td>\n",
       "      <td>2.413647e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79393</th>\n",
       "      <td>(3, (99, 3))</td>\n",
       "      <td>12.401141</td>\n",
       "      <td>1.842420e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79394</th>\n",
       "      <td>(3, (99, 4))</td>\n",
       "      <td>28.362116</td>\n",
       "      <td>9.997564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79395</th>\n",
       "      <td>(3, (99, 5))</td>\n",
       "      <td>658.272400</td>\n",
       "      <td>4.860809e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>(3, (99, 6))</td>\n",
       "      <td>349.759674</td>\n",
       "      <td>1.199396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>(3, (99, 7))</td>\n",
       "      <td>1451.449829</td>\n",
       "      <td>4.923553e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>(3, (99, 8))</td>\n",
       "      <td>170.229309</td>\n",
       "      <td>2.122994e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>(3, (99, 9))</td>\n",
       "      <td>792.838562</td>\n",
       "      <td>5.148330e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0            1             2\n",
       "0       (1, (0, 0))     0.003131  2.672062e-09\n",
       "1       (1, (0, 1))     0.032426  7.222229e-09\n",
       "2       (1, (0, 2))     0.000000  9.731891e-10\n",
       "3       (1, (0, 3))     0.047518  6.299856e-10\n",
       "4       (1, (0, 4))     0.000000  4.932539e-10\n",
       "5       (1, (0, 5))     0.000000  4.249465e-09\n",
       "6       (1, (0, 6))     0.005804  2.513270e-09\n",
       "7       (1, (0, 7))     0.008382  5.171194e-09\n",
       "8       (1, (0, 8))     0.000000  2.826234e-09\n",
       "9       (1, (0, 9))     0.067332  5.273305e-09\n",
       "10     (1, (0, 10))     0.000000  6.378855e-10\n",
       "11     (1, (0, 11))     0.000000  3.205965e-10\n",
       "12     (1, (0, 12))     0.047206  6.133855e-09\n",
       "13     (1, (0, 13))     0.000773  2.183975e-09\n",
       "14     (1, (0, 14))     0.000000  2.130722e-10\n",
       "15     (1, (0, 15))     0.000000  6.555431e-11\n",
       "16     (1, (0, 16))     0.065865  1.856802e-09\n",
       "17     (1, (0, 17))     0.000249  3.436139e-09\n",
       "18     (1, (0, 18))     0.000000  1.413559e-09\n",
       "19     (1, (0, 19))     0.014055  2.923762e-09\n",
       "20     (1, (0, 20))     0.002597  2.300111e-10\n",
       "21     (1, (0, 21))     0.000000  2.406826e-09\n",
       "22     (1, (0, 22))     0.000000  6.613162e-11\n",
       "23     (1, (0, 23))     0.001725  3.554556e-09\n",
       "24     (1, (0, 24))     0.033822  8.932714e-09\n",
       "25     (1, (0, 25))     0.000674  4.425838e-09\n",
       "26     (1, (0, 26))     0.000000  4.470518e-10\n",
       "27     (1, (0, 27))     0.008360  1.626856e-09\n",
       "28     (1, (0, 28))     0.000000  8.402197e-11\n",
       "29     (1, (0, 29))     0.030760  2.992045e-09\n",
       "...             ...          ...           ...\n",
       "79370  (3, (97, 0))   117.585655  2.299783e-04\n",
       "79371  (3, (97, 1))     1.443860  2.597187e-04\n",
       "79372  (3, (97, 2))    58.677158  3.294331e-04\n",
       "79373  (3, (97, 3))    12.787089  8.176657e-04\n",
       "79374  (3, (97, 4))    61.387772  3.388613e-04\n",
       "79375  (3, (97, 5))    20.472462  1.922097e-04\n",
       "79376  (3, (97, 6))   172.311600  1.984100e-04\n",
       "79377  (3, (97, 7))    87.871277  2.354889e-04\n",
       "79378  (3, (97, 8))    69.182236  3.038300e-04\n",
       "79379  (3, (97, 9))    64.462852  1.382862e-04\n",
       "79380  (3, (98, 0))    92.146904  5.428764e-04\n",
       "79381  (3, (98, 1))     0.568987  1.950139e-04\n",
       "79382  (3, (98, 2))   532.335632  5.835434e-04\n",
       "79383  (3, (98, 3))     1.308121  3.387573e-03\n",
       "79384  (3, (98, 4))  1203.965454  5.495626e-04\n",
       "79385  (3, (98, 5))    85.406700  4.457662e-04\n",
       "79386  (3, (98, 6))   835.815735  4.682966e-04\n",
       "79387  (3, (98, 7))   285.317902  1.745778e-04\n",
       "79388  (3, (98, 8))    73.108215  2.249275e-03\n",
       "79389  (3, (98, 9))   199.580627  1.745652e-04\n",
       "79390  (3, (99, 0))   159.157013  1.864389e-04\n",
       "79391  (3, (99, 1))     1.288106  2.534857e-03\n",
       "79392  (3, (99, 2))     3.463109  2.413647e-03\n",
       "79393  (3, (99, 3))    12.401141  1.842420e-04\n",
       "79394  (3, (99, 4))    28.362116  9.997564e-04\n",
       "79395  (3, (99, 5))   658.272400  4.860809e-04\n",
       "79396  (3, (99, 6))   349.759674  1.199396e-04\n",
       "79397  (3, (99, 7))  1451.449829  4.923553e-04\n",
       "79398  (3, (99, 8))   170.229309  2.122994e-04\n",
       "79399  (3, (99, 9))   792.838562  5.148330e-04\n",
       "\n",
       "[79400 rows x 3 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[tuple(vs[0]), vs[1][0], vs[1][1]] for vs in new_locs])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_lst = compute_pareto(np.asarray([vs[1] for vs in new_locs]), [vs[0] for vs in new_locs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, (9, 8)),\n",
       " (3, (93, 6)),\n",
       " (3, (93, 7)),\n",
       " (3, (93, 9)),\n",
       " (3, (5, 3)),\n",
       " (3, (16, 6)),\n",
       " (3, (48, 2)),\n",
       " (3, (93, 0)),\n",
       " (3, (93, 2)),\n",
       " (3, (93, 4)),\n",
       " (3, (93, 5)),\n",
       " (3, (1, 8)),\n",
       " (3, (5, 4)),\n",
       " (3, (9, 2)),\n",
       " (3, (9, 6)),\n",
       " (3, (21, 6)),\n",
       " (3, (45, 2)),\n",
       " (3, (45, 6)),\n",
       " (3, (45, 9)),\n",
       " (3, (62, 6)),\n",
       " (3, (66, 0)),\n",
       " (3, (66, 8)),\n",
       " (3, (67, 8)),\n",
       " (3, (74, 8)),\n",
       " (3, (93, 3)),\n",
       " (3, (93, 8)),\n",
       " (3, (5, 7)),\n",
       " (3, (9, 7)),\n",
       " (3, (41, 6)),\n",
       " (3, (45, 3)),\n",
       " (3, (45, 4)),\n",
       " (3, (50, 5)),\n",
       " (3, (50, 6)),\n",
       " (3, (59, 4)),\n",
       " (3, (62, 7)),\n",
       " (3, (71, 1)),\n",
       " (3, (71, 6)),\n",
       " (3, (74, 5)),\n",
       " (3, (76, 6)),\n",
       " (3, (86, 0)),\n",
       " (3, (1, 7)),\n",
       " (3, (5, 2)),\n",
       " (3, (5, 6)),\n",
       " (3, (9, 4)),\n",
       " (3, (9, 9)),\n",
       " (3, (16, 2)),\n",
       " (3, (50, 9)),\n",
       " (3, (55, 5)),\n",
       " (3, (74, 2)),\n",
       " (3, (16, 0)),\n",
       " (3, (37, 0)),\n",
       " (3, (45, 1)),\n",
       " (3, (45, 8)),\n",
       " (3, (46, 5)),\n",
       " (3, (48, 6)),\n",
       " (3, (55, 8)),\n",
       " (3, (59, 6)),\n",
       " (3, (66, 1)),\n",
       " (3, (71, 0)),\n",
       " (3, (71, 4)),\n",
       " (3, (86, 4)),\n",
       " (3, (1, 4)),\n",
       " (3, (16, 9)),\n",
       " (3, (27, 7)),\n",
       " (3, (37, 1)),\n",
       " (3, (40, 5)),\n",
       " (3, (46, 7)),\n",
       " (3, (50, 0)),\n",
       " (3, (58, 6)),\n",
       " (3, (67, 5)),\n",
       " (3, (67, 6)),\n",
       " (3, (68, 3)),\n",
       " (3, (68, 4)),\n",
       " (3, (71, 2)),\n",
       " (3, (74, 4)),\n",
       " (3, (86, 5)),\n",
       " (3, (86, 6)),\n",
       " (3, (90, 6)),\n",
       " (3, (5, 0)),\n",
       " (3, (5, 8)),\n",
       " (3, (8, 4)),\n",
       " (3, (14, 4)),\n",
       " (3, (21, 0)),\n",
       " (3, (21, 2)),\n",
       " (3, (23, 4)),\n",
       " (3, (37, 7)),\n",
       " (3, (41, 4)),\n",
       " (3, (44, 6)),\n",
       " (3, (46, 4)),\n",
       " (3, (50, 1)),\n",
       " (3, (50, 4)),\n",
       " (3, (55, 6)),\n",
       " (3, (59, 0)),\n",
       " (3, (66, 4)),\n",
       " (3, (67, 9)),\n",
       " (3, (69, 3)),\n",
       " (3, (69, 6)),\n",
       " (3, (74, 6)),\n",
       " (3, (84, 3)),\n",
       " (3, (1, 2)),\n",
       " (3, (2, 6)),\n",
       " (3, (16, 4)),\n",
       " (3, (19, 4)),\n",
       " (3, (33, 7)),\n",
       " (3, (44, 4)),\n",
       " (3, (45, 7)),\n",
       " (3, (55, 4)),\n",
       " (3, (62, 3)),\n",
       " (3, (64, 0)),\n",
       " (3, (66, 6)),\n",
       " (3, (67, 4)),\n",
       " (3, (68, 6)),\n",
       " (3, (71, 7)),\n",
       " (3, (86, 7)),\n",
       " (3, (8, 0)),\n",
       " (3, (9, 0)),\n",
       " (3, (9, 3)),\n",
       " (3, (14, 6)),\n",
       " (3, (14, 8)),\n",
       " (3, (19, 0)),\n",
       " (3, (25, 6)),\n",
       " (3, (27, 6)),\n",
       " (3, (31, 0)),\n",
       " (3, (31, 5)),\n",
       " (3, (42, 7)),\n",
       " (3, (50, 2)),\n",
       " (3, (69, 2)),\n",
       " (3, (71, 8)),\n",
       " (3, (74, 0)),\n",
       " (3, (82, 4)),\n",
       " (3, (83, 5)),\n",
       " (3, (1, 0)),\n",
       " (3, (8, 6)),\n",
       " (3, (16, 7)),\n",
       " (3, (27, 9)),\n",
       " (3, (29, 8)),\n",
       " (3, (34, 6)),\n",
       " (3, (34, 7)),\n",
       " (3, (36, 5)),\n",
       " (3, (45, 0)),\n",
       " (3, (50, 8)),\n",
       " (3, (51, 3)),\n",
       " (3, (51, 4)),\n",
       " (3, (59, 2)),\n",
       " (3, (64, 8)),\n",
       " (3, (68, 0)),\n",
       " (3, (69, 0)),\n",
       " (3, (73, 4)),\n",
       " (3, (73, 6)),\n",
       " (3, (86, 2)),\n",
       " (3, (1, 6)),\n",
       " (3, (16, 3)),\n",
       " (3, (19, 5)),\n",
       " (3, (19, 6)),\n",
       " (3, (23, 7)),\n",
       " (3, (33, 8)),\n",
       " (3, (33, 9)),\n",
       " (3, (36, 8)),\n",
       " (3, (37, 9)),\n",
       " (3, (41, 2)),\n",
       " (3, (41, 3)),\n",
       " (3, (42, 8)),\n",
       " (3, (46, 0)),\n",
       " (3, (58, 0)),\n",
       " (3, (66, 2)),\n",
       " (3, (66, 7)),\n",
       " (3, (67, 0)),\n",
       " (3, (67, 2)),\n",
       " (3, (80, 9)),\n",
       " (3, (98, 3)),\n",
       " (1, (259, 48)),\n",
       " (1, (316, 48)),\n",
       " (1, (343, 48)),\n",
       " (1, (356, 48)),\n",
       " (1, (371, 48)),\n",
       " (1, (381, 48)),\n",
       " (1, (426, 48)),\n",
       " (1, (514, 48)),\n",
       " (1, (544, 48)),\n",
       " (1, (546, 48)),\n",
       " (1, (548, 48)),\n",
       " (3, (0, 4)),\n",
       " (3, (8, 2)),\n",
       " (3, (12, 8)),\n",
       " (3, (14, 2)),\n",
       " (3, (19, 2)),\n",
       " (3, (19, 3)),\n",
       " (3, (24, 0)),\n",
       " (3, (36, 4)),\n",
       " (3, (37, 5)),\n",
       " (3, (40, 7)),\n",
       " (3, (42, 9)),\n",
       " (3, (46, 9)),\n",
       " (3, (52, 2)),\n",
       " (3, (55, 0)),\n",
       " (3, (58, 3)),\n",
       " (3, (59, 1)),\n",
       " (3, (64, 4)),\n",
       " (3, (66, 3)),\n",
       " (3, (70, 7)),\n",
       " (3, (82, 6)),\n",
       " (3, (84, 0)),\n",
       " (3, (84, 4)),\n",
       " (3, (84, 6)),\n",
       " (3, (88, 6)),\n",
       " (3, (98, 8)),\n",
       " (3, (99, 7)),\n",
       " (1, (149, 76)),\n",
       " (1, (203, 48)),\n",
       " (1, (231, 48)),\n",
       " (1, (287, 48)),\n",
       " (1, (288, 48)),\n",
       " (1, (315, 48)),\n",
       " (1, (328, 48)),\n",
       " (1, (329, 48)),\n",
       " (1, (351, 62)),\n",
       " (1, (384, 48)),\n",
       " (1, (441, 48)),\n",
       " (1, (457, 62)),\n",
       " (1, (458, 48)),\n",
       " (1, (465, 62)),\n",
       " (1, (482, 48)),\n",
       " (1, (514, 76)),\n",
       " (1, (517, 48)),\n",
       " (1, (543, 48)),\n",
       " (1, (566, 48)),\n",
       " (1, (574, 48)),\n",
       " (3, (0, 7)),\n",
       " (3, (1, 5)),\n",
       " (3, (23, 1)),\n",
       " (3, (24, 4)),\n",
       " (3, (25, 0)),\n",
       " (3, (29, 3)),\n",
       " (3, (34, 2)),\n",
       " (3, (40, 3)),\n",
       " (3, (52, 4)),\n",
       " (3, (52, 6)),\n",
       " (3, (55, 2)),\n",
       " (3, (62, 0)),\n",
       " (3, (62, 8)),\n",
       " (3, (62, 9)),\n",
       " (3, (73, 0)),\n",
       " (3, (75, 8)),\n",
       " (3, (76, 4)),\n",
       " (3, (83, 0)),\n",
       " (3, (83, 6)),\n",
       " (3, (95, 6)),\n",
       " (3, (98, 4)),\n",
       " (1, (272, 48)),\n",
       " (1, (383, 62)),\n",
       " (1, (385, 48)),\n",
       " (1, (399, 48)),\n",
       " (1, (410, 62)),\n",
       " (1, (427, 48)),\n",
       " (1, (430, 48)),\n",
       " (1, (469, 48)),\n",
       " (1, (490, 48)),\n",
       " (1, (491, 62)),\n",
       " (1, (493, 48)),\n",
       " (1, (510, 48)),\n",
       " (1, (515, 48)),\n",
       " (1, (518, 48)),\n",
       " (1, (522, 90)),\n",
       " (1, (538, 48)),\n",
       " (1, (569, 62)),\n",
       " (1, (594, 48)),\n",
       " (3, (0, 0)),\n",
       " (3, (7, 8)),\n",
       " (3, (8, 5)),\n",
       " (3, (23, 9)),\n",
       " (3, (27, 5)),\n",
       " (3, (33, 0)),\n",
       " (3, (33, 2)),\n",
       " (3, (34, 9)),\n",
       " (3, (36, 2)),\n",
       " (3, (48, 4)),\n",
       " (3, (51, 5)),\n",
       " (3, (51, 6)),\n",
       " (3, (64, 3)),\n",
       " (3, (76, 2)),\n",
       " (3, (84, 9)),\n",
       " (3, (99, 2)),\n",
       " (1, (204, 48)),\n",
       " (1, (232, 48)),\n",
       " (1, (242, 62)),\n",
       " (1, (259, 9)),\n",
       " (1, (328, 62)),\n",
       " (1, (344, 48)),\n",
       " (1, (370, 48)),\n",
       " (1, (372, 48)),\n",
       " (1, (398, 48)),\n",
       " (1, (413, 48)),\n",
       " (1, (454, 48)),\n",
       " (1, (462, 48)),\n",
       " (1, (486, 48)),\n",
       " (1, (489, 21)),\n",
       " (1, (513, 48)),\n",
       " (1, (547, 48)),\n",
       " (1, (550, 48)),\n",
       " (1, (569, 48)),\n",
       " (1, (601, 48)),\n",
       " (1, (602, 48)),\n",
       " (3, (0, 6)),\n",
       " (3, (10, 4)),\n",
       " (3, (12, 4)),\n",
       " (3, (12, 6)),\n",
       " (3, (14, 1)),\n",
       " (3, (16, 1)),\n",
       " (3, (21, 7)),\n",
       " (3, (29, 6)),\n",
       " (3, (29, 7)),\n",
       " (3, (31, 6)),\n",
       " (3, (33, 3)),\n",
       " (3, (33, 4)),\n",
       " (3, (36, 6)),\n",
       " (3, (40, 9)),\n",
       " (3, (48, 7)),\n",
       " (3, (52, 0)),\n",
       " (3, (53, 0)),\n",
       " (3, (58, 2)),\n",
       " (3, (58, 4)),\n",
       " (3, (59, 8)),\n",
       " (3, (62, 5)),\n",
       " (3, (63, 3)),\n",
       " (3, (70, 9)),\n",
       " (3, (71, 9)),\n",
       " (3, (84, 2)),\n",
       " (3, (95, 8)),\n",
       " (1, (203, 9)),\n",
       " (1, (260, 48)),\n",
       " (1, (301, 48)),\n",
       " (1, (315, 9)),\n",
       " (1, (343, 9)),\n",
       " (1, (357, 48)),\n",
       " (1, (375, 48)),\n",
       " (1, (434, 48)),\n",
       " (1, (437, 48)),\n",
       " (1, (482, 9)),\n",
       " (1, (486, 62)),\n",
       " (1, (487, 48)),\n",
       " (1, (497, 48)),\n",
       " (1, (511, 9)),\n",
       " (1, (522, 5)),\n",
       " (1, (525, 48)),\n",
       " (1, (541, 48)),\n",
       " (1, (542, 48)),\n",
       " (1, (571, 48)),\n",
       " (1, (598, 48)),\n",
       " (1, (625, 48)),\n",
       " (3, (1, 3)),\n",
       " (3, (5, 1)),\n",
       " (3, (8, 1)),\n",
       " (3, (9, 1)),\n",
       " (3, (23, 5)),\n",
       " (3, (23, 6)),\n",
       " (3, (27, 2)),\n",
       " (3, (33, 5)),\n",
       " (3, (40, 6)),\n",
       " (3, (42, 4)),\n",
       " (3, (50, 7)),\n",
       " (3, (55, 9)),\n",
       " (3, (63, 1)),\n",
       " (3, (64, 2)),\n",
       " (3, (68, 1)),\n",
       " (3, (68, 8)),\n",
       " (3, (69, 8)),\n",
       " (3, (76, 8)),\n",
       " (3, (82, 2)),\n",
       " (3, (89, 4)),\n",
       " (3, (93, 1)),\n",
       " (3, (94, 0)),\n",
       " (3, (99, 1)),\n",
       " (1, (231, 9)),\n",
       " (1, (244, 48)),\n",
       " (1, (268, 48)),\n",
       " (1, (271, 62)),\n",
       " (1, (300, 48)),\n",
       " (1, (314, 48)),\n",
       " (1, (329, 9)),\n",
       " (1, (342, 48)),\n",
       " (1, (347, 48)),\n",
       " (1, (354, 5)),\n",
       " (1, (374, 48)),\n",
       " (1, (406, 48)),\n",
       " (1, (407, 48)),\n",
       " (1, (433, 48)),\n",
       " (1, (455, 9)),\n",
       " (1, (455, 48)),\n",
       " (1, (467, 48)),\n",
       " (1, (469, 5)),\n",
       " (1, (485, 9)),\n",
       " (1, (494, 48)),\n",
       " (1, (578, 48)),\n",
       " (1, (626, 48)),\n",
       " (1, (629, 48)),\n",
       " (3, (2, 2)),\n",
       " (3, (4, 0)),\n",
       " (3, (9, 5)),\n",
       " (3, (10, 8)),\n",
       " (3, (12, 5)),\n",
       " (3, (13, 2)),\n",
       " (3, (14, 3)),\n",
       " (3, (16, 5)),\n",
       " (3, (25, 1)),\n",
       " (3, (34, 3)),\n",
       " (3, (42, 3)),\n",
       " (3, (42, 6)),\n",
       " (3, (47, 0)),\n",
       " (3, (50, 3)),\n",
       " (3, (62, 2)),\n",
       " (3, (62, 4)),\n",
       " (3, (64, 6)),\n",
       " (3, (69, 4)),\n",
       " (3, (73, 1)),\n",
       " (3, (75, 0)),\n",
       " (3, (81, 8)),\n",
       " (3, (91, 1)),\n",
       " (3, (95, 2)),\n",
       " (3, (95, 4)),\n",
       " (3, (98, 6)),\n",
       " (3, (99, 9)),\n",
       " (1, (99, 48)),\n",
       " (1, (233, 48)),\n",
       " (1, (261, 48)),\n",
       " (1, (269, 90)),\n",
       " (1, (377, 62)),\n",
       " (1, (377, 76)),\n",
       " (1, (380, 48)),\n",
       " (1, (385, 62)),\n",
       " (1, (402, 48)),\n",
       " (1, (428, 62)),\n",
       " (1, (439, 76)),\n",
       " (1, (459, 48)),\n",
       " (1, (485, 48)),\n",
       " (1, (516, 48)),\n",
       " (1, (519, 48)),\n",
       " (1, (541, 76)),\n",
       " (1, (541, 90)),\n",
       " (1, (545, 9)),\n",
       " (1, (546, 62)),\n",
       " (1, (570, 48)),\n",
       " (1, (597, 41)),\n",
       " (1, (604, 9)),\n",
       " (1, (606, 41)),\n",
       " (3, (7, 4)),\n",
       " (3, (8, 8)),\n",
       " (3, (8, 9)),\n",
       " (3, (10, 1)),\n",
       " (3, (10, 6)),\n",
       " (3, (11, 9)),\n",
       " (3, (14, 7)),\n",
       " (3, (20, 2)),\n",
       " (3, (22, 2)),\n",
       " (3, (23, 8)),\n",
       " (3, (24, 2)),\n",
       " (3, (25, 8)),\n",
       " (3, (36, 9)),\n",
       " (3, (41, 0)),\n",
       " (3, (41, 5)),\n",
       " (3, (44, 0)),\n",
       " (3, (44, 3)),\n",
       " (3, (44, 8)),\n",
       " (3, (48, 8)),\n",
       " (3, (51, 2)),\n",
       " (3, (51, 8)),\n",
       " (3, (55, 3)),\n",
       " (3, (70, 6)),\n",
       " (3, (75, 7)),\n",
       " (3, (81, 6)),\n",
       " (3, (86, 1)),\n",
       " (3, (98, 2)),\n",
       " (3, (99, 5)),\n",
       " (1, (98, 48)),\n",
       " (1, (126, 48)),\n",
       " (1, (127, 48)),\n",
       " (1, (128, 48)),\n",
       " (1, (262, 76)),\n",
       " (1, (273, 48)),\n",
       " (1, (350, 48)),\n",
       " (1, (353, 48)),\n",
       " (1, (371, 9)),\n",
       " (1, (380, 5)),\n",
       " (1, (382, 5)),\n",
       " (1, (385, 5)),\n",
       " (1, (404, 48)),\n",
       " (1, (429, 48)),\n",
       " (1, (435, 62)),\n",
       " (1, (436, 48)),\n",
       " (1, (438, 48)),\n",
       " (1, (460, 48)),\n",
       " (1, (461, 62)),\n",
       " (1, (467, 5)),\n",
       " (1, (488, 48)),\n",
       " (1, (494, 90)),\n",
       " (1, (513, 62)),\n",
       " (1, (513, 76)),\n",
       " (1, (518, 76)),\n",
       " (1, (522, 48)),\n",
       " (1, (541, 62)),\n",
       " (1, (567, 9)),\n",
       " (1, (569, 76)),\n",
       " (1, (622, 48)),\n",
       " (1, (630, 62)),\n",
       " (3, (0, 9)),\n",
       " (3, (2, 4)),\n",
       " (3, (10, 2)),\n",
       " (3, (11, 6)),\n",
       " (3, (19, 7)),\n",
       " (3, (31, 9)),\n",
       " (3, (34, 5)),\n",
       " (3, (40, 2)),\n",
       " (3, (42, 5)),\n",
       " (3, (44, 2)),\n",
       " (3, (48, 9)),\n",
       " (3, (59, 5)),\n",
       " (3, (75, 6)),\n",
       " (3, (76, 7)),\n",
       " (3, (80, 6)),\n",
       " (3, (81, 1)),\n",
       " (3, (84, 8)),\n",
       " (3, (86, 8)),\n",
       " (3, (89, 6)),\n",
       " (3, (89, 8)),\n",
       " (3, (90, 7)),\n",
       " (3, (91, 4)),\n",
       " (3, (95, 0)),\n",
       " (1, (130, 48)),\n",
       " (1, (158, 48)),\n",
       " (1, (160, 9)),\n",
       " (1, (204, 9)),\n",
       " (1, (210, 41)),\n",
       " (1, (241, 62)),\n",
       " (1, (297, 48)),\n",
       " (1, (322, 48)),\n",
       " (1, (323, 48)),\n",
       " (1, (324, 76)),\n",
       " (1, (352, 62)),\n",
       " (1, (353, 9)),\n",
       " (1, (378, 48)),\n",
       " (1, (379, 48)),\n",
       " (1, (403, 48)),\n",
       " (1, (405, 48)),\n",
       " (1, (410, 21)),\n",
       " (1, (432, 48)),\n",
       " (1, (437, 62)),\n",
       " (1, (463, 48)),\n",
       " (1, (487, 9)),\n",
       " (1, (489, 62)),\n",
       " (1, (492, 48)),\n",
       " (1, (513, 82)),\n",
       " (1, (542, 76)),\n",
       " (1, (553, 48)),\n",
       " (1, (570, 76)),\n",
       " (1, (572, 48)),\n",
       " (1, (573, 48)),\n",
       " (1, (574, 41)),\n",
       " (1, (597, 48)),\n",
       " (1, (657, 48)),\n",
       " (1, (658, 48)),\n",
       " (3, (3, 6)),\n",
       " (3, (5, 9)),\n",
       " (3, (7, 7)),\n",
       " (3, (12, 0)),\n",
       " (3, (20, 4)),\n",
       " (3, (21, 4)),\n",
       " (3, (21, 9)),\n",
       " (3, (27, 3)),\n",
       " (3, (41, 1)),\n",
       " (3, (41, 7)),\n",
       " (3, (44, 7)),\n",
       " (3, (67, 3)),\n",
       " (3, (68, 7)),\n",
       " (3, (70, 5)),\n",
       " (3, (74, 3)),\n",
       " (3, (75, 2)),\n",
       " (3, (78, 6)),\n",
       " (3, (80, 5)),\n",
       " (3, (82, 1)),\n",
       " (3, (90, 8)),\n",
       " (3, (91, 5)),\n",
       " (3, (91, 6)),\n",
       " (3, (95, 3)),\n",
       " (3, (95, 5)),\n",
       " (3, (99, 4)),\n",
       " (1, (71, 41)),\n",
       " (1, (72, 41)),\n",
       " (1, (121, 48)),\n",
       " (1, (124, 48)),\n",
       " (1, (129, 48)),\n",
       " (1, (151, 9)),\n",
       " (1, (175, 9)),\n",
       " (1, (214, 62)),\n",
       " (1, (215, 9)),\n",
       " (1, (262, 9)),\n",
       " (1, (263, 9)),\n",
       " (1, (268, 41)),\n",
       " (1, (270, 41)),\n",
       " (1, (273, 62)),\n",
       " (1, (287, 9)),\n",
       " (1, (290, 76)),\n",
       " (1, (298, 21)),\n",
       " (1, (315, 41)),\n",
       " (1, (317, 48)),\n",
       " (1, (324, 48)),\n",
       " (1, (350, 62)),\n",
       " (1, (356, 76)),\n",
       " (1, (377, 5)),\n",
       " (1, (386, 62)),\n",
       " (1, (401, 48)),\n",
       " (1, (431, 48)),\n",
       " (1, (462, 62)),\n",
       " (1, (466, 48)),\n",
       " (1, (483, 48)),\n",
       " (1, (489, 48)),\n",
       " (1, (491, 48)),\n",
       " (1, (493, 9)),\n",
       " (1, (520, 48)),\n",
       " (1, (522, 76)),\n",
       " (1, (526, 48)),\n",
       " (1, (545, 48)),\n",
       " (1, (548, 5)),\n",
       " (1, (567, 41)),\n",
       " (1, (577, 48)),\n",
       " (1, (600, 48)),\n",
       " (1, (610, 48)),\n",
       " (1, (624, 9)),\n",
       " (1, (627, 48)),\n",
       " (1, (633, 48)),\n",
       " (1, (651, 9)),\n",
       " (3, (1, 1)),\n",
       " (3, (14, 0)),\n",
       " (3, (19, 8)),\n",
       " (3, (25, 9)),\n",
       " (3, (31, 3)),\n",
       " (3, (40, 1)),\n",
       " (3, (40, 8)),\n",
       " (3, (52, 7)),\n",
       " (3, (52, 8)),\n",
       " (3, (63, 6)),\n",
       " (3, (70, 0)),\n",
       " (3, (71, 3)),\n",
       " (1, (69, 48)),\n",
       " (1, (101, 48)),\n",
       " (1, (175, 48)),\n",
       " (1, (210, 9)),\n",
       " (1, (231, 41)),\n",
       " (1, (245, 48)),\n",
       " (1, (258, 48)),\n",
       " (1, (269, 62)),\n",
       " (1, (286, 48)),\n",
       " (1, (292, 21)),\n",
       " (1, (318, 48)),\n",
       " (1, (319, 48)),\n",
       " (1, (324, 62)),\n",
       " (1, (345, 9)),\n",
       " (1, (346, 48)),\n",
       " (1, (351, 48)),\n",
       " (1, (372, 9)),\n",
       " (1, (382, 1)),\n",
       " (1, (400, 48)),\n",
       " (1, (402, 41)),\n",
       " (1, (410, 48)),\n",
       " (1, (410, 76)),\n",
       " (1, (438, 76)),\n",
       " (1, (441, 5)),\n",
       " (1, (457, 41)),\n",
       " (1, (461, 76)),\n",
       " (1, (489, 76)),\n",
       " (1, (490, 76)),\n",
       " (1, (519, 55)),\n",
       " (1, (521, 48)),\n",
       " (1, (547, 1)),\n",
       " (1, (549, 48)),\n",
       " (1, (551, 9)),\n",
       " (1, (569, 41)),\n",
       " (1, (571, 76)),\n",
       " (1, (576, 48)),\n",
       " (1, (581, 48)),\n",
       " (1, (604, 62)),\n",
       " (1, (628, 48)),\n",
       " (1, (638, 48)),\n",
       " (1, (652, 62)),\n",
       " (3, (10, 9)),\n",
       " (3, (20, 3)),\n",
       " (3, (20, 6)),\n",
       " (3, (31, 8)),\n",
       " (3, (32, 6)),\n",
       " (3, (36, 0)),\n",
       " (3, (43, 4)),\n",
       " (3, (51, 0)),\n",
       " (3, (58, 1)),\n",
       " (3, (81, 0)),\n",
       " (3, (82, 0)),\n",
       " (3, (89, 0)),\n",
       " (3, (90, 4)),\n",
       " (1, (204, 21)),\n",
       " (1, (206, 9)),\n",
       " (1, (214, 41)),\n",
       " (1, (215, 21)),\n",
       " (1, (262, 48)),\n",
       " (1, (271, 48)),\n",
       " (1, (288, 9)),\n",
       " (1, (288, 55)),\n",
       " (1, (289, 48)),\n",
       " (1, (295, 48)),\n",
       " (1, (298, 48)),\n",
       " (1, (301, 55)),\n",
       " (1, (321, 41)),\n",
       " (1, (326, 5)),\n",
       " (1, (326, 41)),\n",
       " (1, (329, 62)),\n",
       " (1, (354, 76)),\n",
       " (1, (412, 48)),\n",
       " (1, (413, 9)),\n",
       " (1, (436, 76)),\n",
       " (1, (439, 5)),\n",
       " (1, (442, 48)),\n",
       " (1, (455, 67)),\n",
       " (1, (461, 48)),\n",
       " (1, (464, 5)),\n",
       " (1, (464, 48)),\n",
       " (1, (465, 48)),\n",
       " (1, (466, 76)),\n",
       " (1, (468, 5)),\n",
       " (1, (496, 5)),\n",
       " (1, (499, 5)),\n",
       " (1, (539, 62)),\n",
       " (1, (571, 9)),\n",
       " (1, (575, 48)),\n",
       " (1, (575, 76)),\n",
       " (1, (577, 76)),\n",
       " (1, (579, 48)),\n",
       " (1, (582, 48)),\n",
       " (1, (603, 5)),\n",
       " (1, (607, 48)),\n",
       " (1, (609, 41)),\n",
       " (1, (656, 48)),\n",
       " (1, (657, 41)),\n",
       " (1, (686, 48)),\n",
       " (1, (688, 48)),\n",
       " (3, (7, 0)),\n",
       " (3, (11, 2)),\n",
       " (3, (19, 1)),\n",
       " (3, (20, 0)),\n",
       " (3, (21, 5)),\n",
       " (3, (22, 9)),\n",
       " (3, (42, 2)),\n",
       " (3, (48, 1)),\n",
       " (3, (51, 7)),\n",
       " (3, (62, 1)),\n",
       " (3, (68, 2)),\n",
       " (3, (80, 4)),\n",
       " (3, (83, 3)),\n",
       " (3, (88, 2)),\n",
       " (3, (91, 2)),\n",
       " (3, (97, 3)),\n",
       " (1, (150, 9)),\n",
       " (1, (156, 48)),\n",
       " (1, (214, 48)),\n",
       " (1, (215, 62)),\n",
       " (1, (234, 41)),\n",
       " (1, (242, 48)),\n",
       " (1, (244, 5)),\n",
       " (1, (269, 9)),\n",
       " (1, (272, 41)),\n",
       " (1, (294, 21)),\n",
       " (1, (295, 9)),\n",
       " (1, (299, 48)),\n",
       " (1, (301, 62)),\n",
       " (1, (353, 76)),\n",
       " (1, (356, 9)),\n",
       " (1, (356, 62)),\n",
       " (1, (376, 48)),\n",
       " (1, (382, 76)),\n",
       " (1, (405, 41)),\n",
       " (1, (408, 48)),\n",
       " (1, (430, 41)),\n",
       " (1, (437, 9)),\n",
       " (1, (440, 5)),\n",
       " (1, (456, 55)),\n",
       " (1, (457, 9)),\n",
       " (1, (457, 48)),\n",
       " (1, (490, 21)),\n",
       " (1, (491, 76)),\n",
       " (1, (513, 55)),\n",
       " (1, (520, 55)),\n",
       " (1, (543, 76)),\n",
       " (1, (577, 9)),\n",
       " (1, (577, 67)),\n",
       " (1, (596, 41)),\n",
       " (1, (599, 48)),\n",
       " (1, (604, 48)),\n",
       " (1, (606, 48)),\n",
       " (1, (608, 62)),\n",
       " (1, (625, 41)),\n",
       " (1, (630, 41)),\n",
       " (1, (631, 48)),\n",
       " (1, (634, 48)),\n",
       " (1, (653, 62)),\n",
       " (1, (659, 55)),\n",
       " (1, (664, 62)),\n",
       " (3, (1, 9)),\n",
       " (3, (7, 9)),\n",
       " (3, (11, 3)),\n",
       " (3, (17, 4)),\n",
       " (3, (21, 8)),\n",
       " (3, (22, 5)),\n",
       " (3, (24, 8)),\n",
       " (3, (24, 9)),\n",
       " (3, (25, 2)),\n",
       " (3, (34, 1)),\n",
       " (3, (41, 9)),\n",
       " (3, (47, 5)),\n",
       " (3, (48, 0)),\n",
       " (3, (48, 5)),\n",
       " (3, (53, 2)),\n",
       " (3, (70, 4)),\n",
       " (3, (72, 4)),\n",
       " (3, (76, 0)),\n",
       " (3, (81, 4)),\n",
       " (3, (94, 4)),\n",
       " (1, (42, 76)),\n",
       " (1, (102, 48)),\n",
       " (1, (158, 21)),\n",
       " (1, (185, 62)),\n",
       " (1, (215, 48)),\n",
       " (1, (217, 48)),\n",
       " (1, (235, 48)),\n",
       " (1, (241, 48)),\n",
       " (1, (243, 9)),\n",
       " (1, (272, 55)),\n",
       " (1, (327, 76)),\n",
       " (1, (345, 48)),\n",
       " (1, (375, 76)),\n",
       " (1, (383, 48)),\n",
       " (1, (384, 74)),\n",
       " (1, (384, 76)),\n",
       " (1, (404, 41)),\n",
       " (1, (408, 76)),\n",
       " (1, (411, 48)),\n",
       " (1, (430, 5)),\n",
       " (1, (431, 21)),\n",
       " (1, (456, 62)),\n",
       " (1, (457, 5)),\n",
       " (1, (463, 62)),\n",
       " (1, (466, 90)),\n",
       " (1, (470, 48)),\n",
       " (1, (481, 21)),\n",
       " (1, (483, 9)),\n",
       " (1, (492, 55)),\n",
       " (1, (511, 48)),\n",
       " (1, (513, 21)),\n",
       " (1, (523, 62)),\n",
       " (1, (524, 62)),\n",
       " (1, (541, 41)),\n",
       " (1, (550, 5)),\n",
       " (1, (554, 48)),\n",
       " (1, (568, 9)),\n",
       " (1, (578, 5)),\n",
       " (1, (596, 48)),\n",
       " (1, (601, 76)),\n",
       " (1, (602, 41)),\n",
       " (1, (632, 48)),\n",
       " (1, (636, 62)),\n",
       " (1, (743, 41)),\n",
       " (3, (0, 2)),\n",
       " (3, (8, 3)),\n",
       " (3, (10, 3)),\n",
       " (3, (13, 7)),\n",
       " (3, (21, 1)),\n",
       " (3, (24, 7)),\n",
       " (3, (29, 0)),\n",
       " (3, (31, 2)),\n",
       " (3, (58, 5)),\n",
       " (3, (64, 1)),\n",
       " (3, (72, 2)),\n",
       " (3, (75, 4)),\n",
       " (3, (81, 7)),\n",
       " (1, (43, 62)),\n",
       " (1, (67, 41)),\n",
       " (1, (125, 48)),\n",
       " (1, (153, 41)),\n",
       " (1, (154, 48)),\n",
       " (1, (155, 41)),\n",
       " (1, (179, 48)),\n",
       " (1, (180, 48)),\n",
       " (1, (234, 76)),\n",
       " (1, (243, 21)),\n",
       " (1, (245, 67)),\n",
       " (1, (264, 9)),\n",
       " (1, (267, 62)),\n",
       " (1, (299, 41)),\n",
       " (1, (300, 67)),\n",
       " (1, (322, 41)),\n",
       " (1, (326, 76)),\n",
       " (1, (347, 62)),\n",
       " (1, (358, 62)),\n",
       " (1, (373, 48)),\n",
       " (1, (377, 48)),\n",
       " (1, (380, 76)),\n",
       " (1, (382, 48)),\n",
       " (1, (435, 48)),\n",
       " (1, (436, 5)),\n",
       " (1, (436, 62)),\n",
       " (1, (459, 21)),\n",
       " (1, (463, 55)),\n",
       " (1, (466, 41)),\n",
       " (1, (490, 62)),\n",
       " (1, (490, 67)),\n",
       " (1, (493, 62)),\n",
       " (1, (509, 55)),\n",
       " (1, (512, 9)),\n",
       " (1, (519, 90)),\n",
       " (1, (523, 48)),\n",
       " (1, (525, 55)),\n",
       " (1, (537, 55)),\n",
       " (1, (566, 41)),\n",
       " (1, (569, 5)),\n",
       " (1, (574, 76)),\n",
       " (1, (576, 67)),\n",
       " (1, (577, 5)),\n",
       " (1, (601, 9)),\n",
       " (1, (602, 55)),\n",
       " (1, (602, 76)),\n",
       " (1, (603, 48)),\n",
       " (1, (608, 41)),\n",
       " (1, (609, 62)),\n",
       " (1, (624, 41)),\n",
       " (1, (654, 48)),\n",
       " (1, (713, 62)),\n",
       " (3, (0, 8)),\n",
       " (3, (3, 4)),\n",
       " (3, (4, 4)),\n",
       " (3, (4, 6)),\n",
       " (3, (4, 8)),\n",
       " (3, (22, 0)),\n",
       " (3, (25, 3)),\n",
       " (3, (44, 1)),\n",
       " (3, (52, 3)),\n",
       " (3, (55, 7)),\n",
       " (3, (58, 7)),\n",
       " (3, (63, 8)),\n",
       " (3, (64, 5)),\n",
       " (3, (73, 5)),\n",
       " (3, (80, 7)),\n",
       " (3, (90, 2)),\n",
       " (3, (92, 2)),\n",
       " (3, (94, 8)),\n",
       " (3, (98, 0)),\n",
       " (1, (40, 41)),\n",
       " (1, (131, 9)),\n",
       " (1, (182, 48)),\n",
       " (1, (187, 48)),\n",
       " (1, (188, 76)),\n",
       " (1, (205, 48)),\n",
       " (1, (212, 55)),\n",
       " (1, (231, 67)),\n",
       " (1, (237, 48)),\n",
       " (1, (241, 55)),\n",
       " (1, (242, 76)),\n",
       " (1, (271, 67)),\n",
       " (1, (274, 5)),\n",
       " (1, (291, 48)),\n",
       " (1, (295, 67)),\n",
       " (1, (300, 41)),\n",
       " (1, (301, 9)),\n",
       " (1, (327, 48)),\n",
       " (1, (328, 76)),\n",
       " (1, (330, 62)),\n",
       " (1, (348, 48)),\n",
       " (1, (350, 76)),\n",
       " (1, (352, 48)),\n",
       " (1, (373, 67)),\n",
       " (1, (374, 41)),\n",
       " (1, (386, 5)),\n",
       " (1, (387, 5)),\n",
       " (1, (403, 76)),\n",
       " (1, (409, 48)),\n",
       " (1, (414, 48)),\n",
       " (1, (432, 55)),\n",
       " (1, (438, 9)),\n",
       " (1, (438, 90)),\n",
       " (1, (455, 62)),\n",
       " (1, (457, 76)),\n",
       " (1, (459, 67)),\n",
       " (1, (466, 67)),\n",
       " (1, (482, 5)),\n",
       " (1, (497, 55)),\n",
       " (1, (510, 9)),\n",
       " (1, (512, 41)),\n",
       " (1, (518, 90)),\n",
       " (1, (519, 62)),\n",
       " (1, (520, 9)),\n",
       " (1, (524, 41)),\n",
       " (1, (547, 5)),\n",
       " (1, (573, 76)),\n",
       " (1, (578, 55)),\n",
       " (1, (580, 67)),\n",
       " (1, (594, 9)),\n",
       " (1, (597, 5)),\n",
       " ...]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78498</th>\n",
       "      <td>(3, (9, 8))</td>\n",
       "      <td>(3323.6279296875, 0.01753034889698214)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                       1\n",
       "78498  (3, (9, 8))  (3323.6279296875, 0.01753034889698214)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[0] == (3,(9,8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rank(axis = 1, method = 'max').iloc[78498].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79339</th>\n",
       "      <td>(3, (93, 9))</td>\n",
       "      <td>17.565239</td>\n",
       "      <td>2.878784e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79337</th>\n",
       "      <td>(3, (93, 7))</td>\n",
       "      <td>46.013561</td>\n",
       "      <td>2.651494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78498</th>\n",
       "      <td>(3, (9, 8))</td>\n",
       "      <td>3323.627930</td>\n",
       "      <td>1.753035e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79335</th>\n",
       "      <td>(3, (93, 5))</td>\n",
       "      <td>27.272110</td>\n",
       "      <td>1.649347e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78453</th>\n",
       "      <td>(3, (5, 3))</td>\n",
       "      <td>153.317612</td>\n",
       "      <td>1.080111e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78859</th>\n",
       "      <td>(3, (45, 9))</td>\n",
       "      <td>40.848118</td>\n",
       "      <td>8.727506e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79111</th>\n",
       "      <td>(3, (71, 1))</td>\n",
       "      <td>6.814991</td>\n",
       "      <td>8.679789e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78499</th>\n",
       "      <td>(3, (9, 9))</td>\n",
       "      <td>5.095457</td>\n",
       "      <td>8.539372e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78497</th>\n",
       "      <td>(3, (9, 7))</td>\n",
       "      <td>12.148599</td>\n",
       "      <td>8.417979e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78882</th>\n",
       "      <td>(3, (48, 2))</td>\n",
       "      <td>396.964294</td>\n",
       "      <td>8.025576e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78905</th>\n",
       "      <td>(3, (50, 5))</td>\n",
       "      <td>13.064903</td>\n",
       "      <td>7.435214e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79148</th>\n",
       "      <td>(3, (74, 8))</td>\n",
       "      <td>215.718567</td>\n",
       "      <td>7.001323e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79060</th>\n",
       "      <td>(3, (66, 0))</td>\n",
       "      <td>240.889359</td>\n",
       "      <td>6.495381e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78955</th>\n",
       "      <td>(3, (55, 5))</td>\n",
       "      <td>8.172618</td>\n",
       "      <td>6.041217e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79078</th>\n",
       "      <td>(3, (67, 8))</td>\n",
       "      <td>313.127472</td>\n",
       "      <td>5.887667e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78566</th>\n",
       "      <td>(3, (16, 6))</td>\n",
       "      <td>946.868896</td>\n",
       "      <td>5.743701e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78909</th>\n",
       "      <td>(3, (50, 9))</td>\n",
       "      <td>9.000734</td>\n",
       "      <td>5.729656e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78851</th>\n",
       "      <td>(3, (45, 1))</td>\n",
       "      <td>8.755547</td>\n",
       "      <td>5.690474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79145</th>\n",
       "      <td>(3, (74, 5))</td>\n",
       "      <td>135.278091</td>\n",
       "      <td>5.629795e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78418</th>\n",
       "      <td>(3, (1, 8))</td>\n",
       "      <td>500.308777</td>\n",
       "      <td>5.556394e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79260</th>\n",
       "      <td>(3, (86, 0))</td>\n",
       "      <td>190.597015</td>\n",
       "      <td>5.555605e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78771</th>\n",
       "      <td>(3, (37, 1))</td>\n",
       "      <td>1.833119</td>\n",
       "      <td>5.495577e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79075</th>\n",
       "      <td>(3, (67, 5))</td>\n",
       "      <td>4.997952</td>\n",
       "      <td>5.469946e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79084</th>\n",
       "      <td>(3, (68, 4))</td>\n",
       "      <td>8.406954</td>\n",
       "      <td>5.449231e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78994</th>\n",
       "      <td>(3, (59, 4))</td>\n",
       "      <td>221.399734</td>\n",
       "      <td>5.361756e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78562</th>\n",
       "      <td>(3, (16, 2))</td>\n",
       "      <td>97.034912</td>\n",
       "      <td>5.283684e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79026</th>\n",
       "      <td>(3, (62, 6))</td>\n",
       "      <td>556.149414</td>\n",
       "      <td>5.191099e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78853</th>\n",
       "      <td>(3, (45, 3))</td>\n",
       "      <td>281.027283</td>\n",
       "      <td>5.063115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79243</th>\n",
       "      <td>(3, (84, 3))</td>\n",
       "      <td>3.131077</td>\n",
       "      <td>5.029937e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79079</th>\n",
       "      <td>(3, (67, 9))</td>\n",
       "      <td>3.594819</td>\n",
       "      <td>5.021858e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75787</th>\n",
       "      <td>(1, (757, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.096822e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61487</th>\n",
       "      <td>(1, (614, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.148433e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>(1, (30, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453270e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14187</th>\n",
       "      <td>(1, (141, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.208397e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16887</th>\n",
       "      <td>(1, (168, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.078216e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11287</th>\n",
       "      <td>(1, (112, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.980508e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>(1, (110, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.207136e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14087</th>\n",
       "      <td>(1, (140, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.048980e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>(1, (57, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.444448e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>(1, (55, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.131297e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>(1, (3, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.485248e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>(1, (54, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.334336e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>(1, (136, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.093827e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11187</th>\n",
       "      <td>(1, (111, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.724575e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8487</th>\n",
       "      <td>(1, (84, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.279171e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>(1, (83, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.239786e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>(1, (2, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.752864e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>(1, (56, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.560832e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>(1, (25, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.444426e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>(1, (4, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.374987e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>(1, (27, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.183484e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13987</th>\n",
       "      <td>(1, (139, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.179100e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>(1, (26, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.232147e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>(1, (29, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.637747e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(1, (0, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.550512e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78387</th>\n",
       "      <td>(1, (783, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.007098e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75687</th>\n",
       "      <td>(1, (756, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.766966e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>(1, (1, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.656696e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>(1, (28, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.570659e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8287</th>\n",
       "      <td>(1, (82, 87))</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.855714e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0            1             2\n",
       "79339    (3, (93, 9))    17.565239  2.878784e-02\n",
       "79337    (3, (93, 7))    46.013561  2.651494e-02\n",
       "78498     (3, (9, 8))  3323.627930  1.753035e-02\n",
       "79335    (3, (93, 5))    27.272110  1.649347e-02\n",
       "78453     (3, (5, 3))   153.317612  1.080111e-02\n",
       "78859    (3, (45, 9))    40.848118  8.727506e-03\n",
       "79111    (3, (71, 1))     6.814991  8.679789e-03\n",
       "78499     (3, (9, 9))     5.095457  8.539372e-03\n",
       "78497     (3, (9, 7))    12.148599  8.417979e-03\n",
       "78882    (3, (48, 2))   396.964294  8.025576e-03\n",
       "78905    (3, (50, 5))    13.064903  7.435214e-03\n",
       "79148    (3, (74, 8))   215.718567  7.001323e-03\n",
       "79060    (3, (66, 0))   240.889359  6.495381e-03\n",
       "78955    (3, (55, 5))     8.172618  6.041217e-03\n",
       "79078    (3, (67, 8))   313.127472  5.887667e-03\n",
       "78566    (3, (16, 6))   946.868896  5.743701e-03\n",
       "78909    (3, (50, 9))     9.000734  5.729656e-03\n",
       "78851    (3, (45, 1))     8.755547  5.690474e-03\n",
       "79145    (3, (74, 5))   135.278091  5.629795e-03\n",
       "78418     (3, (1, 8))   500.308777  5.556394e-03\n",
       "79260    (3, (86, 0))   190.597015  5.555605e-03\n",
       "78771    (3, (37, 1))     1.833119  5.495577e-03\n",
       "79075    (3, (67, 5))     4.997952  5.469946e-03\n",
       "79084    (3, (68, 4))     8.406954  5.449231e-03\n",
       "78994    (3, (59, 4))   221.399734  5.361756e-03\n",
       "78562    (3, (16, 2))    97.034912  5.283684e-03\n",
       "79026    (3, (62, 6))   556.149414  5.191099e-03\n",
       "78853    (3, (45, 3))   281.027283  5.063115e-03\n",
       "79243    (3, (84, 3))     3.131077  5.029937e-03\n",
       "79079    (3, (67, 9))     3.594819  5.021858e-03\n",
       "...               ...          ...           ...\n",
       "75787  (1, (757, 87))     0.000000  1.096822e-12\n",
       "61487  (1, (614, 87))     0.000000  9.148433e-13\n",
       "3087    (1, (30, 87))     0.000000  8.453270e-13\n",
       "14187  (1, (141, 87))     0.000000  8.208397e-13\n",
       "16887  (1, (168, 87))     0.000000  8.078216e-13\n",
       "11287  (1, (112, 87))     0.000000  7.980508e-13\n",
       "11087  (1, (110, 87))     0.000000  7.207136e-13\n",
       "14087  (1, (140, 87))     0.000000  7.048980e-13\n",
       "5787    (1, (57, 87))     0.000000  4.444448e-13\n",
       "5587    (1, (55, 87))     0.000000  4.131297e-13\n",
       "387      (1, (3, 87))     0.000000  3.485248e-13\n",
       "5487    (1, (54, 87))     0.000000  3.334336e-13\n",
       "13687  (1, (136, 87))     0.000000  3.093827e-13\n",
       "11187  (1, (111, 87))     0.000000  2.724575e-13\n",
       "8487    (1, (84, 87))     0.000000  2.279171e-13\n",
       "8387    (1, (83, 87))     0.000000  2.239786e-13\n",
       "287      (1, (2, 87))     0.000000  1.752864e-13\n",
       "5687    (1, (56, 87))     0.000000  1.560832e-13\n",
       "2587    (1, (25, 87))     0.000000  1.444426e-13\n",
       "487      (1, (4, 87))     0.000000  1.374987e-13\n",
       "2787    (1, (27, 87))     0.000000  1.183484e-13\n",
       "13987  (1, (139, 87))     0.000000  8.179100e-14\n",
       "2687    (1, (26, 87))     0.000000  6.232147e-14\n",
       "2987    (1, (29, 87))     0.000000  2.637747e-14\n",
       "87       (1, (0, 87))     0.000000  2.550512e-14\n",
       "78387  (1, (783, 87))     0.000000  2.007098e-14\n",
       "75687  (1, (756, 87))     0.000000  1.766966e-14\n",
       "187      (1, (1, 87))     0.000000  1.656696e-14\n",
       "2887    (1, (28, 87))     0.000000  1.570659e-14\n",
       "8287    (1, (82, 87))     0.000000  1.855714e-15\n",
       "\n",
       "[79400 rows x 3 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=[2,1], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, (93, 6)), 1),\n",
       " ((3, (93, 4)), 2),\n",
       " ((3, (93, 8)), 3),\n",
       " ((3, (93, 0)), 4),\n",
       " ((3, (9, 6)), 5),\n",
       " ((3, (93, 2)), 6),\n",
       " ((3, (45, 6)), 7),\n",
       " ((3, (50, 6)), 8),\n",
       " ((3, (71, 6)), 9),\n",
       " ((3, (45, 4)), 10),\n",
       " ((3, (9, 4)), 11),\n",
       " ((3, (9, 8)), 12),\n",
       " ((3, (5, 4)), 13),\n",
       " ((3, (5, 6)), 14),\n",
       " ((3, (45, 8)), 15),\n",
       " ((3, (46, 7)), 16),\n",
       " ((3, (27, 7)), 17),\n",
       " ((3, (37, 7)), 18),\n",
       " ((3, (33, 7)), 19),\n",
       " ((3, (86, 4)), 20),\n",
       " ((3, (67, 6)), 21),\n",
       " ((3, (74, 4)), 22),\n",
       " ((3, (42, 7)), 23),\n",
       " ((3, (71, 4)), 24),\n",
       " ((3, (74, 6)), 25),\n",
       " ((3, (86, 6)), 26),\n",
       " ((3, (50, 4)), 27),\n",
       " ((3, (67, 4)), 28),\n",
       " ((3, (9, 2)), 29),\n",
       " ((3, (50, 8)), 30),\n",
       " ((3, (45, 2)), 31),\n",
       " ((3, (1, 6)), 32),\n",
       " ((3, (71, 8)), 33),\n",
       " ((1, (343, 48)), 34),\n",
       " ((1, (371, 48)), 35),\n",
       " ((1, (315, 48)), 36),\n",
       " ((3, (34, 7)), 37),\n",
       " ((3, (55, 6)), 38),\n",
       " ((1, (399, 48)), 39),\n",
       " ((1, (287, 48)), 40),\n",
       " ((3, (50, 0)), 41),\n",
       " ((1, (288, 48)), 42),\n",
       " ((1, (441, 48)), 43),\n",
       " ((1, (427, 48)), 44),\n",
       " ((1, (469, 48)), 45),\n",
       " ((1, (413, 48)), 46),\n",
       " ((1, (316, 48)), 47),\n",
       " ((1, (426, 48)), 48),\n",
       " ((1, (385, 48)), 49),\n",
       " ((1, (259, 48)), 50),\n",
       " ((1, (454, 48)), 51),\n",
       " ((1, (497, 48)), 52),\n",
       " ((1, (398, 48)), 53),\n",
       " ((1, (482, 48)), 54),\n",
       " ((1, (260, 48)), 55),\n",
       " ((1, (510, 48)), 56),\n",
       " ((1, (538, 48)), 57),\n",
       " ((1, (455, 48)), 58),\n",
       " ((1, (328, 48)), 59),\n",
       " ((1, (370, 48)), 60),\n",
       " ((3, (59, 6)), 61),\n",
       " ((1, (566, 48)), 62),\n",
       " ((1, (541, 48)), 63),\n",
       " ((1, (300, 48)), 64),\n",
       " ((1, (569, 48)), 65),\n",
       " ((1, (344, 48)), 66),\n",
       " ((1, (342, 48)), 67),\n",
       " ((1, (357, 48)), 68),\n",
       " ((1, (594, 48)), 69),\n",
       " ((1, (231, 48)), 70),\n",
       " ((1, (458, 48)), 71),\n",
       " ((1, (486, 48)), 72),\n",
       " ((1, (525, 48)), 73),\n",
       " ((1, (542, 48)), 74),\n",
       " ((1, (356, 48)), 75),\n",
       " ((1, (329, 48)), 76),\n",
       " ((1, (514, 48)), 77),\n",
       " ((1, (314, 48)), 78),\n",
       " ((1, (430, 48)), 79),\n",
       " ((1, (544, 48)), 80),\n",
       " ((3, (23, 7)), 81),\n",
       " ((1, (513, 48)), 82),\n",
       " ((1, (543, 48)), 83),\n",
       " ((1, (516, 48)), 84),\n",
       " ((1, (550, 48)), 85),\n",
       " ((1, (570, 48)), 86),\n",
       " ((1, (622, 48)), 87),\n",
       " ((1, (597, 48)), 88),\n",
       " ((1, (488, 48)), 89),\n",
       " ((1, (515, 48)), 90),\n",
       " ((1, (483, 48)), 91),\n",
       " ((1, (232, 48)), 92),\n",
       " ((1, (286, 48)), 93),\n",
       " ((1, (272, 48)), 94),\n",
       " ((1, (547, 48)), 95),\n",
       " ((1, (487, 48)), 96),\n",
       " ((3, (93, 3)), 97),\n",
       " ((1, (494, 48)), 98),\n",
       " ((1, (301, 48)), 99),\n",
       " ((1, (571, 48)), 100),\n",
       " ((1, (459, 48)), 101),\n",
       " ((1, (522, 48)), 102),\n",
       " ((1, (572, 48)), 103),\n",
       " ((1, (402, 48)), 104),\n",
       " ((1, (625, 48)), 105),\n",
       " ((1, (553, 48)), 106),\n",
       " ((1, (374, 48)), 107),\n",
       " ((1, (466, 48)), 108),\n",
       " ((1, (548, 48)), 109),\n",
       " ((1, (578, 48)), 110),\n",
       " ((1, (460, 48)), 111),\n",
       " ((1, (545, 48)), 112),\n",
       " ((1, (519, 48)), 113),\n",
       " ((1, (575, 48)), 114),\n",
       " ((1, (485, 48)), 115),\n",
       " ((1, (576, 48)), 116),\n",
       " ((1, (431, 48)), 117),\n",
       " ((1, (573, 48)), 118),\n",
       " ((1, (517, 48)), 119),\n",
       " ((1, (520, 48)), 120),\n",
       " ((1, (273, 48)), 121),\n",
       " ((1, (491, 48)), 122),\n",
       " ((1, (492, 48)), 123),\n",
       " ((1, (432, 48)), 124),\n",
       " ((1, (372, 48)), 125),\n",
       " ((1, (384, 48)), 126),\n",
       " ((1, (346, 48)), 127),\n",
       " ((1, (489, 48)), 128),\n",
       " ((1, (549, 48)), 129),\n",
       " ((1, (546, 48)), 130),\n",
       " ((1, (464, 48)), 131),\n",
       " ((1, (438, 48)), 132),\n",
       " ((1, (203, 48)), 133),\n",
       " ((1, (258, 48)), 134),\n",
       " ((1, (577, 48)), 135),\n",
       " ((1, (493, 48)), 136),\n",
       " ((1, (574, 48)), 137),\n",
       " ((1, (299, 48)), 138),\n",
       " ((1, (461, 48)), 139),\n",
       " ((1, (442, 48)), 140),\n",
       " ((1, (463, 48)), 141),\n",
       " ((1, (465, 48)), 142),\n",
       " ((1, (600, 48)), 143),\n",
       " ((1, (518, 48)), 144),\n",
       " ((1, (521, 48)), 145),\n",
       " ((1, (289, 48)), 146),\n",
       " ((1, (436, 48)), 147),\n",
       " ((1, (403, 48)), 148),\n",
       " ((1, (599, 48)), 149),\n",
       " ((1, (490, 48)), 150),\n",
       " ((1, (470, 48)), 151),\n",
       " ((1, (404, 48)), 152),\n",
       " ((1, (318, 48)), 153),\n",
       " ((1, (204, 48)), 154),\n",
       " ((1, (457, 48)), 155),\n",
       " ((1, (376, 48)), 156),\n",
       " ((1, (375, 48)), 157),\n",
       " ((1, (601, 48)), 158),\n",
       " ((1, (435, 48)), 159),\n",
       " ((1, (598, 48)), 160),\n",
       " ((1, (511, 48)), 161),\n",
       " ((1, (414, 48)), 162),\n",
       " ((1, (410, 48)), 163),\n",
       " ((1, (462, 48)), 164),\n",
       " ((1, (433, 48)), 165),\n",
       " ((1, (581, 48)), 166),\n",
       " ((1, (603, 48)), 167),\n",
       " ((1, (498, 48)), 168),\n",
       " ((1, (317, 48)), 169),\n",
       " ((1, (245, 48)), 170),\n",
       " ((1, (437, 48)), 171),\n",
       " ((1, (244, 48)), 172),\n",
       " ((1, (628, 48)), 173),\n",
       " ((1, (526, 48)), 174),\n",
       " ((1, (380, 48)), 175),\n",
       " ((1, (381, 48)), 176),\n",
       " ((1, (408, 48)), 177),\n",
       " ((1, (271, 48)), 178),\n",
       " ((1, (627, 48)), 179),\n",
       " ((1, (606, 48)), 180),\n",
       " ((1, (554, 48)), 181),\n",
       " ((1, (604, 48)), 182),\n",
       " ((1, (409, 48)), 183),\n",
       " ((1, (602, 48)), 184),\n",
       " ((1, (261, 48)), 185),\n",
       " ((1, (382, 48)), 186),\n",
       " ((1, (434, 48)), 187),\n",
       " ((1, (327, 48)), 188),\n",
       " ((1, (582, 48)), 189),\n",
       " ((1, (650, 48)), 190),\n",
       " ((1, (626, 48)), 191),\n",
       " ((1, (631, 48)), 192),\n",
       " ((1, (290, 48)), 193),\n",
       " ((1, (386, 48)), 194),\n",
       " ((1, (629, 48)), 195),\n",
       " ((1, (407, 48)), 196),\n",
       " ((1, (176, 48)), 197),\n",
       " ((1, (405, 48)), 198),\n",
       " ((1, (632, 48)), 199),\n",
       " ((1, (377, 48)), 200),\n",
       " ((1, (347, 48)), 201),\n",
       " ((1, (605, 48)), 202),\n",
       " ((1, (348, 48)), 203),\n",
       " ((1, (610, 48)), 204),\n",
       " ((1, (634, 48)), 205),\n",
       " ((1, (429, 48)), 206),\n",
       " ((1, (379, 48)), 207),\n",
       " ((1, (630, 48)), 208),\n",
       " ((1, (243, 48)), 209),\n",
       " ((1, (345, 48)), 210),\n",
       " ((1, (205, 48)), 211),\n",
       " ((1, (177, 48)), 212),\n",
       " ((1, (373, 48)), 213),\n",
       " ((1, (406, 48)), 214),\n",
       " ((1, (353, 48)), 215),\n",
       " ((1, (354, 48)), 216),\n",
       " ((1, (326, 48)), 217),\n",
       " ((1, (233, 48)), 218),\n",
       " ((1, (325, 48)), 219),\n",
       " ((1, (633, 48)), 220),\n",
       " ((1, (378, 48)), 221),\n",
       " ((1, (349, 48)), 222),\n",
       " ((1, (401, 48)), 223),\n",
       " ((1, (319, 48)), 224),\n",
       " ((1, (149, 48)), 225),\n",
       " ((1, (262, 48)), 226),\n",
       " ((1, (175, 48)), 227),\n",
       " ((1, (291, 48)), 228),\n",
       " ((1, (352, 48)), 229),\n",
       " ((1, (653, 48)), 230),\n",
       " ((1, (215, 48)), 231),\n",
       " ((1, (638, 48)), 232),\n",
       " ((1, (122, 48)), 233),\n",
       " ((1, (216, 48)), 234),\n",
       " ((1, (350, 48)), 235),\n",
       " ((1, (206, 48)), 236),\n",
       " ((1, (320, 48)), 237),\n",
       " ((1, (355, 48)), 238),\n",
       " ((1, (539, 48)), 239),\n",
       " ((1, (351, 48)), 240),\n",
       " ((1, (358, 48)), 241),\n",
       " ((3, (71, 0)), 242),\n",
       " ((1, (230, 48)), 243),\n",
       " ((1, (412, 48)), 244),\n",
       " ((1, (298, 48)), 245),\n",
       " ((1, (178, 48)), 246),\n",
       " ((1, (217, 48)), 247),\n",
       " ((3, (1, 4)), 248),\n",
       " ((1, (579, 48)), 249),\n",
       " ((1, (187, 48)), 250),\n",
       " ((1, (150, 48)), 251),\n",
       " ((1, (188, 48)), 252),\n",
       " ((1, (234, 48)), 253),\n",
       " ((1, (158, 48)), 254),\n",
       " ((1, (148, 48)), 255),\n",
       " ((1, (324, 48)), 256),\n",
       " ((1, (321, 48)), 257),\n",
       " ((1, (159, 48)), 258),\n",
       " ((1, (270, 48)), 259),\n",
       " ((1, (123, 48)), 260),\n",
       " ((1, (609, 48)), 261),\n",
       " ((1, (129, 48)), 262),\n",
       " ((1, (323, 48)), 263),\n",
       " ((1, (186, 48)), 264),\n",
       " ((1, (551, 48)), 265),\n",
       " ((1, (400, 48)), 266),\n",
       " ((1, (151, 48)), 267),\n",
       " ((1, (185, 48)), 268),\n",
       " ((1, (99, 48)), 269),\n",
       " ((1, (322, 48)), 270),\n",
       " ((1, (153, 48)), 271),\n",
       " ((1, (157, 48)), 272),\n",
       " ((1, (295, 48)), 273),\n",
       " ((1, (214, 48)), 274),\n",
       " ((1, (96, 48)), 275),\n",
       " ((1, (297, 48)), 276),\n",
       " ((1, (95, 48)), 277),\n",
       " ((1, (127, 48)), 278),\n",
       " ((1, (292, 48)), 279),\n",
       " ((1, (263, 48)), 280),\n",
       " ((1, (296, 48)), 281),\n",
       " ((1, (152, 48)), 282),\n",
       " ((1, (124, 48)), 283),\n",
       " ((1, (330, 48)), 284),\n",
       " ((1, (659, 48)), 285),\n",
       " ((1, (155, 48)), 286),\n",
       " ((1, (154, 48)), 287),\n",
       " ((1, (156, 48)), 288),\n",
       " ((1, (656, 48)), 289),\n",
       " ((1, (241, 48)), 290),\n",
       " ((1, (125, 48)), 291),\n",
       " ((1, (607, 48)), 292),\n",
       " ((1, (383, 48)), 293),\n",
       " ((1, (126, 48)), 294),\n",
       " ((1, (179, 48)), 295),\n",
       " ((1, (128, 48)), 296),\n",
       " ((1, (657, 48)), 297),\n",
       " ((1, (655, 48)), 298),\n",
       " ((1, (242, 48)), 299),\n",
       " ((1, (264, 48)), 300),\n",
       " ((1, (294, 48)), 301),\n",
       " ((1, (182, 48)), 302),\n",
       " ((1, (293, 48)), 303),\n",
       " ((1, (207, 48)), 304),\n",
       " ((1, (660, 48)), 305),\n",
       " ((1, (654, 48)), 306),\n",
       " ((1, (267, 48)), 307),\n",
       " ((1, (130, 48)), 308),\n",
       " ((1, (235, 48)), 309),\n",
       " ((1, (213, 48)), 310),\n",
       " ((1, (236, 48)), 311),\n",
       " ((1, (181, 48)), 312),\n",
       " ((1, (183, 48)), 313),\n",
       " ((1, (658, 48)), 314),\n",
       " ((1, (94, 48)), 315),\n",
       " ((1, (635, 48)), 316),\n",
       " ((1, (678, 48)), 317),\n",
       " ((1, (666, 48)), 318),\n",
       " ((1, (184, 48)), 319),\n",
       " ((1, (269, 48)), 320),\n",
       " ((1, (239, 48)), 321),\n",
       " ((1, (662, 48)), 322),\n",
       " ((1, (523, 48)), 323),\n",
       " ((1, (240, 48)), 324),\n",
       " ((1, (180, 48)), 325),\n",
       " ((1, (237, 48)), 326),\n",
       " ((1, (71, 48)), 327),\n",
       " ((1, (211, 48)), 328),\n",
       " ((1, (100, 48)), 329),\n",
       " ((1, (268, 48)), 330),\n",
       " ((1, (68, 48)), 331),\n",
       " ((1, (101, 48)), 332),\n",
       " ((1, (97, 48)), 333),\n",
       " ((1, (661, 48)), 334),\n",
       " ((1, (72, 48)), 335),\n",
       " ((1, (266, 48)), 336),\n",
       " ((1, (238, 48)), 337),\n",
       " ((1, (212, 48)), 338),\n",
       " ((1, (121, 48)), 339),\n",
       " ((1, (98, 48)), 340),\n",
       " ((1, (209, 48)), 341),\n",
       " ((1, (210, 48)), 342),\n",
       " ((1, (265, 48)), 343),\n",
       " ((1, (208, 48)), 344),\n",
       " ((1, (567, 48)), 345),\n",
       " ((1, (160, 48)), 346),\n",
       " ((1, (440, 48)), 347),\n",
       " ((1, (411, 48)), 348),\n",
       " ((1, (467, 48)), 349),\n",
       " ((1, (495, 48)), 350),\n",
       " ((1, (439, 48)), 351),\n",
       " ((1, (637, 48)), 352),\n",
       " ((1, (428, 48)), 353),\n",
       " ((1, (302, 48)), 354),\n",
       " ((1, (69, 48)), 355),\n",
       " ((3, (8, 4)), 356),\n",
       " ((1, (481, 48)), 357),\n",
       " ((1, (147, 48)), 358),\n",
       " ((1, (509, 48)), 359),\n",
       " ((1, (189, 48)), 360),\n",
       " ((1, (202, 48)), 361),\n",
       " ((1, (663, 48)), 362),\n",
       " ((1, (67, 48)), 363),\n",
       " ((1, (453, 48)), 364),\n",
       " ((3, (40, 7)), 365),\n",
       " ((1, (565, 48)), 366),\n",
       " ((1, (537, 48)), 367),\n",
       " ((3, (70, 7)), 368),\n",
       " ((1, (694, 48)), 369),\n",
       " ((1, (468, 48)), 370),\n",
       " ((1, (425, 48)), 371),\n",
       " ((1, (706, 48)), 372),\n",
       " ((1, (456, 48)), 373),\n",
       " ((1, (70, 48)), 374),\n",
       " ((1, (593, 48)), 375),\n",
       " ((1, (102, 48)), 376),\n",
       " ((1, (40, 48)), 377),\n",
       " ((1, (44, 48)), 378),\n",
       " ((1, (131, 48)), 379),\n",
       " ((1, (43, 48)), 380),\n",
       " ((1, (73, 48)), 381),\n",
       " ((1, (595, 48)), 382),\n",
       " ((1, (621, 48)), 383),\n",
       " ((1, (681, 48)), 384),\n",
       " ((1, (397, 48)), 385),\n",
       " ((3, (14, 4)), 386),\n",
       " ((3, (62, 7)), 387),\n",
       " ((1, (484, 48)), 388),\n",
       " ((1, (41, 48)), 389),\n",
       " ((1, (274, 48)), 390),\n",
       " ((1, (496, 48)), 391),\n",
       " ((1, (541, 76)), 392),\n",
       " ((1, (120, 48)), 393),\n",
       " ((1, (665, 48)), 394),\n",
       " ((1, (687, 48)), 395),\n",
       " ((1, (569, 76)), 396),\n",
       " ((1, (684, 48)), 397),\n",
       " ((1, (688, 48)), 398),\n",
       " ((1, (512, 48)), 399),\n",
       " ((1, (685, 48)), 400),\n",
       " ((1, (686, 48)), 401),\n",
       " ((1, (683, 48)), 402),\n",
       " ((1, (682, 48)), 403),\n",
       " ((1, (690, 48)), 404),\n",
       " ((1, (513, 76)), 405),\n",
       " ((1, (722, 48)), 406),\n",
       " ((1, (540, 48)), 407),\n",
       " ((1, (649, 48)), 408),\n",
       " ((1, (42, 48)), 409),\n",
       " ((1, (546, 76)), 410),\n",
       " ((1, (544, 76)), 411),\n",
       " ((1, (545, 76)), 412),\n",
       " ((1, (689, 48)), 413),\n",
       " ((1, (547, 76)), 414),\n",
       " ((1, (369, 48)), 415),\n",
       " ((1, (543, 76)), 416),\n",
       " ((1, (548, 76)), 417),\n",
       " ((1, (66, 48)), 418),\n",
       " ((1, (549, 76)), 419),\n",
       " ((1, (568, 48)), 420),\n",
       " ((1, (300, 76)), 421),\n",
       " ((1, (571, 76)), 422),\n",
       " ((1, (597, 76)), 423),\n",
       " ((1, (572, 76)), 424),\n",
       " ((1, (518, 76)), 425),\n",
       " ((1, (570, 76)), 426),\n",
       " ((1, (574, 76)), 427),\n",
       " ((1, (485, 76)), 428),\n",
       " ((1, (519, 76)), 429),\n",
       " ((1, (575, 76)), 430),\n",
       " ((1, (516, 76)), 431),\n",
       " ((1, (517, 76)), 432),\n",
       " ((1, (542, 76)), 433),\n",
       " ((1, (573, 76)), 434),\n",
       " ((1, (93, 48)), 435),\n",
       " ((1, (524, 48)), 436),\n",
       " ((1, (576, 76)), 437),\n",
       " ((1, (486, 76)), 438),\n",
       " ((1, (514, 76)), 439),\n",
       " ((1, (328, 76)), 440),\n",
       " ((1, (272, 76)), 441),\n",
       " ((1, (623, 48)), 442),\n",
       " ((1, (520, 76)), 443),\n",
       " ((1, (462, 76)), 444),\n",
       " ((1, (522, 76)), 445),\n",
       " ((1, (577, 76)), 446),\n",
       " ((1, (521, 76)), 447),\n",
       " ((1, (515, 76)), 448),\n",
       " ((1, (491, 76)), 449),\n",
       " ((1, (490, 76)), 450),\n",
       " ((1, (550, 76)), 451),\n",
       " ((1, (489, 76)), 452),\n",
       " ((1, (596, 48)), 453),\n",
       " ((1, (487, 76)), 454),\n",
       " ((1, (522, 90)), 455),\n",
       " ((1, (457, 76)), 456),\n",
       " ((1, (463, 76)), 457),\n",
       " ((1, (599, 76)), 458),\n",
       " ((1, (601, 76)), 459),\n",
       " ((1, (494, 76)), 460),\n",
       " ((1, (602, 76)), 461),\n",
       " ((1, (488, 76)), 462),\n",
       " ((1, (578, 76)), 463),\n",
       " ((1, (600, 76)), 464),\n",
       " ((1, (299, 76)), 465),\n",
       " ((1, (327, 76)), 466),\n",
       " ((3, (27, 9)), 467),\n",
       " ((1, (598, 76)), 468),\n",
       " ((1, (493, 76)), 469),\n",
       " ((1, (603, 76)), 470),\n",
       " ((1, (174, 48)), 471),\n",
       " ((1, (461, 76)), 472),\n",
       " ((1, (356, 76)), 473),\n",
       " ((1, (459, 76)), 474),\n",
       " ((1, (492, 76)), 475),\n",
       " ((1, (458, 76)), 476),\n",
       " ((1, (271, 76)), 477),\n",
       " ((1, (434, 76)), 478),\n",
       " ((3, (66, 4)), 479),\n",
       " ((1, (460, 76)), 480),\n",
       " ((1, (435, 76)), 481),\n",
       " ((1, (466, 76)), 482),\n",
       " ((1, (552, 48)), 483),\n",
       " ((1, (518, 62)), 484),\n",
       " ((1, (161, 48)), 485),\n",
       " ((1, (355, 76)), 486),\n",
       " ((1, (604, 76)), 487),\n",
       " ((1, (518, 90)), 488),\n",
       " ((1, (625, 76)), 489),\n",
       " ((1, (244, 76)), 490),\n",
       " ((1, (517, 90)), 491),\n",
       " ((1, (465, 76)), 492),\n",
       " ((1, (132, 48)), 493),\n",
       " ((1, (433, 76)), 494),\n",
       " ((1, (551, 76)), 495),\n",
       " ((1, (382, 76)), 496),\n",
       " ((1, (519, 90)), 497),\n",
       " ((1, (519, 62)), 498),\n",
       " ((1, (410, 76)), 499),\n",
       " ((1, (431, 76)), 500),\n",
       " ((1, (438, 76)), 501),\n",
       " ((1, (523, 62)), 502),\n",
       " ((1, (325, 76)), 503),\n",
       " ((1, (429, 76)), 504),\n",
       " ((1, (677, 48)), 505),\n",
       " ((1, (379, 76)), 506),\n",
       " ((1, (407, 76)), 507),\n",
       " ((1, (341, 48)), 508),\n",
       " ((1, (436, 76)), 509),\n",
       " ((1, (605, 76)), 510),\n",
       " ((1, (522, 62)), 511),\n",
       " ((1, (494, 90)), 512),\n",
       " ((1, (734, 48)), 513),\n",
       " ((1, (579, 76)), 514),\n",
       " ((1, (430, 76)), 515),\n",
       " ((1, (432, 76)), 516),\n",
       " ((1, (297, 76)), 517),\n",
       " ((1, (406, 76)), 518),\n",
       " ((1, (624, 48)), 519),\n",
       " ((1, (437, 76)), 520),\n",
       " ((1, (464, 76)), 521),\n",
       " ((1, (523, 76)), 522),\n",
       " ((1, (521, 62)), 523),\n",
       " ((1, (606, 76)), 524),\n",
       " ((1, (288, 76)), 525),\n",
       " ((1, (517, 62)), 526),\n",
       " ((3, (55, 4)), 527),\n",
       " ((1, (354, 76)), 528),\n",
       " ((1, (353, 76)), 529),\n",
       " ((1, (381, 76)), 530),\n",
       " ((1, (351, 76)), 531),\n",
       " ((1, (243, 76)), 532),\n",
       " ((1, (409, 76)), 533),\n",
       " ((1, (693, 48)), 534),\n",
       " ((1, (520, 90)), 535),\n",
       " ((1, (629, 76)), 536),\n",
       " ((1, (691, 48)), 537),\n",
       " ((1, (326, 76)), 538),\n",
       " ((1, (630, 76)), 539),\n",
       " ((1, (494, 62)), 540),\n",
       " ((1, (466, 90)), 541),\n",
       " ((1, (408, 76)), 542),\n",
       " ((1, (260, 76)), 543),\n",
       " ((1, (521, 90)), 544),\n",
       " ((1, (298, 76)), 545),\n",
       " ((1, (352, 76)), 546),\n",
       " ((1, (384, 76)), 547),\n",
       " ((1, (378, 76)), 548),\n",
       " ((1, (493, 62)), 549),\n",
       " ((1, (246, 48)), 550),\n",
       " ((1, (628, 76)), 551),\n",
       " ((1, (466, 62)), 552),\n",
       " ((1, (405, 76)), 553),\n",
       " ((1, (438, 90)), 554),\n",
       " ((1, (607, 76)), 555),\n",
       " ((1, (627, 76)), 556),\n",
       " ((1, (520, 62)), 557),\n",
       " ((1, (316, 76)), 558),\n",
       " ((1, (495, 62)), 559),\n",
       " ((3, (33, 9)), 560),\n",
       " ((1, (383, 76)), 561),\n",
       " ((1, (580, 48)), 562),\n",
       " ((1, (631, 76)), 563),\n",
       " ((1, (380, 76)), 564),\n",
       " ((1, (377, 76)), 565),\n",
       " ((1, (404, 76)), 566),\n",
       " ((1, (324, 76)), 567),\n",
       " ((1, (490, 62)), 568),\n",
       " ((1, (491, 62)), 569),\n",
       " ((1, (490, 90)), 570),\n",
       " ((1, (270, 76)), 571),\n",
       " ((1, (546, 90)), 572),\n",
       " ((1, (516, 90)), 573),\n",
       " ((1, (495, 76)), 574),\n",
       " ((3, (99, 7)), 575),\n",
       " ((1, (403, 76)), 576),\n",
       " ((1, (382, 62)), 577),\n",
       " ((1, (626, 76)), 578),\n",
       " ((1, (545, 90)), 579),\n",
       " ((1, (232, 76)), 580),\n",
       " ((1, (462, 90)), 581),\n",
       " ((1, (438, 62)), 582),\n",
       " ((1, (39, 48)), 583),\n",
       " ((1, (402, 76)), 584),\n",
       " ((1, (269, 76)), 585),\n",
       " ((1, (491, 90)), 586),\n",
       " ((1, (410, 62)), 587),\n",
       " ((1, (410, 90)), 588),\n",
       " ((1, (462, 62)), 589),\n",
       " ((1, (382, 90)), 590),\n",
       " ((1, (492, 62)), 591),\n",
       " ((1, (493, 90)), 592),\n",
       " ((1, (632, 76)), 593),\n",
       " ((1, (411, 76)), 594),\n",
       " ((1, (547, 90)), 595),\n",
       " ((1, (323, 76)), 596),\n",
       " ((1, (489, 62)), 597),\n",
       " ((1, (489, 90)), 598),\n",
       " ((1, (541, 90)), 599),\n",
       " ((1, (467, 62)), 600),\n",
       " ((1, (272, 62)), 601),\n",
       " ((1, (376, 76)), 602),\n",
       " ((1, (465, 62)), 603),\n",
       " ((1, (350, 76)), 604),\n",
       " ((1, (492, 90)), 605),\n",
       " ((1, (344, 76)), 606),\n",
       " ((1, (653, 76)), 607),\n",
       " ((1, (467, 76)), 608),\n",
       " ((1, (401, 76)), 609),\n",
       " ((1, (384, 90)), 610),\n",
       " ((1, (463, 62)), 611),\n",
       " ((1, (513, 90)), 612),\n",
       " ((1, (242, 76)), 613),\n",
       " ((1, (515, 90)), 614),\n",
       " ((1, (349, 76)), 615),\n",
       " ((1, (463, 90)), 616),\n",
       " ((1, (657, 76)), 617),\n",
       " ((1, (544, 90)), 618),\n",
       " ((1, (523, 90)), 619),\n",
       " ((1, (296, 76)), 620),\n",
       " ((1, (300, 62)), 621),\n",
       " ((1, (295, 76)), 622),\n",
       " ((1, (543, 90)), 623),\n",
       " ((1, (633, 76)), 624),\n",
       " ((1, (215, 76)), 625),\n",
       " ((1, (411, 62)), 626),\n",
       " ((1, (465, 90)), 627),\n",
       " ((1, (439, 76)), 628),\n",
       " ((1, (464, 62)), 629),\n",
       " ((1, (439, 62)), 630),\n",
       " ((1, (516, 62)), 631),\n",
       " ((1, (550, 90)), 632),\n",
       " ((1, (656, 76)), 633),\n",
       " ((1, (412, 76)), 634),\n",
       " ((1, (658, 76)), 635),\n",
       " ((1, (750, 48)), 636),\n",
       " ((1, (546, 62)), 637),\n",
       " ((1, (634, 76)), 638),\n",
       " ((1, (548, 90)), 639),\n",
       " ((1, (436, 62)), 640),\n",
       " ((1, (635, 76)), 641),\n",
       " ((1, (383, 62)), 642),\n",
       " ((1, (464, 90)), 643),\n",
       " ((1, (545, 62)), 644),\n",
       " ((1, (513, 62)), 645),\n",
       " ((1, (659, 76)), 646),\n",
       " ((1, (435, 90)), 647),\n",
       " ((1, (436, 90)), 648),\n",
       " ((1, (241, 76)), 649),\n",
       " ((1, (461, 90)), 650),\n",
       " ((1, (461, 62)), 651),\n",
       " ((1, (514, 90)), 652),\n",
       " ((1, (216, 76)), 653),\n",
       " ((1, (681, 76)), 654),\n",
       " ((1, (434, 90)), 655),\n",
       " ((1, (354, 62)), 656),\n",
       " ((1, (322, 76)), 657),\n",
       " ((1, (488, 90)), 658),\n",
       " ((1, (375, 76)), 659),\n",
       " ((1, (655, 76)), 660),\n",
       " ((1, (435, 62)), 661),\n",
       " ((1, (437, 62)), 662),\n",
       " ((1, (547, 62)), 663),\n",
       " ((1, (685, 76)), 664),\n",
       " ((1, (686, 76)), 665),\n",
       " ((1, (549, 90)), 666),\n",
       " ((1, (437, 90)), 667),\n",
       " ((1, (214, 76)), 668),\n",
       " ((1, (412, 90)), 669),\n",
       " ((1, (268, 76)), 670),\n",
       " ((1, (373, 76)), 671),\n",
       " ((1, (383, 90)), 672),\n",
       " ((1, (289, 76)), 673),\n",
       " ((1, (374, 76)), 674),\n",
       " ((1, (495, 90)), 675),\n",
       " ((1, (204, 76)), 676),\n",
       " ((1, (356, 90)), 677),\n",
       " ((1, (408, 62)), 678),\n",
       " ((1, (488, 62)), 679),\n",
       " ((3, (19, 4)), 680),\n",
       " ((1, (327, 90)), 681),\n",
       " ((1, (684, 76)), 682),\n",
       " ((1, (355, 90)), 683),\n",
       " ((1, (326, 62)), 684),\n",
       " ((1, (348, 76)), 685),\n",
       " ((1, (485, 90)), 686),\n",
       " ((1, (542, 90)), 687),\n",
       " ((1, (74, 48)), 688),\n",
       " ((1, (487, 90)), 689),\n",
       " ((1, (515, 62)), 690),\n",
       " ((1, (355, 62)), 691),\n",
       " ((1, (654, 76)), 692),\n",
       " ((1, (434, 62)), 693),\n",
       " ((1, (313, 48)), 694),\n",
       " ((1, (261, 76)), 695),\n",
       " ((1, (407, 62)), 696),\n",
       " ((1, (317, 76)), 697),\n",
       " ((1, (287, 76)), 698),\n",
       " ((1, (408, 90)), 699),\n",
       " ((1, (660, 76)), 700),\n",
       " ((1, (345, 76)), 701),\n",
       " ((1, (267, 76)), 702),\n",
       " ((1, (409, 62)), 703),\n",
       " ((1, (687, 76)), 704),\n",
       " ((1, (651, 48)), 705),\n",
       " ((1, (549, 62)), 706),\n",
       " ((1, (381, 62)), 707),\n",
       " ((1, (468, 90)), 708),\n",
       " ((1, (354, 90)), 709),\n",
       " ((1, (259, 76)), 710),\n",
       " ((1, (294, 76)), 711),\n",
       " ((1, (409, 90)), 712),\n",
       " ((1, (433, 90)), 713),\n",
       " ((1, (548, 62)), 714),\n",
       " ((1, (372, 76)), 715),\n",
       " ((1, (688, 76)), 716),\n",
       " ((1, (440, 90)), 717),\n",
       " ((1, (381, 90)), 718),\n",
       " ((1, (661, 76)), 719),\n",
       " ((1, (467, 90)), 720),\n",
       " ((1, (321, 76)), 721),\n",
       " ((1, (315, 76)), 722),\n",
       " ((1, (683, 76)), 723),\n",
       " ((1, (411, 90)), 724),\n",
       " ((1, (544, 62)), 725),\n",
       " ((1, (487, 62)), 726),\n",
       " ((1, (353, 62)), 727),\n",
       " ((1, (299, 90)), 728),\n",
       " ((1, (439, 90)), 729),\n",
       " ((1, (119, 48)), 730),\n",
       " ((1, (407, 90)), 731),\n",
       " ((1, (608, 48)), 732),\n",
       " ((1, (233, 76)), 733),\n",
       " ((1, (486, 90)), 734),\n",
       " ((1, (514, 62)), 735),\n",
       " ((1, (541, 62)), 736),\n",
       " ((1, (347, 76)), 737),\n",
       " ((1, (689, 76)), 738),\n",
       " ((1, (231, 76)), 739),\n",
       " ((1, (540, 76)), 740),\n",
       " ((1, (353, 90)), 741),\n",
       " ((1, (326, 90)), 742),\n",
       " ((1, (682, 76)), 743),\n",
       " ((1, (568, 76)), 744),\n",
       " ((1, (380, 90)), 745),\n",
       " ((1, (485, 62)), 746),\n",
       " ((1, (328, 90)), 747),\n",
       " ((1, (187, 76)), 748),\n",
       " ((1, (551, 62)), 749),\n",
       " ((1, (379, 90)), 750),\n",
       " ((1, (705, 48)), 751),\n",
       " ((1, (325, 62)), 752),\n",
       " ((1, (325, 90)), 753),\n",
       " ((1, (244, 62)), 754),\n",
       " ((1, (320, 76)), 755),\n",
       " ((1, (240, 76)), 756),\n",
       " ((1, (346, 76)), 757),\n",
       " ((1, (440, 76)), 758),\n",
       " ((1, (460, 90)), 759),\n",
       " ((1, (652, 48)), 760),\n",
       " ((1, (524, 90)), 761),\n",
       " ((1, (543, 62)), 762),\n",
       " ((1, (406, 90)), 763),\n",
       " ((3, (66, 6)), 764),\n",
       " ((1, (298, 62)), 765),\n",
       " ((3, (42, 9)), 766),\n",
       " ((1, (406, 62)), 767),\n",
       " ((1, (496, 90)), 768),\n",
       " ((1, (328, 62)), 769),\n",
       " ((1, (663, 76)), 770),\n",
       " ((1, (266, 76)), 771),\n",
       " ((1, (380, 62)), 772),\n",
       " ((1, (318, 76)), 773),\n",
       " ((1, (327, 62)), 774),\n",
       " ((1, (213, 76)), 775),\n",
       " ((1, (352, 62)), 776),\n",
       " ((1, (459, 90)), 777),\n",
       " ((1, (352, 90)), 778),\n",
       " ((1, (290, 76)), 779),\n",
       " ((1, (379, 62)), 780),\n",
       " ((1, (433, 62)), 781),\n",
       " ((1, (273, 62)), 782),\n",
       " ((1, (460, 62)), 783),\n",
       " ((1, (690, 76)), 784),\n",
       " ((1, (324, 62)), 785),\n",
       " ((1, (550, 62)), 786),\n",
       " ((1, (596, 76)), 787),\n",
       " ((1, (662, 76)), 788),\n",
       " ((1, (512, 76)), 789),\n",
       " ((1, (239, 76)), 790),\n",
       " ((1, (186, 76)), 791),\n",
       " ((1, (262, 76)), 792),\n",
       " ((1, (205, 76)), 793),\n",
       " ((1, (176, 76)), 794),\n",
       " ((1, (569, 90)), 795),\n",
       " ((1, (484, 76)), 796),\n",
       " ((1, (486, 62)), 797),\n",
       " ((1, (324, 90)), 798),\n",
       " ((1, (691, 76)), 799),\n",
       " ((1, (292, 76)), 800),\n",
       " ((1, (319, 76)), 801),\n",
       " ((1, (378, 90)), 802),\n",
       " ((1, (271, 90)), 803),\n",
       " ((1, (468, 76)), 804),\n",
       " ((1, (400, 76)), 805),\n",
       " ((1, (293, 76)), 806),\n",
       " ((1, (573, 90)), 807),\n",
       " ((1, (456, 76)), 808),\n",
       " ((1, (297, 62)), 809),\n",
       " ((1, (103, 48)), 810),\n",
       " ((1, (291, 76)), 811),\n",
       " ((1, (351, 90)), 812),\n",
       " ((1, (299, 62)), 813),\n",
       " ((1, (300, 90)), 814),\n",
       " ((1, (551, 90)), 815),\n",
       " ((1, (574, 90)), 816),\n",
       " ((1, (428, 76)), 817),\n",
       " ((1, (264, 76)), 818),\n",
       " ((1, (457, 90)), 819),\n",
       " ((1, (265, 76)), 820),\n",
       " ((1, (301, 62)), 821),\n",
       " ((1, (542, 62)), 822),\n",
       " ((1, (458, 90)), 823),\n",
       " ((1, (234, 76)), 824),\n",
       " ((1, (203, 76)), 825),\n",
       " ((1, (263, 76)), 826),\n",
       " ((1, (149, 76)), 827),\n",
       " ((1, (298, 90)), 828),\n",
       " ((1, (271, 62)), 829),\n",
       " ((1, (343, 76)), 830),\n",
       " ((1, (351, 62)), 831),\n",
       " ((1, (459, 62)), 832),\n",
       " ((1, (238, 76)), 833),\n",
       " ((1, (457, 62)), 834),\n",
       " ((1, (624, 76)), 835),\n",
       " ((1, (177, 76)), 836),\n",
       " ((1, (378, 62)), 837),\n",
       " ((1, (572, 90)), 838),\n",
       " ((3, (46, 9)), 839),\n",
       " ((1, (212, 76)), 840),\n",
       " ((1, (432, 90)), 841),\n",
       " ((1, (297, 90)), 842),\n",
       " ((1, (188, 76)), 843),\n",
       " ((1, (571, 90)), 844),\n",
       " ((1, (185, 76)), 845),\n",
       " ((1, (405, 90)), 846),\n",
       " ((1, (570, 90)), 847),\n",
       " ((1, (210, 76)), 848),\n",
       " ((1, (511, 76)), 849),\n",
       " ((1, (211, 76)), 850),\n",
       " ((1, (525, 90)), 851),\n",
       " ((1, (158, 76)), 852),\n",
       " ((1, (182, 76)), 853),\n",
       " ((1, (575, 90)), 854),\n",
       " ((1, (483, 76)), 855),\n",
       " ((1, (496, 76)), 856),\n",
       " ((1, (206, 76)), 857),\n",
       " ((1, (159, 76)), 858),\n",
       " ((1, (583, 48)), 859),\n",
       " ((1, (45, 48)), 860),\n",
       " ((1, (235, 76)), 861),\n",
       " ((1, (178, 76)), 862),\n",
       " ((1, (721, 48)), 863),\n",
       " ((1, (150, 76)), 864),\n",
       " ((1, (243, 62)), 865),\n",
       " ((1, (236, 76)), 866),\n",
       " ((1, (329, 62)), 867),\n",
       " ((1, (237, 76)), 868),\n",
       " ((1, (455, 76)), 869),\n",
       " ((1, (524, 76)), 870),\n",
       " ((1, (431, 90)), 871),\n",
       " ((1, (611, 48)), 872),\n",
       " ((1, (209, 76)), 873),\n",
       " ((1, (148, 76)), 874),\n",
       " ((1, (377, 90)), 875),\n",
       " ((1, (273, 76)), 876),\n",
       " ((1, (154, 76)), 877),\n",
       " ((1, (323, 90)), 878),\n",
       " ((1, (555, 48)), 879),\n",
       " ((1, (713, 76)), 880),\n",
       " ((1, (469, 90)), 881),\n",
       " ((1, (458, 62)), 882),\n",
       " ((1, (270, 62)), 883),\n",
       " ((1, (578, 90)), 884),\n",
       " ((1, (207, 76)), 885),\n",
       " ((1, (539, 76)), 886),\n",
       " ((1, (153, 76)), 887),\n",
       " ((1, (497, 90)), 888),\n",
       " ((1, (714, 76)), 889),\n",
       " ((1, (709, 76)), 890),\n",
       " ((1, (181, 76)), 891),\n",
       " ((1, (576, 90)), 892),\n",
       " ((1, (126, 76)), 893),\n",
       " ((1, (512, 90)), 894),\n",
       " ((1, (511, 90)), 895),\n",
       " ((1, (636, 48)), 896),\n",
       " ((1, (712, 76)), 897),\n",
       " ((1, (296, 90)), 898),\n",
       " ((1, (301, 76)), 899),\n",
       " ((1, (124, 76)), 900),\n",
       " ((1, (208, 76)), 901),\n",
       " ((1, (179, 76)), 902),\n",
       " ((1, (552, 76)), 903),\n",
       " ((1, (405, 62)), 904),\n",
       " ((1, (183, 76)), 905),\n",
       " ((1, (285, 48)), 906),\n",
       " ((1, (527, 48)), 907),\n",
       " ((1, (184, 76)), 908),\n",
       " ((1, (157, 76)), 909),\n",
       " ((1, (243, 90)), 910),\n",
       " ((1, (125, 76)), 911),\n",
       " ((1, (569, 62)), 912),\n",
       " ((1, (432, 62)), 913),\n",
       " ((1, (441, 90)), 914),\n",
       " ((1, (577, 90)), 915),\n",
       " ((1, (427, 76)), 916),\n",
       " ((1, (127, 76)), 917),\n",
       " ((1, (270, 90)), 918),\n",
       " ((1, (639, 48)), 919),\n",
       " ((1, (323, 62)), 920),\n",
       " ((1, (296, 62)), 921),\n",
       " ((1, (413, 90)), 922),\n",
       " ((1, (152, 76)), 923),\n",
       " ((1, (371, 76)), 924),\n",
       " ((1, (350, 90)), 925),\n",
       " ((1, (245, 76)), 926),\n",
       " ((1, (715, 76)), 927),\n",
       " ((1, (597, 90)), 928),\n",
       " ((1, (540, 90)), 929),\n",
       " ((1, (272, 90)), 930),\n",
       " ((1, (155, 76)), 931),\n",
       " ((1, (68, 76)), 932),\n",
       " ((1, (711, 76)), 933),\n",
       " ((1, (180, 76)), 934),\n",
       " ((1, (385, 90)), 935),\n",
       " ((1, (356, 62)), 936),\n",
       " ((1, (242, 62)), 937),\n",
       " ((1, (430, 90)), 938),\n",
       " ((1, (652, 76)), 939),\n",
       " ((1, (40, 76)), 940),\n",
       " ((1, (121, 76)), 941),\n",
       " ((1, (404, 90)), 942),\n",
       " ((1, (269, 62)), 943),\n",
       " ((1, (329, 76)), 944),\n",
       " ((1, (71, 76)), 945),\n",
       " ((1, (156, 76)), 946),\n",
       " ((1, (483, 90)), 947),\n",
       " ((1, (710, 76)), 948),\n",
       " ((1, (601, 90)), 949),\n",
       " ((1, (574, 62)), 950),\n",
       " ((1, (151, 76)), 951),\n",
       " ((1, (245, 62)), 952),\n",
       " ((1, (175, 76)), 953),\n",
       " ((1, (96, 76)), 954),\n",
       " ((1, (716, 76)), 955),\n",
       " ((1, (218, 48)), 956),\n",
       " ((1, (499, 48)), 957),\n",
       " ((1, (573, 62)), 958),\n",
       " ((1, (99, 76)), 959),\n",
       " ((1, (399, 76)), 960),\n",
       " ((1, (120, 76)), 961),\n",
       " ((1, (575, 62)), 962),\n",
       " ((1, (602, 90)), 963),\n",
       " ((1, (122, 76)), 964),\n",
       " ((1, (718, 76)), 965),\n",
       " ((1, (269, 90)), 966),\n",
       " ((1, (484, 90)), 967),\n",
       " ((1, (431, 62)), 968),\n",
       " ((1, (717, 76)), 969),\n",
       " ((1, (123, 76)), 970),\n",
       " ((1, (95, 76)), 971),\n",
       " ((1, (680, 76)), 972),\n",
       " ((1, (552, 90)), 973),\n",
       " ((1, (567, 76)), 974),\n",
       " ((1, (131, 76)), 975),\n",
       " ((1, (242, 90)), 976),\n",
       " ((1, (130, 76)), 977),\n",
       " ((1, (600, 90)), 978),\n",
       " ((1, (128, 76)), 979),\n",
       " ((1, (599, 90)), 980),\n",
       " ((1, (97, 76)), 981),\n",
       " ((1, (572, 62)), 982),\n",
       " ((1, (598, 90)), 983),\n",
       " ((3, (25, 6)), 984),\n",
       " ((1, (160, 76)), 985),\n",
       " ((1, (709, 48)), 986),\n",
       " ((1, (580, 76)), 987),\n",
       " ((1, (384, 62)), 988),\n",
       " ((1, (350, 62)), 989),\n",
       " ((1, (43, 76)), 990),\n",
       " ((1, (579, 90)), 991),\n",
       " ((1, (576, 62)), 992),\n",
       " ((1, (129, 76)), 993),\n",
       " ((1, (404, 62)), 994),\n",
       " ((1, (98, 76)), 995),\n",
       " ((1, (577, 62)), 996),\n",
       " ((1, (67, 76)), 997),\n",
       " ((1, (539, 90)), 998),\n",
       " ((1, (94, 76)), 999),\n",
       " ((1, (571, 62)), 1000),\n",
       " ...]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pairs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3, (93, 6))</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, (93, 4))</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3, (93, 8))</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3, (93, 0))</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(3, (9, 6))</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(3, (93, 2))</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(3, (45, 6))</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(3, (50, 6))</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(3, (71, 6))</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(3, (45, 4))</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(3, (9, 4))</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(3, (9, 8))</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, (5, 4))</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, (5, 6))</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, (45, 8))</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, (46, 7))</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(3, (27, 7))</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(3, (37, 7))</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(3, (33, 7))</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(3, (86, 4))</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(3, (67, 6))</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(3, (74, 4))</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(3, (42, 7))</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(3, (71, 4))</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(3, (74, 6))</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(3, (86, 6))</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(3, (50, 4))</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(3, (67, 4))</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(3, (9, 2))</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(3, (50, 8))</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79370</th>\n",
       "      <td>(1, (772, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79371</th>\n",
       "      <td>(1, (773, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79372</th>\n",
       "      <td>(1, (774, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79373</th>\n",
       "      <td>(1, (775, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79374</th>\n",
       "      <td>(1, (776, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79375</th>\n",
       "      <td>(1, (777, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79376</th>\n",
       "      <td>(1, (778, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79377</th>\n",
       "      <td>(1, (779, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79378</th>\n",
       "      <td>(1, (780, 39))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79379</th>\n",
       "      <td>(1, (780, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79380</th>\n",
       "      <td>(1, (781, 39))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79381</th>\n",
       "      <td>(1, (781, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79382</th>\n",
       "      <td>(1, (782, 39))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79383</th>\n",
       "      <td>(1, (782, 49))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79384</th>\n",
       "      <td>(1, (782, 79))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79385</th>\n",
       "      <td>(1, (782, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79386</th>\n",
       "      <td>(1, (782, 94))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79387</th>\n",
       "      <td>(1, (783, 4))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79388</th>\n",
       "      <td>(1, (783, 8))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79389</th>\n",
       "      <td>(1, (783, 26))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79390</th>\n",
       "      <td>(1, (783, 30))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79391</th>\n",
       "      <td>(1, (783, 32))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79392</th>\n",
       "      <td>(1, (783, 39))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79393</th>\n",
       "      <td>(1, (783, 57))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79394</th>\n",
       "      <td>(1, (783, 60))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79395</th>\n",
       "      <td>(1, (783, 61))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79396</th>\n",
       "      <td>(1, (783, 79))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79397</th>\n",
       "      <td>(1, (783, 80))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79398</th>\n",
       "      <td>(1, (783, 87))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79399</th>\n",
       "      <td>(1, (783, 94))</td>\n",
       "      <td>79400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0      1\n",
       "0        (3, (93, 6))      1\n",
       "1        (3, (93, 4))      2\n",
       "2        (3, (93, 8))      3\n",
       "3        (3, (93, 0))      4\n",
       "4         (3, (9, 6))      5\n",
       "5        (3, (93, 2))      6\n",
       "6        (3, (45, 6))      7\n",
       "7        (3, (50, 6))      8\n",
       "8        (3, (71, 6))      9\n",
       "9        (3, (45, 4))     10\n",
       "10        (3, (9, 4))     11\n",
       "11        (3, (9, 8))     12\n",
       "12        (3, (5, 4))     13\n",
       "13        (3, (5, 6))     14\n",
       "14       (3, (45, 8))     15\n",
       "15       (3, (46, 7))     16\n",
       "16       (3, (27, 7))     17\n",
       "17       (3, (37, 7))     18\n",
       "18       (3, (33, 7))     19\n",
       "19       (3, (86, 4))     20\n",
       "20       (3, (67, 6))     21\n",
       "21       (3, (74, 4))     22\n",
       "22       (3, (42, 7))     23\n",
       "23       (3, (71, 4))     24\n",
       "24       (3, (74, 6))     25\n",
       "25       (3, (86, 6))     26\n",
       "26       (3, (50, 4))     27\n",
       "27       (3, (67, 4))     28\n",
       "28        (3, (9, 2))     29\n",
       "29       (3, (50, 8))     30\n",
       "...               ...    ...\n",
       "79370  (1, (772, 87))  79400\n",
       "79371  (1, (773, 87))  79400\n",
       "79372  (1, (774, 87))  79400\n",
       "79373  (1, (775, 87))  79400\n",
       "79374  (1, (776, 87))  79400\n",
       "79375  (1, (777, 87))  79400\n",
       "79376  (1, (778, 87))  79400\n",
       "79377  (1, (779, 87))  79400\n",
       "79378  (1, (780, 39))  79400\n",
       "79379  (1, (780, 87))  79400\n",
       "79380  (1, (781, 39))  79400\n",
       "79381  (1, (781, 87))  79400\n",
       "79382  (1, (782, 39))  79400\n",
       "79383  (1, (782, 49))  79400\n",
       "79384  (1, (782, 79))  79400\n",
       "79385  (1, (782, 87))  79400\n",
       "79386  (1, (782, 94))  79400\n",
       "79387   (1, (783, 4))  79400\n",
       "79388   (1, (783, 8))  79400\n",
       "79389  (1, (783, 26))  79400\n",
       "79390  (1, (783, 30))  79400\n",
       "79391  (1, (783, 32))  79400\n",
       "79392  (1, (783, 39))  79400\n",
       "79393  (1, (783, 57))  79400\n",
       "79394  (1, (783, 60))  79400\n",
       "79395  (1, (783, 61))  79400\n",
       "79396  (1, (783, 79))  79400\n",
       "79397  (1, (783, 80))  79400\n",
       "79398  (1, (783, 87))  79400\n",
       "79399  (1, (783, 94))  79400\n",
       "\n",
       "[79400 rows x 2 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"a.csv\", sep = \";\", header = False, index = False)\n",
    "adf = pd.read_csv(\"a.csv\", sep =\";\", header = None)\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"a.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "loc_file = \"results/rq1/all_layers/simple_fm/grad/loc.all_cost.loc.0.1.grad.pkl\"\n",
    "loc_which = 'gradient_loss'\n",
    "target_weights = fm_target_layes\n",
    "\n",
    "pairs = get_weight_and_cost(loc_which, seed, loc_file, target_weights, method = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, (93, 6)): 1,\n",
       " (3, (93, 4)): 2,\n",
       " (3, (93, 8)): 3,\n",
       " (3, (93, 0)): 4,\n",
       " (3, (9, 6)): 5,\n",
       " (3, (93, 2)): 6,\n",
       " (3, (45, 6)): 7,\n",
       " (3, (50, 6)): 8,\n",
       " (3, (71, 6)): 9,\n",
       " (3, (45, 4)): 10,\n",
       " (3, (9, 4)): 11,\n",
       " (3, (9, 8)): 12,\n",
       " (3, (5, 4)): 13,\n",
       " (3, (5, 6)): 14,\n",
       " (3, (45, 8)): 15,\n",
       " (3, (46, 7)): 16,\n",
       " (3, (27, 7)): 17,\n",
       " (3, (37, 7)): 18,\n",
       " (3, (33, 7)): 19,\n",
       " (3, (86, 4)): 20,\n",
       " (3, (67, 6)): 21,\n",
       " (3, (74, 4)): 22,\n",
       " (3, (42, 7)): 23,\n",
       " (3, (71, 4)): 24,\n",
       " (3, (74, 6)): 25,\n",
       " (3, (86, 6)): 26,\n",
       " (3, (50, 4)): 27,\n",
       " (3, (67, 4)): 28,\n",
       " (3, (9, 2)): 29,\n",
       " (3, (50, 8)): 30,\n",
       " (3, (45, 2)): 31,\n",
       " (3, (1, 6)): 32,\n",
       " (3, (71, 8)): 33,\n",
       " (1, (343, 48)): 34,\n",
       " (1, (371, 48)): 35,\n",
       " (1, (315, 48)): 36,\n",
       " (3, (34, 7)): 37,\n",
       " (3, (55, 6)): 38,\n",
       " (1, (399, 48)): 39,\n",
       " (1, (287, 48)): 40,\n",
       " (3, (50, 0)): 41,\n",
       " (1, (288, 48)): 42,\n",
       " (1, (441, 48)): 43,\n",
       " (1, (427, 48)): 44,\n",
       " (1, (469, 48)): 45,\n",
       " (1, (413, 48)): 46,\n",
       " (1, (316, 48)): 47,\n",
       " (1, (426, 48)): 48,\n",
       " (1, (385, 48)): 49,\n",
       " (1, (259, 48)): 50,\n",
       " (1, (454, 48)): 51,\n",
       " (1, (497, 48)): 52,\n",
       " (1, (398, 48)): 53,\n",
       " (1, (482, 48)): 54,\n",
       " (1, (260, 48)): 55,\n",
       " (1, (510, 48)): 56,\n",
       " (1, (538, 48)): 57,\n",
       " (1, (455, 48)): 58,\n",
       " (1, (328, 48)): 59,\n",
       " (1, (370, 48)): 60,\n",
       " (3, (59, 6)): 61,\n",
       " (1, (566, 48)): 62,\n",
       " (1, (541, 48)): 63,\n",
       " (1, (300, 48)): 64,\n",
       " (1, (569, 48)): 65,\n",
       " (1, (344, 48)): 66,\n",
       " (1, (342, 48)): 67,\n",
       " (1, (357, 48)): 68,\n",
       " (1, (594, 48)): 69,\n",
       " (1, (231, 48)): 70,\n",
       " (1, (458, 48)): 71,\n",
       " (1, (486, 48)): 72,\n",
       " (1, (525, 48)): 73,\n",
       " (1, (542, 48)): 74,\n",
       " (1, (356, 48)): 75,\n",
       " (1, (329, 48)): 76,\n",
       " (1, (514, 48)): 77,\n",
       " (1, (314, 48)): 78,\n",
       " (1, (430, 48)): 79,\n",
       " (1, (544, 48)): 80,\n",
       " (3, (23, 7)): 81,\n",
       " (1, (513, 48)): 82,\n",
       " (1, (543, 48)): 83,\n",
       " (1, (516, 48)): 84,\n",
       " (1, (550, 48)): 85,\n",
       " (1, (570, 48)): 86,\n",
       " (1, (622, 48)): 87,\n",
       " (1, (597, 48)): 88,\n",
       " (1, (488, 48)): 89,\n",
       " (1, (515, 48)): 90,\n",
       " (1, (483, 48)): 91,\n",
       " (1, (232, 48)): 92,\n",
       " (1, (286, 48)): 93,\n",
       " (1, (272, 48)): 94,\n",
       " (1, (547, 48)): 95,\n",
       " (1, (487, 48)): 96,\n",
       " (3, (93, 3)): 97,\n",
       " (1, (494, 48)): 98,\n",
       " (1, (301, 48)): 99,\n",
       " (1, (571, 48)): 100,\n",
       " (1, (459, 48)): 101,\n",
       " (1, (522, 48)): 102,\n",
       " (1, (572, 48)): 103,\n",
       " (1, (402, 48)): 104,\n",
       " (1, (625, 48)): 105,\n",
       " (1, (553, 48)): 106,\n",
       " (1, (374, 48)): 107,\n",
       " (1, (466, 48)): 108,\n",
       " (1, (548, 48)): 109,\n",
       " (1, (578, 48)): 110,\n",
       " (1, (460, 48)): 111,\n",
       " (1, (545, 48)): 112,\n",
       " (1, (519, 48)): 113,\n",
       " (1, (575, 48)): 114,\n",
       " (1, (485, 48)): 115,\n",
       " (1, (576, 48)): 116,\n",
       " (1, (431, 48)): 117,\n",
       " (1, (573, 48)): 118,\n",
       " (1, (517, 48)): 119,\n",
       " (1, (520, 48)): 120,\n",
       " (1, (273, 48)): 121,\n",
       " (1, (491, 48)): 122,\n",
       " (1, (492, 48)): 123,\n",
       " (1, (432, 48)): 124,\n",
       " (1, (372, 48)): 125,\n",
       " (1, (384, 48)): 126,\n",
       " (1, (346, 48)): 127,\n",
       " (1, (489, 48)): 128,\n",
       " (1, (549, 48)): 129,\n",
       " (1, (546, 48)): 130,\n",
       " (1, (464, 48)): 131,\n",
       " (1, (438, 48)): 132,\n",
       " (1, (203, 48)): 133,\n",
       " (1, (258, 48)): 134,\n",
       " (1, (577, 48)): 135,\n",
       " (1, (493, 48)): 136,\n",
       " (1, (574, 48)): 137,\n",
       " (1, (299, 48)): 138,\n",
       " (1, (461, 48)): 139,\n",
       " (1, (442, 48)): 140,\n",
       " (1, (463, 48)): 141,\n",
       " (1, (465, 48)): 142,\n",
       " (1, (600, 48)): 143,\n",
       " (1, (518, 48)): 144,\n",
       " (1, (521, 48)): 145,\n",
       " (1, (289, 48)): 146,\n",
       " (1, (436, 48)): 147,\n",
       " (1, (403, 48)): 148,\n",
       " (1, (599, 48)): 149,\n",
       " (1, (490, 48)): 150,\n",
       " (1, (470, 48)): 151,\n",
       " (1, (404, 48)): 152,\n",
       " (1, (318, 48)): 153,\n",
       " (1, (204, 48)): 154,\n",
       " (1, (457, 48)): 155,\n",
       " (1, (376, 48)): 156,\n",
       " (1, (375, 48)): 157,\n",
       " (1, (601, 48)): 158,\n",
       " (1, (435, 48)): 159,\n",
       " (1, (598, 48)): 160,\n",
       " (1, (511, 48)): 161,\n",
       " (1, (414, 48)): 162,\n",
       " (1, (410, 48)): 163,\n",
       " (1, (462, 48)): 164,\n",
       " (1, (433, 48)): 165,\n",
       " (1, (581, 48)): 166,\n",
       " (1, (603, 48)): 167,\n",
       " (1, (498, 48)): 168,\n",
       " (1, (317, 48)): 169,\n",
       " (1, (245, 48)): 170,\n",
       " (1, (437, 48)): 171,\n",
       " (1, (244, 48)): 172,\n",
       " (1, (628, 48)): 173,\n",
       " (1, (526, 48)): 174,\n",
       " (1, (380, 48)): 175,\n",
       " (1, (381, 48)): 176,\n",
       " (1, (408, 48)): 177,\n",
       " (1, (271, 48)): 178,\n",
       " (1, (627, 48)): 179,\n",
       " (1, (606, 48)): 180,\n",
       " (1, (554, 48)): 181,\n",
       " (1, (604, 48)): 182,\n",
       " (1, (409, 48)): 183,\n",
       " (1, (602, 48)): 184,\n",
       " (1, (261, 48)): 185,\n",
       " (1, (382, 48)): 186,\n",
       " (1, (434, 48)): 187,\n",
       " (1, (327, 48)): 188,\n",
       " (1, (582, 48)): 189,\n",
       " (1, (650, 48)): 190,\n",
       " (1, (626, 48)): 191,\n",
       " (1, (631, 48)): 192,\n",
       " (1, (290, 48)): 193,\n",
       " (1, (386, 48)): 194,\n",
       " (1, (629, 48)): 195,\n",
       " (1, (407, 48)): 196,\n",
       " (1, (176, 48)): 197,\n",
       " (1, (405, 48)): 198,\n",
       " (1, (632, 48)): 199,\n",
       " (1, (377, 48)): 200,\n",
       " (1, (347, 48)): 201,\n",
       " (1, (605, 48)): 202,\n",
       " (1, (348, 48)): 203,\n",
       " (1, (610, 48)): 204,\n",
       " (1, (634, 48)): 205,\n",
       " (1, (429, 48)): 206,\n",
       " (1, (379, 48)): 207,\n",
       " (1, (630, 48)): 208,\n",
       " (1, (243, 48)): 209,\n",
       " (1, (345, 48)): 210,\n",
       " (1, (205, 48)): 211,\n",
       " (1, (177, 48)): 212,\n",
       " (1, (373, 48)): 213,\n",
       " (1, (406, 48)): 214,\n",
       " (1, (353, 48)): 215,\n",
       " (1, (354, 48)): 216,\n",
       " (1, (326, 48)): 217,\n",
       " (1, (233, 48)): 218,\n",
       " (1, (325, 48)): 219,\n",
       " (1, (633, 48)): 220,\n",
       " (1, (378, 48)): 221,\n",
       " (1, (349, 48)): 222,\n",
       " (1, (401, 48)): 223,\n",
       " (1, (319, 48)): 224,\n",
       " (1, (149, 48)): 225,\n",
       " (1, (262, 48)): 226,\n",
       " (1, (175, 48)): 227,\n",
       " (1, (291, 48)): 228,\n",
       " (1, (352, 48)): 229,\n",
       " (1, (653, 48)): 230,\n",
       " (1, (215, 48)): 231,\n",
       " (1, (638, 48)): 232,\n",
       " (1, (122, 48)): 233,\n",
       " (1, (216, 48)): 234,\n",
       " (1, (350, 48)): 235,\n",
       " (1, (206, 48)): 236,\n",
       " (1, (320, 48)): 237,\n",
       " (1, (355, 48)): 238,\n",
       " (1, (539, 48)): 239,\n",
       " (1, (351, 48)): 240,\n",
       " (1, (358, 48)): 241,\n",
       " (3, (71, 0)): 242,\n",
       " (1, (230, 48)): 243,\n",
       " (1, (412, 48)): 244,\n",
       " (1, (298, 48)): 245,\n",
       " (1, (178, 48)): 246,\n",
       " (1, (217, 48)): 247,\n",
       " (3, (1, 4)): 248,\n",
       " (1, (579, 48)): 249,\n",
       " (1, (187, 48)): 250,\n",
       " (1, (150, 48)): 251,\n",
       " (1, (188, 48)): 252,\n",
       " (1, (234, 48)): 253,\n",
       " (1, (158, 48)): 254,\n",
       " (1, (148, 48)): 255,\n",
       " (1, (324, 48)): 256,\n",
       " (1, (321, 48)): 257,\n",
       " (1, (159, 48)): 258,\n",
       " (1, (270, 48)): 259,\n",
       " (1, (123, 48)): 260,\n",
       " (1, (609, 48)): 261,\n",
       " (1, (129, 48)): 262,\n",
       " (1, (323, 48)): 263,\n",
       " (1, (186, 48)): 264,\n",
       " (1, (551, 48)): 265,\n",
       " (1, (400, 48)): 266,\n",
       " (1, (151, 48)): 267,\n",
       " (1, (185, 48)): 268,\n",
       " (1, (99, 48)): 269,\n",
       " (1, (322, 48)): 270,\n",
       " (1, (153, 48)): 271,\n",
       " (1, (157, 48)): 272,\n",
       " (1, (295, 48)): 273,\n",
       " (1, (214, 48)): 274,\n",
       " (1, (96, 48)): 275,\n",
       " (1, (297, 48)): 276,\n",
       " (1, (95, 48)): 277,\n",
       " (1, (127, 48)): 278,\n",
       " (1, (292, 48)): 279,\n",
       " (1, (263, 48)): 280,\n",
       " (1, (296, 48)): 281,\n",
       " (1, (152, 48)): 282,\n",
       " (1, (124, 48)): 283,\n",
       " (1, (330, 48)): 284,\n",
       " (1, (659, 48)): 285,\n",
       " (1, (155, 48)): 286,\n",
       " (1, (154, 48)): 287,\n",
       " (1, (156, 48)): 288,\n",
       " (1, (656, 48)): 289,\n",
       " (1, (241, 48)): 290,\n",
       " (1, (125, 48)): 291,\n",
       " (1, (607, 48)): 292,\n",
       " (1, (383, 48)): 293,\n",
       " (1, (126, 48)): 294,\n",
       " (1, (179, 48)): 295,\n",
       " (1, (128, 48)): 296,\n",
       " (1, (657, 48)): 297,\n",
       " (1, (655, 48)): 298,\n",
       " (1, (242, 48)): 299,\n",
       " (1, (264, 48)): 300,\n",
       " (1, (294, 48)): 301,\n",
       " (1, (182, 48)): 302,\n",
       " (1, (293, 48)): 303,\n",
       " (1, (207, 48)): 304,\n",
       " (1, (660, 48)): 305,\n",
       " (1, (654, 48)): 306,\n",
       " (1, (267, 48)): 307,\n",
       " (1, (130, 48)): 308,\n",
       " (1, (235, 48)): 309,\n",
       " (1, (213, 48)): 310,\n",
       " (1, (236, 48)): 311,\n",
       " (1, (181, 48)): 312,\n",
       " (1, (183, 48)): 313,\n",
       " (1, (658, 48)): 314,\n",
       " (1, (94, 48)): 315,\n",
       " (1, (635, 48)): 316,\n",
       " (1, (678, 48)): 317,\n",
       " (1, (666, 48)): 318,\n",
       " (1, (184, 48)): 319,\n",
       " (1, (269, 48)): 320,\n",
       " (1, (239, 48)): 321,\n",
       " (1, (662, 48)): 322,\n",
       " (1, (523, 48)): 323,\n",
       " (1, (240, 48)): 324,\n",
       " (1, (180, 48)): 325,\n",
       " (1, (237, 48)): 326,\n",
       " (1, (71, 48)): 327,\n",
       " (1, (211, 48)): 328,\n",
       " (1, (100, 48)): 329,\n",
       " (1, (268, 48)): 330,\n",
       " (1, (68, 48)): 331,\n",
       " (1, (101, 48)): 332,\n",
       " (1, (97, 48)): 333,\n",
       " (1, (661, 48)): 334,\n",
       " (1, (72, 48)): 335,\n",
       " (1, (266, 48)): 336,\n",
       " (1, (238, 48)): 337,\n",
       " (1, (212, 48)): 338,\n",
       " (1, (121, 48)): 339,\n",
       " (1, (98, 48)): 340,\n",
       " (1, (209, 48)): 341,\n",
       " (1, (210, 48)): 342,\n",
       " (1, (265, 48)): 343,\n",
       " (1, (208, 48)): 344,\n",
       " (1, (567, 48)): 345,\n",
       " (1, (160, 48)): 346,\n",
       " (1, (440, 48)): 347,\n",
       " (1, (411, 48)): 348,\n",
       " (1, (467, 48)): 349,\n",
       " (1, (495, 48)): 350,\n",
       " (1, (439, 48)): 351,\n",
       " (1, (637, 48)): 352,\n",
       " (1, (428, 48)): 353,\n",
       " (1, (302, 48)): 354,\n",
       " (1, (69, 48)): 355,\n",
       " (3, (8, 4)): 356,\n",
       " (1, (481, 48)): 357,\n",
       " (1, (147, 48)): 358,\n",
       " (1, (509, 48)): 359,\n",
       " (1, (189, 48)): 360,\n",
       " (1, (202, 48)): 361,\n",
       " (1, (663, 48)): 362,\n",
       " (1, (67, 48)): 363,\n",
       " (1, (453, 48)): 364,\n",
       " (3, (40, 7)): 365,\n",
       " (1, (565, 48)): 366,\n",
       " (1, (537, 48)): 367,\n",
       " (3, (70, 7)): 368,\n",
       " (1, (694, 48)): 369,\n",
       " (1, (468, 48)): 370,\n",
       " (1, (425, 48)): 371,\n",
       " (1, (706, 48)): 372,\n",
       " (1, (456, 48)): 373,\n",
       " (1, (70, 48)): 374,\n",
       " (1, (593, 48)): 375,\n",
       " (1, (102, 48)): 376,\n",
       " (1, (40, 48)): 377,\n",
       " (1, (44, 48)): 378,\n",
       " (1, (131, 48)): 379,\n",
       " (1, (43, 48)): 380,\n",
       " (1, (73, 48)): 381,\n",
       " (1, (595, 48)): 382,\n",
       " (1, (621, 48)): 383,\n",
       " (1, (681, 48)): 384,\n",
       " (1, (397, 48)): 385,\n",
       " (3, (14, 4)): 386,\n",
       " (3, (62, 7)): 387,\n",
       " (1, (484, 48)): 388,\n",
       " (1, (41, 48)): 389,\n",
       " (1, (274, 48)): 390,\n",
       " (1, (496, 48)): 391,\n",
       " (1, (541, 76)): 392,\n",
       " (1, (120, 48)): 393,\n",
       " (1, (665, 48)): 394,\n",
       " (1, (687, 48)): 395,\n",
       " (1, (569, 76)): 396,\n",
       " (1, (684, 48)): 397,\n",
       " (1, (688, 48)): 398,\n",
       " (1, (512, 48)): 399,\n",
       " (1, (685, 48)): 400,\n",
       " (1, (686, 48)): 401,\n",
       " (1, (683, 48)): 402,\n",
       " (1, (682, 48)): 403,\n",
       " (1, (690, 48)): 404,\n",
       " (1, (513, 76)): 405,\n",
       " (1, (722, 48)): 406,\n",
       " (1, (540, 48)): 407,\n",
       " (1, (649, 48)): 408,\n",
       " (1, (42, 48)): 409,\n",
       " (1, (546, 76)): 410,\n",
       " (1, (544, 76)): 411,\n",
       " (1, (545, 76)): 412,\n",
       " (1, (689, 48)): 413,\n",
       " (1, (547, 76)): 414,\n",
       " (1, (369, 48)): 415,\n",
       " (1, (543, 76)): 416,\n",
       " (1, (548, 76)): 417,\n",
       " (1, (66, 48)): 418,\n",
       " (1, (549, 76)): 419,\n",
       " (1, (568, 48)): 420,\n",
       " (1, (300, 76)): 421,\n",
       " (1, (571, 76)): 422,\n",
       " (1, (597, 76)): 423,\n",
       " (1, (572, 76)): 424,\n",
       " (1, (518, 76)): 425,\n",
       " (1, (570, 76)): 426,\n",
       " (1, (574, 76)): 427,\n",
       " (1, (485, 76)): 428,\n",
       " (1, (519, 76)): 429,\n",
       " (1, (575, 76)): 430,\n",
       " (1, (516, 76)): 431,\n",
       " (1, (517, 76)): 432,\n",
       " (1, (542, 76)): 433,\n",
       " (1, (573, 76)): 434,\n",
       " (1, (93, 48)): 435,\n",
       " (1, (524, 48)): 436,\n",
       " (1, (576, 76)): 437,\n",
       " (1, (486, 76)): 438,\n",
       " (1, (514, 76)): 439,\n",
       " (1, (328, 76)): 440,\n",
       " (1, (272, 76)): 441,\n",
       " (1, (623, 48)): 442,\n",
       " (1, (520, 76)): 443,\n",
       " (1, (462, 76)): 444,\n",
       " (1, (522, 76)): 445,\n",
       " (1, (577, 76)): 446,\n",
       " (1, (521, 76)): 447,\n",
       " (1, (515, 76)): 448,\n",
       " (1, (491, 76)): 449,\n",
       " (1, (490, 76)): 450,\n",
       " (1, (550, 76)): 451,\n",
       " (1, (489, 76)): 452,\n",
       " (1, (596, 48)): 453,\n",
       " (1, (487, 76)): 454,\n",
       " (1, (522, 90)): 455,\n",
       " (1, (457, 76)): 456,\n",
       " (1, (463, 76)): 457,\n",
       " (1, (599, 76)): 458,\n",
       " (1, (601, 76)): 459,\n",
       " (1, (494, 76)): 460,\n",
       " (1, (602, 76)): 461,\n",
       " (1, (488, 76)): 462,\n",
       " (1, (578, 76)): 463,\n",
       " (1, (600, 76)): 464,\n",
       " (1, (299, 76)): 465,\n",
       " (1, (327, 76)): 466,\n",
       " (3, (27, 9)): 467,\n",
       " (1, (598, 76)): 468,\n",
       " (1, (493, 76)): 469,\n",
       " (1, (603, 76)): 470,\n",
       " (1, (174, 48)): 471,\n",
       " (1, (461, 76)): 472,\n",
       " (1, (356, 76)): 473,\n",
       " (1, (459, 76)): 474,\n",
       " (1, (492, 76)): 475,\n",
       " (1, (458, 76)): 476,\n",
       " (1, (271, 76)): 477,\n",
       " (1, (434, 76)): 478,\n",
       " (3, (66, 4)): 479,\n",
       " (1, (460, 76)): 480,\n",
       " (1, (435, 76)): 481,\n",
       " (1, (466, 76)): 482,\n",
       " (1, (552, 48)): 483,\n",
       " (1, (518, 62)): 484,\n",
       " (1, (161, 48)): 485,\n",
       " (1, (355, 76)): 486,\n",
       " (1, (604, 76)): 487,\n",
       " (1, (518, 90)): 488,\n",
       " (1, (625, 76)): 489,\n",
       " (1, (244, 76)): 490,\n",
       " (1, (517, 90)): 491,\n",
       " (1, (465, 76)): 492,\n",
       " (1, (132, 48)): 493,\n",
       " (1, (433, 76)): 494,\n",
       " (1, (551, 76)): 495,\n",
       " (1, (382, 76)): 496,\n",
       " (1, (519, 90)): 497,\n",
       " (1, (519, 62)): 498,\n",
       " (1, (410, 76)): 499,\n",
       " (1, (431, 76)): 500,\n",
       " (1, (438, 76)): 501,\n",
       " (1, (523, 62)): 502,\n",
       " (1, (325, 76)): 503,\n",
       " (1, (429, 76)): 504,\n",
       " (1, (677, 48)): 505,\n",
       " (1, (379, 76)): 506,\n",
       " (1, (407, 76)): 507,\n",
       " (1, (341, 48)): 508,\n",
       " (1, (436, 76)): 509,\n",
       " (1, (605, 76)): 510,\n",
       " (1, (522, 62)): 511,\n",
       " (1, (494, 90)): 512,\n",
       " (1, (734, 48)): 513,\n",
       " (1, (579, 76)): 514,\n",
       " (1, (430, 76)): 515,\n",
       " (1, (432, 76)): 516,\n",
       " (1, (297, 76)): 517,\n",
       " (1, (406, 76)): 518,\n",
       " (1, (624, 48)): 519,\n",
       " (1, (437, 76)): 520,\n",
       " (1, (464, 76)): 521,\n",
       " (1, (523, 76)): 522,\n",
       " (1, (521, 62)): 523,\n",
       " (1, (606, 76)): 524,\n",
       " (1, (288, 76)): 525,\n",
       " (1, (517, 62)): 526,\n",
       " (3, (55, 4)): 527,\n",
       " (1, (354, 76)): 528,\n",
       " (1, (353, 76)): 529,\n",
       " (1, (381, 76)): 530,\n",
       " (1, (351, 76)): 531,\n",
       " (1, (243, 76)): 532,\n",
       " (1, (409, 76)): 533,\n",
       " (1, (693, 48)): 534,\n",
       " (1, (520, 90)): 535,\n",
       " (1, (629, 76)): 536,\n",
       " (1, (691, 48)): 537,\n",
       " (1, (326, 76)): 538,\n",
       " (1, (630, 76)): 539,\n",
       " (1, (494, 62)): 540,\n",
       " (1, (466, 90)): 541,\n",
       " (1, (408, 76)): 542,\n",
       " (1, (260, 76)): 543,\n",
       " (1, (521, 90)): 544,\n",
       " (1, (298, 76)): 545,\n",
       " (1, (352, 76)): 546,\n",
       " (1, (384, 76)): 547,\n",
       " (1, (378, 76)): 548,\n",
       " (1, (493, 62)): 549,\n",
       " (1, (246, 48)): 550,\n",
       " (1, (628, 76)): 551,\n",
       " (1, (466, 62)): 552,\n",
       " (1, (405, 76)): 553,\n",
       " (1, (438, 90)): 554,\n",
       " (1, (607, 76)): 555,\n",
       " (1, (627, 76)): 556,\n",
       " (1, (520, 62)): 557,\n",
       " (1, (316, 76)): 558,\n",
       " (1, (495, 62)): 559,\n",
       " (3, (33, 9)): 560,\n",
       " (1, (383, 76)): 561,\n",
       " (1, (580, 48)): 562,\n",
       " (1, (631, 76)): 563,\n",
       " (1, (380, 76)): 564,\n",
       " (1, (377, 76)): 565,\n",
       " (1, (404, 76)): 566,\n",
       " (1, (324, 76)): 567,\n",
       " (1, (490, 62)): 568,\n",
       " (1, (491, 62)): 569,\n",
       " (1, (490, 90)): 570,\n",
       " (1, (270, 76)): 571,\n",
       " (1, (546, 90)): 572,\n",
       " (1, (516, 90)): 573,\n",
       " (1, (495, 76)): 574,\n",
       " (3, (99, 7)): 575,\n",
       " (1, (403, 76)): 576,\n",
       " (1, (382, 62)): 577,\n",
       " (1, (626, 76)): 578,\n",
       " (1, (545, 90)): 579,\n",
       " (1, (232, 76)): 580,\n",
       " (1, (462, 90)): 581,\n",
       " (1, (438, 62)): 582,\n",
       " (1, (39, 48)): 583,\n",
       " (1, (402, 76)): 584,\n",
       " (1, (269, 76)): 585,\n",
       " (1, (491, 90)): 586,\n",
       " (1, (410, 62)): 587,\n",
       " (1, (410, 90)): 588,\n",
       " (1, (462, 62)): 589,\n",
       " (1, (382, 90)): 590,\n",
       " (1, (492, 62)): 591,\n",
       " (1, (493, 90)): 592,\n",
       " (1, (632, 76)): 593,\n",
       " (1, (411, 76)): 594,\n",
       " (1, (547, 90)): 595,\n",
       " (1, (323, 76)): 596,\n",
       " (1, (489, 62)): 597,\n",
       " (1, (489, 90)): 598,\n",
       " (1, (541, 90)): 599,\n",
       " (1, (467, 62)): 600,\n",
       " (1, (272, 62)): 601,\n",
       " (1, (376, 76)): 602,\n",
       " (1, (465, 62)): 603,\n",
       " (1, (350, 76)): 604,\n",
       " (1, (492, 90)): 605,\n",
       " (1, (344, 76)): 606,\n",
       " (1, (653, 76)): 607,\n",
       " (1, (467, 76)): 608,\n",
       " (1, (401, 76)): 609,\n",
       " (1, (384, 90)): 610,\n",
       " (1, (463, 62)): 611,\n",
       " (1, (513, 90)): 612,\n",
       " (1, (242, 76)): 613,\n",
       " (1, (515, 90)): 614,\n",
       " (1, (349, 76)): 615,\n",
       " (1, (463, 90)): 616,\n",
       " (1, (657, 76)): 617,\n",
       " (1, (544, 90)): 618,\n",
       " (1, (523, 90)): 619,\n",
       " (1, (296, 76)): 620,\n",
       " (1, (300, 62)): 621,\n",
       " (1, (295, 76)): 622,\n",
       " (1, (543, 90)): 623,\n",
       " (1, (633, 76)): 624,\n",
       " (1, (215, 76)): 625,\n",
       " (1, (411, 62)): 626,\n",
       " (1, (465, 90)): 627,\n",
       " (1, (439, 76)): 628,\n",
       " (1, (464, 62)): 629,\n",
       " (1, (439, 62)): 630,\n",
       " (1, (516, 62)): 631,\n",
       " (1, (550, 90)): 632,\n",
       " (1, (656, 76)): 633,\n",
       " (1, (412, 76)): 634,\n",
       " (1, (658, 76)): 635,\n",
       " (1, (750, 48)): 636,\n",
       " (1, (546, 62)): 637,\n",
       " (1, (634, 76)): 638,\n",
       " (1, (548, 90)): 639,\n",
       " (1, (436, 62)): 640,\n",
       " (1, (635, 76)): 641,\n",
       " (1, (383, 62)): 642,\n",
       " (1, (464, 90)): 643,\n",
       " (1, (545, 62)): 644,\n",
       " (1, (513, 62)): 645,\n",
       " (1, (659, 76)): 646,\n",
       " (1, (435, 90)): 647,\n",
       " (1, (436, 90)): 648,\n",
       " (1, (241, 76)): 649,\n",
       " (1, (461, 90)): 650,\n",
       " (1, (461, 62)): 651,\n",
       " (1, (514, 90)): 652,\n",
       " (1, (216, 76)): 653,\n",
       " (1, (681, 76)): 654,\n",
       " (1, (434, 90)): 655,\n",
       " (1, (354, 62)): 656,\n",
       " (1, (322, 76)): 657,\n",
       " (1, (488, 90)): 658,\n",
       " (1, (375, 76)): 659,\n",
       " (1, (655, 76)): 660,\n",
       " (1, (435, 62)): 661,\n",
       " (1, (437, 62)): 662,\n",
       " (1, (547, 62)): 663,\n",
       " (1, (685, 76)): 664,\n",
       " (1, (686, 76)): 665,\n",
       " (1, (549, 90)): 666,\n",
       " (1, (437, 90)): 667,\n",
       " (1, (214, 76)): 668,\n",
       " (1, (412, 90)): 669,\n",
       " (1, (268, 76)): 670,\n",
       " (1, (373, 76)): 671,\n",
       " (1, (383, 90)): 672,\n",
       " (1, (289, 76)): 673,\n",
       " (1, (374, 76)): 674,\n",
       " (1, (495, 90)): 675,\n",
       " (1, (204, 76)): 676,\n",
       " (1, (356, 90)): 677,\n",
       " (1, (408, 62)): 678,\n",
       " (1, (488, 62)): 679,\n",
       " (3, (19, 4)): 680,\n",
       " (1, (327, 90)): 681,\n",
       " (1, (684, 76)): 682,\n",
       " (1, (355, 90)): 683,\n",
       " (1, (326, 62)): 684,\n",
       " (1, (348, 76)): 685,\n",
       " (1, (485, 90)): 686,\n",
       " (1, (542, 90)): 687,\n",
       " (1, (74, 48)): 688,\n",
       " (1, (487, 90)): 689,\n",
       " (1, (515, 62)): 690,\n",
       " (1, (355, 62)): 691,\n",
       " (1, (654, 76)): 692,\n",
       " (1, (434, 62)): 693,\n",
       " (1, (313, 48)): 694,\n",
       " (1, (261, 76)): 695,\n",
       " (1, (407, 62)): 696,\n",
       " (1, (317, 76)): 697,\n",
       " (1, (287, 76)): 698,\n",
       " (1, (408, 90)): 699,\n",
       " (1, (660, 76)): 700,\n",
       " (1, (345, 76)): 701,\n",
       " (1, (267, 76)): 702,\n",
       " (1, (409, 62)): 703,\n",
       " (1, (687, 76)): 704,\n",
       " (1, (651, 48)): 705,\n",
       " (1, (549, 62)): 706,\n",
       " (1, (381, 62)): 707,\n",
       " (1, (468, 90)): 708,\n",
       " (1, (354, 90)): 709,\n",
       " (1, (259, 76)): 710,\n",
       " (1, (294, 76)): 711,\n",
       " (1, (409, 90)): 712,\n",
       " (1, (433, 90)): 713,\n",
       " (1, (548, 62)): 714,\n",
       " (1, (372, 76)): 715,\n",
       " (1, (688, 76)): 716,\n",
       " (1, (440, 90)): 717,\n",
       " (1, (381, 90)): 718,\n",
       " (1, (661, 76)): 719,\n",
       " (1, (467, 90)): 720,\n",
       " (1, (321, 76)): 721,\n",
       " (1, (315, 76)): 722,\n",
       " (1, (683, 76)): 723,\n",
       " (1, (411, 90)): 724,\n",
       " (1, (544, 62)): 725,\n",
       " (1, (487, 62)): 726,\n",
       " (1, (353, 62)): 727,\n",
       " (1, (299, 90)): 728,\n",
       " (1, (439, 90)): 729,\n",
       " (1, (119, 48)): 730,\n",
       " (1, (407, 90)): 731,\n",
       " (1, (608, 48)): 732,\n",
       " (1, (233, 76)): 733,\n",
       " (1, (486, 90)): 734,\n",
       " (1, (514, 62)): 735,\n",
       " (1, (541, 62)): 736,\n",
       " (1, (347, 76)): 737,\n",
       " (1, (689, 76)): 738,\n",
       " (1, (231, 76)): 739,\n",
       " (1, (540, 76)): 740,\n",
       " (1, (353, 90)): 741,\n",
       " (1, (326, 90)): 742,\n",
       " (1, (682, 76)): 743,\n",
       " (1, (568, 76)): 744,\n",
       " (1, (380, 90)): 745,\n",
       " (1, (485, 62)): 746,\n",
       " (1, (328, 90)): 747,\n",
       " (1, (187, 76)): 748,\n",
       " (1, (551, 62)): 749,\n",
       " (1, (379, 90)): 750,\n",
       " (1, (705, 48)): 751,\n",
       " (1, (325, 62)): 752,\n",
       " (1, (325, 90)): 753,\n",
       " (1, (244, 62)): 754,\n",
       " (1, (320, 76)): 755,\n",
       " (1, (240, 76)): 756,\n",
       " (1, (346, 76)): 757,\n",
       " (1, (440, 76)): 758,\n",
       " (1, (460, 90)): 759,\n",
       " (1, (652, 48)): 760,\n",
       " (1, (524, 90)): 761,\n",
       " (1, (543, 62)): 762,\n",
       " (1, (406, 90)): 763,\n",
       " (3, (66, 6)): 764,\n",
       " (1, (298, 62)): 765,\n",
       " (3, (42, 9)): 766,\n",
       " (1, (406, 62)): 767,\n",
       " (1, (496, 90)): 768,\n",
       " (1, (328, 62)): 769,\n",
       " (1, (663, 76)): 770,\n",
       " (1, (266, 76)): 771,\n",
       " (1, (380, 62)): 772,\n",
       " (1, (318, 76)): 773,\n",
       " (1, (327, 62)): 774,\n",
       " (1, (213, 76)): 775,\n",
       " (1, (352, 62)): 776,\n",
       " (1, (459, 90)): 777,\n",
       " (1, (352, 90)): 778,\n",
       " (1, (290, 76)): 779,\n",
       " (1, (379, 62)): 780,\n",
       " (1, (433, 62)): 781,\n",
       " (1, (273, 62)): 782,\n",
       " (1, (460, 62)): 783,\n",
       " (1, (690, 76)): 784,\n",
       " (1, (324, 62)): 785,\n",
       " (1, (550, 62)): 786,\n",
       " (1, (596, 76)): 787,\n",
       " (1, (662, 76)): 788,\n",
       " (1, (512, 76)): 789,\n",
       " (1, (239, 76)): 790,\n",
       " (1, (186, 76)): 791,\n",
       " (1, (262, 76)): 792,\n",
       " (1, (205, 76)): 793,\n",
       " (1, (176, 76)): 794,\n",
       " (1, (569, 90)): 795,\n",
       " (1, (484, 76)): 796,\n",
       " (1, (486, 62)): 797,\n",
       " (1, (324, 90)): 798,\n",
       " (1, (691, 76)): 799,\n",
       " (1, (292, 76)): 800,\n",
       " (1, (319, 76)): 801,\n",
       " (1, (378, 90)): 802,\n",
       " (1, (271, 90)): 803,\n",
       " (1, (468, 76)): 804,\n",
       " (1, (400, 76)): 805,\n",
       " (1, (293, 76)): 806,\n",
       " (1, (573, 90)): 807,\n",
       " (1, (456, 76)): 808,\n",
       " (1, (297, 62)): 809,\n",
       " (1, (103, 48)): 810,\n",
       " (1, (291, 76)): 811,\n",
       " (1, (351, 90)): 812,\n",
       " (1, (299, 62)): 813,\n",
       " (1, (300, 90)): 814,\n",
       " (1, (551, 90)): 815,\n",
       " (1, (574, 90)): 816,\n",
       " (1, (428, 76)): 817,\n",
       " (1, (264, 76)): 818,\n",
       " (1, (457, 90)): 819,\n",
       " (1, (265, 76)): 820,\n",
       " (1, (301, 62)): 821,\n",
       " (1, (542, 62)): 822,\n",
       " (1, (458, 90)): 823,\n",
       " (1, (234, 76)): 824,\n",
       " (1, (203, 76)): 825,\n",
       " (1, (263, 76)): 826,\n",
       " (1, (149, 76)): 827,\n",
       " (1, (298, 90)): 828,\n",
       " (1, (271, 62)): 829,\n",
       " (1, (343, 76)): 830,\n",
       " (1, (351, 62)): 831,\n",
       " (1, (459, 62)): 832,\n",
       " (1, (238, 76)): 833,\n",
       " (1, (457, 62)): 834,\n",
       " (1, (624, 76)): 835,\n",
       " (1, (177, 76)): 836,\n",
       " (1, (378, 62)): 837,\n",
       " (1, (572, 90)): 838,\n",
       " (3, (46, 9)): 839,\n",
       " (1, (212, 76)): 840,\n",
       " (1, (432, 90)): 841,\n",
       " (1, (297, 90)): 842,\n",
       " (1, (188, 76)): 843,\n",
       " (1, (571, 90)): 844,\n",
       " (1, (185, 76)): 845,\n",
       " (1, (405, 90)): 846,\n",
       " (1, (570, 90)): 847,\n",
       " (1, (210, 76)): 848,\n",
       " (1, (511, 76)): 849,\n",
       " (1, (211, 76)): 850,\n",
       " (1, (525, 90)): 851,\n",
       " (1, (158, 76)): 852,\n",
       " (1, (182, 76)): 853,\n",
       " (1, (575, 90)): 854,\n",
       " (1, (483, 76)): 855,\n",
       " (1, (496, 76)): 856,\n",
       " (1, (206, 76)): 857,\n",
       " (1, (159, 76)): 858,\n",
       " (1, (583, 48)): 859,\n",
       " (1, (45, 48)): 860,\n",
       " (1, (235, 76)): 861,\n",
       " (1, (178, 76)): 862,\n",
       " (1, (721, 48)): 863,\n",
       " (1, (150, 76)): 864,\n",
       " (1, (243, 62)): 865,\n",
       " (1, (236, 76)): 866,\n",
       " (1, (329, 62)): 867,\n",
       " (1, (237, 76)): 868,\n",
       " (1, (455, 76)): 869,\n",
       " (1, (524, 76)): 870,\n",
       " (1, (431, 90)): 871,\n",
       " (1, (611, 48)): 872,\n",
       " (1, (209, 76)): 873,\n",
       " (1, (148, 76)): 874,\n",
       " (1, (377, 90)): 875,\n",
       " (1, (273, 76)): 876,\n",
       " (1, (154, 76)): 877,\n",
       " (1, (323, 90)): 878,\n",
       " (1, (555, 48)): 879,\n",
       " (1, (713, 76)): 880,\n",
       " (1, (469, 90)): 881,\n",
       " (1, (458, 62)): 882,\n",
       " (1, (270, 62)): 883,\n",
       " (1, (578, 90)): 884,\n",
       " (1, (207, 76)): 885,\n",
       " (1, (539, 76)): 886,\n",
       " (1, (153, 76)): 887,\n",
       " (1, (497, 90)): 888,\n",
       " (1, (714, 76)): 889,\n",
       " (1, (709, 76)): 890,\n",
       " (1, (181, 76)): 891,\n",
       " (1, (576, 90)): 892,\n",
       " (1, (126, 76)): 893,\n",
       " (1, (512, 90)): 894,\n",
       " (1, (511, 90)): 895,\n",
       " (1, (636, 48)): 896,\n",
       " (1, (712, 76)): 897,\n",
       " (1, (296, 90)): 898,\n",
       " (1, (301, 76)): 899,\n",
       " (1, (124, 76)): 900,\n",
       " (1, (208, 76)): 901,\n",
       " (1, (179, 76)): 902,\n",
       " (1, (552, 76)): 903,\n",
       " (1, (405, 62)): 904,\n",
       " (1, (183, 76)): 905,\n",
       " (1, (285, 48)): 906,\n",
       " (1, (527, 48)): 907,\n",
       " (1, (184, 76)): 908,\n",
       " (1, (157, 76)): 909,\n",
       " (1, (243, 90)): 910,\n",
       " (1, (125, 76)): 911,\n",
       " (1, (569, 62)): 912,\n",
       " (1, (432, 62)): 913,\n",
       " (1, (441, 90)): 914,\n",
       " (1, (577, 90)): 915,\n",
       " (1, (427, 76)): 916,\n",
       " (1, (127, 76)): 917,\n",
       " (1, (270, 90)): 918,\n",
       " (1, (639, 48)): 919,\n",
       " (1, (323, 62)): 920,\n",
       " (1, (296, 62)): 921,\n",
       " (1, (413, 90)): 922,\n",
       " (1, (152, 76)): 923,\n",
       " (1, (371, 76)): 924,\n",
       " (1, (350, 90)): 925,\n",
       " (1, (245, 76)): 926,\n",
       " (1, (715, 76)): 927,\n",
       " (1, (597, 90)): 928,\n",
       " (1, (540, 90)): 929,\n",
       " (1, (272, 90)): 930,\n",
       " (1, (155, 76)): 931,\n",
       " (1, (68, 76)): 932,\n",
       " (1, (711, 76)): 933,\n",
       " (1, (180, 76)): 934,\n",
       " (1, (385, 90)): 935,\n",
       " (1, (356, 62)): 936,\n",
       " (1, (242, 62)): 937,\n",
       " (1, (430, 90)): 938,\n",
       " (1, (652, 76)): 939,\n",
       " (1, (40, 76)): 940,\n",
       " (1, (121, 76)): 941,\n",
       " (1, (404, 90)): 942,\n",
       " (1, (269, 62)): 943,\n",
       " (1, (329, 76)): 944,\n",
       " (1, (71, 76)): 945,\n",
       " (1, (156, 76)): 946,\n",
       " (1, (483, 90)): 947,\n",
       " (1, (710, 76)): 948,\n",
       " (1, (601, 90)): 949,\n",
       " (1, (574, 62)): 950,\n",
       " (1, (151, 76)): 951,\n",
       " (1, (245, 62)): 952,\n",
       " (1, (175, 76)): 953,\n",
       " (1, (96, 76)): 954,\n",
       " (1, (716, 76)): 955,\n",
       " (1, (218, 48)): 956,\n",
       " (1, (499, 48)): 957,\n",
       " (1, (573, 62)): 958,\n",
       " (1, (99, 76)): 959,\n",
       " (1, (399, 76)): 960,\n",
       " (1, (120, 76)): 961,\n",
       " (1, (575, 62)): 962,\n",
       " (1, (602, 90)): 963,\n",
       " (1, (122, 76)): 964,\n",
       " (1, (718, 76)): 965,\n",
       " (1, (269, 90)): 966,\n",
       " (1, (484, 90)): 967,\n",
       " (1, (431, 62)): 968,\n",
       " (1, (717, 76)): 969,\n",
       " (1, (123, 76)): 970,\n",
       " (1, (95, 76)): 971,\n",
       " (1, (680, 76)): 972,\n",
       " (1, (552, 90)): 973,\n",
       " (1, (567, 76)): 974,\n",
       " (1, (131, 76)): 975,\n",
       " (1, (242, 90)): 976,\n",
       " (1, (130, 76)): 977,\n",
       " (1, (600, 90)): 978,\n",
       " (1, (128, 76)): 979,\n",
       " (1, (599, 90)): 980,\n",
       " (1, (97, 76)): 981,\n",
       " (1, (572, 62)): 982,\n",
       " (1, (598, 90)): 983,\n",
       " (3, (25, 6)): 984,\n",
       " (1, (160, 76)): 985,\n",
       " (1, (709, 48)): 986,\n",
       " (1, (580, 76)): 987,\n",
       " (1, (384, 62)): 988,\n",
       " (1, (350, 62)): 989,\n",
       " (1, (43, 76)): 990,\n",
       " (1, (579, 90)): 991,\n",
       " (1, (576, 62)): 992,\n",
       " (1, (129, 76)): 993,\n",
       " (1, (404, 62)): 994,\n",
       " (1, (98, 76)): 995,\n",
       " (1, (577, 62)): 996,\n",
       " (1, (67, 76)): 997,\n",
       " (1, (539, 90)): 998,\n",
       " (1, (94, 76)): 999,\n",
       " (1, (571, 62)): 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "loc_file = \"results/rq1/all_layers/simple_fm/loc.all_cost.loc.0.1.pkl\"\n",
    "loc_which = 'localiser'\n",
    "target_weights = fm_target_layes\n",
    "\n",
    "pairs_loc = get_weight_and_cost(loc_which, seed, loc_file, target_weights, method = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, (9, 8)): 1,\n",
       " (3, (93, 6)): 2,\n",
       " (3, (93, 7)): 3,\n",
       " (3, (93, 9)): 4,\n",
       " (3, (5, 3)): 5,\n",
       " (3, (16, 6)): 6,\n",
       " (3, (48, 2)): 7,\n",
       " (3, (93, 0)): 8,\n",
       " (3, (93, 2)): 9,\n",
       " (3, (93, 4)): 10,\n",
       " (3, (93, 5)): 11,\n",
       " (3, (1, 8)): 12,\n",
       " (3, (5, 4)): 13,\n",
       " (3, (9, 2)): 14,\n",
       " (3, (9, 6)): 15,\n",
       " (3, (21, 6)): 16,\n",
       " (3, (45, 2)): 17,\n",
       " (3, (45, 6)): 18,\n",
       " (3, (45, 9)): 19,\n",
       " (3, (62, 6)): 20,\n",
       " (3, (66, 0)): 21,\n",
       " (3, (66, 8)): 22,\n",
       " (3, (67, 8)): 23,\n",
       " (3, (74, 8)): 24,\n",
       " (3, (93, 3)): 25,\n",
       " (3, (93, 8)): 26,\n",
       " (3, (5, 7)): 27,\n",
       " (3, (9, 7)): 28,\n",
       " (3, (41, 6)): 29,\n",
       " (3, (45, 3)): 30,\n",
       " (3, (45, 4)): 31,\n",
       " (3, (50, 5)): 32,\n",
       " (3, (50, 6)): 33,\n",
       " (3, (59, 4)): 34,\n",
       " (3, (62, 7)): 35,\n",
       " (3, (71, 1)): 36,\n",
       " (3, (71, 6)): 37,\n",
       " (3, (74, 5)): 38,\n",
       " (3, (76, 6)): 39,\n",
       " (3, (86, 0)): 40,\n",
       " (3, (1, 7)): 41,\n",
       " (3, (5, 2)): 42,\n",
       " (3, (5, 6)): 43,\n",
       " (3, (9, 4)): 44,\n",
       " (3, (9, 9)): 45,\n",
       " (3, (16, 2)): 46,\n",
       " (3, (50, 9)): 47,\n",
       " (3, (55, 5)): 48,\n",
       " (3, (74, 2)): 49,\n",
       " (3, (16, 0)): 50,\n",
       " (3, (37, 0)): 51,\n",
       " (3, (45, 1)): 52,\n",
       " (3, (45, 8)): 53,\n",
       " (3, (46, 5)): 54,\n",
       " (3, (48, 6)): 55,\n",
       " (3, (55, 8)): 56,\n",
       " (3, (59, 6)): 57,\n",
       " (3, (66, 1)): 58,\n",
       " (3, (71, 0)): 59,\n",
       " (3, (71, 4)): 60,\n",
       " (3, (86, 4)): 61,\n",
       " (3, (1, 4)): 62,\n",
       " (3, (16, 9)): 63,\n",
       " (3, (27, 7)): 64,\n",
       " (3, (37, 1)): 65,\n",
       " (3, (40, 5)): 66,\n",
       " (3, (46, 7)): 67,\n",
       " (3, (50, 0)): 68,\n",
       " (3, (58, 6)): 69,\n",
       " (3, (67, 5)): 70,\n",
       " (3, (67, 6)): 71,\n",
       " (3, (68, 3)): 72,\n",
       " (3, (68, 4)): 73,\n",
       " (3, (71, 2)): 74,\n",
       " (3, (74, 4)): 75,\n",
       " (3, (86, 5)): 76,\n",
       " (3, (86, 6)): 77,\n",
       " (3, (90, 6)): 78,\n",
       " (3, (5, 0)): 79,\n",
       " (3, (5, 8)): 80,\n",
       " (3, (8, 4)): 81,\n",
       " (3, (14, 4)): 82,\n",
       " (3, (21, 0)): 83,\n",
       " (3, (21, 2)): 84,\n",
       " (3, (23, 4)): 85,\n",
       " (3, (37, 7)): 86,\n",
       " (3, (41, 4)): 87,\n",
       " (3, (44, 6)): 88,\n",
       " (3, (46, 4)): 89,\n",
       " (3, (50, 1)): 90,\n",
       " (3, (50, 4)): 91,\n",
       " (3, (55, 6)): 92,\n",
       " (3, (59, 0)): 93,\n",
       " (3, (66, 4)): 94,\n",
       " (3, (67, 9)): 95,\n",
       " (3, (69, 3)): 96,\n",
       " (3, (69, 6)): 97,\n",
       " (3, (74, 6)): 98,\n",
       " (3, (84, 3)): 99,\n",
       " (3, (1, 2)): 100,\n",
       " (3, (2, 6)): 101,\n",
       " (3, (16, 4)): 102,\n",
       " (3, (19, 4)): 103,\n",
       " (3, (33, 7)): 104,\n",
       " (3, (44, 4)): 105,\n",
       " (3, (45, 7)): 106,\n",
       " (3, (55, 4)): 107,\n",
       " (3, (62, 3)): 108,\n",
       " (3, (64, 0)): 109,\n",
       " (3, (66, 6)): 110,\n",
       " (3, (67, 4)): 111,\n",
       " (3, (68, 6)): 112,\n",
       " (3, (71, 7)): 113,\n",
       " (3, (86, 7)): 114,\n",
       " (3, (8, 0)): 115,\n",
       " (3, (9, 0)): 116,\n",
       " (3, (9, 3)): 117,\n",
       " (3, (14, 6)): 118,\n",
       " (3, (14, 8)): 119,\n",
       " (3, (19, 0)): 120,\n",
       " (3, (25, 6)): 121,\n",
       " (3, (27, 6)): 122,\n",
       " (3, (31, 0)): 123,\n",
       " (3, (31, 5)): 124,\n",
       " (3, (42, 7)): 125,\n",
       " (3, (50, 2)): 126,\n",
       " (3, (69, 2)): 127,\n",
       " (3, (71, 8)): 128,\n",
       " (3, (74, 0)): 129,\n",
       " (3, (82, 4)): 130,\n",
       " (3, (83, 5)): 131,\n",
       " (3, (1, 0)): 132,\n",
       " (3, (8, 6)): 133,\n",
       " (3, (16, 7)): 134,\n",
       " (3, (27, 9)): 135,\n",
       " (3, (29, 8)): 136,\n",
       " (3, (34, 6)): 137,\n",
       " (3, (34, 7)): 138,\n",
       " (3, (36, 5)): 139,\n",
       " (3, (45, 0)): 140,\n",
       " (3, (50, 8)): 141,\n",
       " (3, (51, 3)): 142,\n",
       " (3, (51, 4)): 143,\n",
       " (3, (59, 2)): 144,\n",
       " (3, (64, 8)): 145,\n",
       " (3, (68, 0)): 146,\n",
       " (3, (69, 0)): 147,\n",
       " (3, (73, 4)): 148,\n",
       " (3, (73, 6)): 149,\n",
       " (3, (86, 2)): 150,\n",
       " (3, (1, 6)): 151,\n",
       " (3, (16, 3)): 152,\n",
       " (3, (19, 5)): 153,\n",
       " (3, (19, 6)): 154,\n",
       " (3, (23, 7)): 155,\n",
       " (3, (33, 8)): 156,\n",
       " (3, (33, 9)): 157,\n",
       " (3, (36, 8)): 158,\n",
       " (3, (37, 9)): 159,\n",
       " (3, (41, 2)): 160,\n",
       " (3, (41, 3)): 161,\n",
       " (3, (42, 8)): 162,\n",
       " (3, (46, 0)): 163,\n",
       " (3, (58, 0)): 164,\n",
       " (3, (66, 2)): 165,\n",
       " (3, (66, 7)): 166,\n",
       " (3, (67, 0)): 167,\n",
       " (3, (67, 2)): 168,\n",
       " (3, (80, 9)): 169,\n",
       " (3, (98, 3)): 170,\n",
       " (1, (259, 48)): 171,\n",
       " (1, (316, 48)): 172,\n",
       " (1, (343, 48)): 173,\n",
       " (1, (356, 48)): 174,\n",
       " (1, (371, 48)): 175,\n",
       " (1, (381, 48)): 176,\n",
       " (1, (426, 48)): 177,\n",
       " (1, (514, 48)): 178,\n",
       " (1, (544, 48)): 179,\n",
       " (1, (546, 48)): 180,\n",
       " (1, (548, 48)): 181,\n",
       " (3, (0, 4)): 182,\n",
       " (3, (8, 2)): 183,\n",
       " (3, (12, 8)): 184,\n",
       " (3, (14, 2)): 185,\n",
       " (3, (19, 2)): 186,\n",
       " (3, (19, 3)): 187,\n",
       " (3, (24, 0)): 188,\n",
       " (3, (36, 4)): 189,\n",
       " (3, (37, 5)): 190,\n",
       " (3, (40, 7)): 191,\n",
       " (3, (42, 9)): 192,\n",
       " (3, (46, 9)): 193,\n",
       " (3, (52, 2)): 194,\n",
       " (3, (55, 0)): 195,\n",
       " (3, (58, 3)): 196,\n",
       " (3, (59, 1)): 197,\n",
       " (3, (64, 4)): 198,\n",
       " (3, (66, 3)): 199,\n",
       " (3, (70, 7)): 200,\n",
       " (3, (82, 6)): 201,\n",
       " (3, (84, 0)): 202,\n",
       " (3, (84, 4)): 203,\n",
       " (3, (84, 6)): 204,\n",
       " (3, (88, 6)): 205,\n",
       " (3, (98, 8)): 206,\n",
       " (3, (99, 7)): 207,\n",
       " (1, (149, 76)): 208,\n",
       " (1, (203, 48)): 209,\n",
       " (1, (231, 48)): 210,\n",
       " (1, (287, 48)): 211,\n",
       " (1, (288, 48)): 212,\n",
       " (1, (315, 48)): 213,\n",
       " (1, (328, 48)): 214,\n",
       " (1, (329, 48)): 215,\n",
       " (1, (351, 62)): 216,\n",
       " (1, (384, 48)): 217,\n",
       " (1, (441, 48)): 218,\n",
       " (1, (457, 62)): 219,\n",
       " (1, (458, 48)): 220,\n",
       " (1, (465, 62)): 221,\n",
       " (1, (482, 48)): 222,\n",
       " (1, (514, 76)): 223,\n",
       " (1, (517, 48)): 224,\n",
       " (1, (543, 48)): 225,\n",
       " (1, (566, 48)): 226,\n",
       " (1, (574, 48)): 227,\n",
       " (3, (0, 7)): 228,\n",
       " (3, (1, 5)): 229,\n",
       " (3, (23, 1)): 230,\n",
       " (3, (24, 4)): 231,\n",
       " (3, (25, 0)): 232,\n",
       " (3, (29, 3)): 233,\n",
       " (3, (34, 2)): 234,\n",
       " (3, (40, 3)): 235,\n",
       " (3, (52, 4)): 236,\n",
       " (3, (52, 6)): 237,\n",
       " (3, (55, 2)): 238,\n",
       " (3, (62, 0)): 239,\n",
       " (3, (62, 8)): 240,\n",
       " (3, (62, 9)): 241,\n",
       " (3, (73, 0)): 242,\n",
       " (3, (75, 8)): 243,\n",
       " (3, (76, 4)): 244,\n",
       " (3, (83, 0)): 245,\n",
       " (3, (83, 6)): 246,\n",
       " (3, (95, 6)): 247,\n",
       " (3, (98, 4)): 248,\n",
       " (1, (272, 48)): 249,\n",
       " (1, (383, 62)): 250,\n",
       " (1, (385, 48)): 251,\n",
       " (1, (399, 48)): 252,\n",
       " (1, (410, 62)): 253,\n",
       " (1, (427, 48)): 254,\n",
       " (1, (430, 48)): 255,\n",
       " (1, (469, 48)): 256,\n",
       " (1, (490, 48)): 257,\n",
       " (1, (491, 62)): 258,\n",
       " (1, (493, 48)): 259,\n",
       " (1, (510, 48)): 260,\n",
       " (1, (515, 48)): 261,\n",
       " (1, (518, 48)): 262,\n",
       " (1, (522, 90)): 263,\n",
       " (1, (538, 48)): 264,\n",
       " (1, (569, 62)): 265,\n",
       " (1, (594, 48)): 266,\n",
       " (3, (0, 0)): 267,\n",
       " (3, (7, 8)): 268,\n",
       " (3, (8, 5)): 269,\n",
       " (3, (23, 9)): 270,\n",
       " (3, (27, 5)): 271,\n",
       " (3, (33, 0)): 272,\n",
       " (3, (33, 2)): 273,\n",
       " (3, (34, 9)): 274,\n",
       " (3, (36, 2)): 275,\n",
       " (3, (48, 4)): 276,\n",
       " (3, (51, 5)): 277,\n",
       " (3, (51, 6)): 278,\n",
       " (3, (64, 3)): 279,\n",
       " (3, (76, 2)): 280,\n",
       " (3, (84, 9)): 281,\n",
       " (3, (99, 2)): 282,\n",
       " (1, (204, 48)): 283,\n",
       " (1, (232, 48)): 284,\n",
       " (1, (242, 62)): 285,\n",
       " (1, (259, 9)): 286,\n",
       " (1, (328, 62)): 287,\n",
       " (1, (344, 48)): 288,\n",
       " (1, (370, 48)): 289,\n",
       " (1, (372, 48)): 290,\n",
       " (1, (398, 48)): 291,\n",
       " (1, (413, 48)): 292,\n",
       " (1, (454, 48)): 293,\n",
       " (1, (462, 48)): 294,\n",
       " (1, (486, 48)): 295,\n",
       " (1, (489, 21)): 296,\n",
       " (1, (513, 48)): 297,\n",
       " (1, (547, 48)): 298,\n",
       " (1, (550, 48)): 299,\n",
       " (1, (569, 48)): 300,\n",
       " (1, (601, 48)): 301,\n",
       " (1, (602, 48)): 302,\n",
       " (3, (0, 6)): 303,\n",
       " (3, (10, 4)): 304,\n",
       " (3, (12, 4)): 305,\n",
       " (3, (12, 6)): 306,\n",
       " (3, (14, 1)): 307,\n",
       " (3, (16, 1)): 308,\n",
       " (3, (21, 7)): 309,\n",
       " (3, (29, 6)): 310,\n",
       " (3, (29, 7)): 311,\n",
       " (3, (31, 6)): 312,\n",
       " (3, (33, 3)): 313,\n",
       " (3, (33, 4)): 314,\n",
       " (3, (36, 6)): 315,\n",
       " (3, (40, 9)): 316,\n",
       " (3, (48, 7)): 317,\n",
       " (3, (52, 0)): 318,\n",
       " (3, (53, 0)): 319,\n",
       " (3, (58, 2)): 320,\n",
       " (3, (58, 4)): 321,\n",
       " (3, (59, 8)): 322,\n",
       " (3, (62, 5)): 323,\n",
       " (3, (63, 3)): 324,\n",
       " (3, (70, 9)): 325,\n",
       " (3, (71, 9)): 326,\n",
       " (3, (84, 2)): 327,\n",
       " (3, (95, 8)): 328,\n",
       " (1, (203, 9)): 329,\n",
       " (1, (260, 48)): 330,\n",
       " (1, (301, 48)): 331,\n",
       " (1, (315, 9)): 332,\n",
       " (1, (343, 9)): 333,\n",
       " (1, (357, 48)): 334,\n",
       " (1, (375, 48)): 335,\n",
       " (1, (434, 48)): 336,\n",
       " (1, (437, 48)): 337,\n",
       " (1, (482, 9)): 338,\n",
       " (1, (486, 62)): 339,\n",
       " (1, (487, 48)): 340,\n",
       " (1, (497, 48)): 341,\n",
       " (1, (511, 9)): 342,\n",
       " (1, (522, 5)): 343,\n",
       " (1, (525, 48)): 344,\n",
       " (1, (541, 48)): 345,\n",
       " (1, (542, 48)): 346,\n",
       " (1, (571, 48)): 347,\n",
       " (1, (598, 48)): 348,\n",
       " (1, (625, 48)): 349,\n",
       " (3, (1, 3)): 350,\n",
       " (3, (5, 1)): 351,\n",
       " (3, (8, 1)): 352,\n",
       " (3, (9, 1)): 353,\n",
       " (3, (23, 5)): 354,\n",
       " (3, (23, 6)): 355,\n",
       " (3, (27, 2)): 356,\n",
       " (3, (33, 5)): 357,\n",
       " (3, (40, 6)): 358,\n",
       " (3, (42, 4)): 359,\n",
       " (3, (50, 7)): 360,\n",
       " (3, (55, 9)): 361,\n",
       " (3, (63, 1)): 362,\n",
       " (3, (64, 2)): 363,\n",
       " (3, (68, 1)): 364,\n",
       " (3, (68, 8)): 365,\n",
       " (3, (69, 8)): 366,\n",
       " (3, (76, 8)): 367,\n",
       " (3, (82, 2)): 368,\n",
       " (3, (89, 4)): 369,\n",
       " (3, (93, 1)): 370,\n",
       " (3, (94, 0)): 371,\n",
       " (3, (99, 1)): 372,\n",
       " (1, (231, 9)): 373,\n",
       " (1, (244, 48)): 374,\n",
       " (1, (268, 48)): 375,\n",
       " (1, (271, 62)): 376,\n",
       " (1, (300, 48)): 377,\n",
       " (1, (314, 48)): 378,\n",
       " (1, (329, 9)): 379,\n",
       " (1, (342, 48)): 380,\n",
       " (1, (347, 48)): 381,\n",
       " (1, (354, 5)): 382,\n",
       " (1, (374, 48)): 383,\n",
       " (1, (406, 48)): 384,\n",
       " (1, (407, 48)): 385,\n",
       " (1, (433, 48)): 386,\n",
       " (1, (455, 9)): 387,\n",
       " (1, (455, 48)): 388,\n",
       " (1, (467, 48)): 389,\n",
       " (1, (469, 5)): 390,\n",
       " (1, (485, 9)): 391,\n",
       " (1, (494, 48)): 392,\n",
       " (1, (578, 48)): 393,\n",
       " (1, (626, 48)): 394,\n",
       " (1, (629, 48)): 395,\n",
       " (3, (2, 2)): 396,\n",
       " (3, (4, 0)): 397,\n",
       " (3, (9, 5)): 398,\n",
       " (3, (10, 8)): 399,\n",
       " (3, (12, 5)): 400,\n",
       " (3, (13, 2)): 401,\n",
       " (3, (14, 3)): 402,\n",
       " (3, (16, 5)): 403,\n",
       " (3, (25, 1)): 404,\n",
       " (3, (34, 3)): 405,\n",
       " (3, (42, 3)): 406,\n",
       " (3, (42, 6)): 407,\n",
       " (3, (47, 0)): 408,\n",
       " (3, (50, 3)): 409,\n",
       " (3, (62, 2)): 410,\n",
       " (3, (62, 4)): 411,\n",
       " (3, (64, 6)): 412,\n",
       " (3, (69, 4)): 413,\n",
       " (3, (73, 1)): 414,\n",
       " (3, (75, 0)): 415,\n",
       " (3, (81, 8)): 416,\n",
       " (3, (91, 1)): 417,\n",
       " (3, (95, 2)): 418,\n",
       " (3, (95, 4)): 419,\n",
       " (3, (98, 6)): 420,\n",
       " (3, (99, 9)): 421,\n",
       " (1, (99, 48)): 422,\n",
       " (1, (233, 48)): 423,\n",
       " (1, (261, 48)): 424,\n",
       " (1, (269, 90)): 425,\n",
       " (1, (377, 62)): 426,\n",
       " (1, (377, 76)): 427,\n",
       " (1, (380, 48)): 428,\n",
       " (1, (385, 62)): 429,\n",
       " (1, (402, 48)): 430,\n",
       " (1, (428, 62)): 431,\n",
       " (1, (439, 76)): 432,\n",
       " (1, (459, 48)): 433,\n",
       " (1, (485, 48)): 434,\n",
       " (1, (516, 48)): 435,\n",
       " (1, (519, 48)): 436,\n",
       " (1, (541, 76)): 437,\n",
       " (1, (541, 90)): 438,\n",
       " (1, (545, 9)): 439,\n",
       " (1, (546, 62)): 440,\n",
       " (1, (570, 48)): 441,\n",
       " (1, (597, 41)): 442,\n",
       " (1, (604, 9)): 443,\n",
       " (1, (606, 41)): 444,\n",
       " (3, (7, 4)): 445,\n",
       " (3, (8, 8)): 446,\n",
       " (3, (8, 9)): 447,\n",
       " (3, (10, 1)): 448,\n",
       " (3, (10, 6)): 449,\n",
       " (3, (11, 9)): 450,\n",
       " (3, (14, 7)): 451,\n",
       " (3, (20, 2)): 452,\n",
       " (3, (22, 2)): 453,\n",
       " (3, (23, 8)): 454,\n",
       " (3, (24, 2)): 455,\n",
       " (3, (25, 8)): 456,\n",
       " (3, (36, 9)): 457,\n",
       " (3, (41, 0)): 458,\n",
       " (3, (41, 5)): 459,\n",
       " (3, (44, 0)): 460,\n",
       " (3, (44, 3)): 461,\n",
       " (3, (44, 8)): 462,\n",
       " (3, (48, 8)): 463,\n",
       " (3, (51, 2)): 464,\n",
       " (3, (51, 8)): 465,\n",
       " (3, (55, 3)): 466,\n",
       " (3, (70, 6)): 467,\n",
       " (3, (75, 7)): 468,\n",
       " (3, (81, 6)): 469,\n",
       " (3, (86, 1)): 470,\n",
       " (3, (98, 2)): 471,\n",
       " (3, (99, 5)): 472,\n",
       " (1, (98, 48)): 473,\n",
       " (1, (126, 48)): 474,\n",
       " (1, (127, 48)): 475,\n",
       " (1, (128, 48)): 476,\n",
       " (1, (262, 76)): 477,\n",
       " (1, (273, 48)): 478,\n",
       " (1, (350, 48)): 479,\n",
       " (1, (353, 48)): 480,\n",
       " (1, (371, 9)): 481,\n",
       " (1, (380, 5)): 482,\n",
       " (1, (382, 5)): 483,\n",
       " (1, (385, 5)): 484,\n",
       " (1, (404, 48)): 485,\n",
       " (1, (429, 48)): 486,\n",
       " (1, (435, 62)): 487,\n",
       " (1, (436, 48)): 488,\n",
       " (1, (438, 48)): 489,\n",
       " (1, (460, 48)): 490,\n",
       " (1, (461, 62)): 491,\n",
       " (1, (467, 5)): 492,\n",
       " (1, (488, 48)): 493,\n",
       " (1, (494, 90)): 494,\n",
       " (1, (513, 62)): 495,\n",
       " (1, (513, 76)): 496,\n",
       " (1, (518, 76)): 497,\n",
       " (1, (522, 48)): 498,\n",
       " (1, (541, 62)): 499,\n",
       " (1, (567, 9)): 500,\n",
       " (1, (569, 76)): 501,\n",
       " (1, (622, 48)): 502,\n",
       " (1, (630, 62)): 503,\n",
       " (3, (0, 9)): 504,\n",
       " (3, (2, 4)): 505,\n",
       " (3, (10, 2)): 506,\n",
       " (3, (11, 6)): 507,\n",
       " (3, (19, 7)): 508,\n",
       " (3, (31, 9)): 509,\n",
       " (3, (34, 5)): 510,\n",
       " (3, (40, 2)): 511,\n",
       " (3, (42, 5)): 512,\n",
       " (3, (44, 2)): 513,\n",
       " (3, (48, 9)): 514,\n",
       " (3, (59, 5)): 515,\n",
       " (3, (75, 6)): 516,\n",
       " (3, (76, 7)): 517,\n",
       " (3, (80, 6)): 518,\n",
       " (3, (81, 1)): 519,\n",
       " (3, (84, 8)): 520,\n",
       " (3, (86, 8)): 521,\n",
       " (3, (89, 6)): 522,\n",
       " (3, (89, 8)): 523,\n",
       " (3, (90, 7)): 524,\n",
       " (3, (91, 4)): 525,\n",
       " (3, (95, 0)): 526,\n",
       " (1, (130, 48)): 527,\n",
       " (1, (158, 48)): 528,\n",
       " (1, (160, 9)): 529,\n",
       " (1, (204, 9)): 530,\n",
       " (1, (210, 41)): 531,\n",
       " (1, (241, 62)): 532,\n",
       " (1, (297, 48)): 533,\n",
       " (1, (322, 48)): 534,\n",
       " (1, (323, 48)): 535,\n",
       " (1, (324, 76)): 536,\n",
       " (1, (352, 62)): 537,\n",
       " (1, (353, 9)): 538,\n",
       " (1, (378, 48)): 539,\n",
       " (1, (379, 48)): 540,\n",
       " (1, (403, 48)): 541,\n",
       " (1, (405, 48)): 542,\n",
       " (1, (410, 21)): 543,\n",
       " (1, (432, 48)): 544,\n",
       " (1, (437, 62)): 545,\n",
       " (1, (463, 48)): 546,\n",
       " (1, (487, 9)): 547,\n",
       " (1, (489, 62)): 548,\n",
       " (1, (492, 48)): 549,\n",
       " (1, (513, 82)): 550,\n",
       " (1, (542, 76)): 551,\n",
       " (1, (553, 48)): 552,\n",
       " (1, (570, 76)): 553,\n",
       " (1, (572, 48)): 554,\n",
       " (1, (573, 48)): 555,\n",
       " (1, (574, 41)): 556,\n",
       " (1, (597, 48)): 557,\n",
       " (1, (657, 48)): 558,\n",
       " (1, (658, 48)): 559,\n",
       " (3, (3, 6)): 560,\n",
       " (3, (5, 9)): 561,\n",
       " (3, (7, 7)): 562,\n",
       " (3, (12, 0)): 563,\n",
       " (3, (20, 4)): 564,\n",
       " (3, (21, 4)): 565,\n",
       " (3, (21, 9)): 566,\n",
       " (3, (27, 3)): 567,\n",
       " (3, (41, 1)): 568,\n",
       " (3, (41, 7)): 569,\n",
       " (3, (44, 7)): 570,\n",
       " (3, (67, 3)): 571,\n",
       " (3, (68, 7)): 572,\n",
       " (3, (70, 5)): 573,\n",
       " (3, (74, 3)): 574,\n",
       " (3, (75, 2)): 575,\n",
       " (3, (78, 6)): 576,\n",
       " (3, (80, 5)): 577,\n",
       " (3, (82, 1)): 578,\n",
       " (3, (90, 8)): 579,\n",
       " (3, (91, 5)): 580,\n",
       " (3, (91, 6)): 581,\n",
       " (3, (95, 3)): 582,\n",
       " (3, (95, 5)): 583,\n",
       " (3, (99, 4)): 584,\n",
       " (1, (71, 41)): 585,\n",
       " (1, (72, 41)): 586,\n",
       " (1, (121, 48)): 587,\n",
       " (1, (124, 48)): 588,\n",
       " (1, (129, 48)): 589,\n",
       " (1, (151, 9)): 590,\n",
       " (1, (175, 9)): 591,\n",
       " (1, (214, 62)): 592,\n",
       " (1, (215, 9)): 593,\n",
       " (1, (262, 9)): 594,\n",
       " (1, (263, 9)): 595,\n",
       " (1, (268, 41)): 596,\n",
       " (1, (270, 41)): 597,\n",
       " (1, (273, 62)): 598,\n",
       " (1, (287, 9)): 599,\n",
       " (1, (290, 76)): 600,\n",
       " (1, (298, 21)): 601,\n",
       " (1, (315, 41)): 602,\n",
       " (1, (317, 48)): 603,\n",
       " (1, (324, 48)): 604,\n",
       " (1, (350, 62)): 605,\n",
       " (1, (356, 76)): 606,\n",
       " (1, (377, 5)): 607,\n",
       " (1, (386, 62)): 608,\n",
       " (1, (401, 48)): 609,\n",
       " (1, (431, 48)): 610,\n",
       " (1, (462, 62)): 611,\n",
       " (1, (466, 48)): 612,\n",
       " (1, (483, 48)): 613,\n",
       " (1, (489, 48)): 614,\n",
       " (1, (491, 48)): 615,\n",
       " (1, (493, 9)): 616,\n",
       " (1, (520, 48)): 617,\n",
       " (1, (522, 76)): 618,\n",
       " (1, (526, 48)): 619,\n",
       " (1, (545, 48)): 620,\n",
       " (1, (548, 5)): 621,\n",
       " (1, (567, 41)): 622,\n",
       " (1, (577, 48)): 623,\n",
       " (1, (600, 48)): 624,\n",
       " (1, (610, 48)): 625,\n",
       " (1, (624, 9)): 626,\n",
       " (1, (627, 48)): 627,\n",
       " (1, (633, 48)): 628,\n",
       " (1, (651, 9)): 629,\n",
       " (3, (1, 1)): 630,\n",
       " (3, (14, 0)): 631,\n",
       " (3, (19, 8)): 632,\n",
       " (3, (25, 9)): 633,\n",
       " (3, (31, 3)): 634,\n",
       " (3, (40, 1)): 635,\n",
       " (3, (40, 8)): 636,\n",
       " (3, (52, 7)): 637,\n",
       " (3, (52, 8)): 638,\n",
       " (3, (63, 6)): 639,\n",
       " (3, (70, 0)): 640,\n",
       " (3, (71, 3)): 641,\n",
       " (1, (69, 48)): 642,\n",
       " (1, (101, 48)): 643,\n",
       " (1, (175, 48)): 644,\n",
       " (1, (210, 9)): 645,\n",
       " (1, (231, 41)): 646,\n",
       " (1, (245, 48)): 647,\n",
       " (1, (258, 48)): 648,\n",
       " (1, (269, 62)): 649,\n",
       " (1, (286, 48)): 650,\n",
       " (1, (292, 21)): 651,\n",
       " (1, (318, 48)): 652,\n",
       " (1, (319, 48)): 653,\n",
       " (1, (324, 62)): 654,\n",
       " (1, (345, 9)): 655,\n",
       " (1, (346, 48)): 656,\n",
       " (1, (351, 48)): 657,\n",
       " (1, (372, 9)): 658,\n",
       " (1, (382, 1)): 659,\n",
       " (1, (400, 48)): 660,\n",
       " (1, (402, 41)): 661,\n",
       " (1, (410, 48)): 662,\n",
       " (1, (410, 76)): 663,\n",
       " (1, (438, 76)): 664,\n",
       " (1, (441, 5)): 665,\n",
       " (1, (457, 41)): 666,\n",
       " (1, (461, 76)): 667,\n",
       " (1, (489, 76)): 668,\n",
       " (1, (490, 76)): 669,\n",
       " (1, (519, 55)): 670,\n",
       " (1, (521, 48)): 671,\n",
       " (1, (547, 1)): 672,\n",
       " (1, (549, 48)): 673,\n",
       " (1, (551, 9)): 674,\n",
       " (1, (569, 41)): 675,\n",
       " (1, (571, 76)): 676,\n",
       " (1, (576, 48)): 677,\n",
       " (1, (581, 48)): 678,\n",
       " (1, (604, 62)): 679,\n",
       " (1, (628, 48)): 680,\n",
       " (1, (638, 48)): 681,\n",
       " (1, (652, 62)): 682,\n",
       " (3, (10, 9)): 683,\n",
       " (3, (20, 3)): 684,\n",
       " (3, (20, 6)): 685,\n",
       " (3, (31, 8)): 686,\n",
       " (3, (32, 6)): 687,\n",
       " (3, (36, 0)): 688,\n",
       " (3, (43, 4)): 689,\n",
       " (3, (51, 0)): 690,\n",
       " (3, (58, 1)): 691,\n",
       " (3, (81, 0)): 692,\n",
       " (3, (82, 0)): 693,\n",
       " (3, (89, 0)): 694,\n",
       " (3, (90, 4)): 695,\n",
       " (1, (204, 21)): 696,\n",
       " (1, (206, 9)): 697,\n",
       " (1, (214, 41)): 698,\n",
       " (1, (215, 21)): 699,\n",
       " (1, (262, 48)): 700,\n",
       " (1, (271, 48)): 701,\n",
       " (1, (288, 9)): 702,\n",
       " (1, (288, 55)): 703,\n",
       " (1, (289, 48)): 704,\n",
       " (1, (295, 48)): 705,\n",
       " (1, (298, 48)): 706,\n",
       " (1, (301, 55)): 707,\n",
       " (1, (321, 41)): 708,\n",
       " (1, (326, 5)): 709,\n",
       " (1, (326, 41)): 710,\n",
       " (1, (329, 62)): 711,\n",
       " (1, (354, 76)): 712,\n",
       " (1, (412, 48)): 713,\n",
       " (1, (413, 9)): 714,\n",
       " (1, (436, 76)): 715,\n",
       " (1, (439, 5)): 716,\n",
       " (1, (442, 48)): 717,\n",
       " (1, (455, 67)): 718,\n",
       " (1, (461, 48)): 719,\n",
       " (1, (464, 5)): 720,\n",
       " (1, (464, 48)): 721,\n",
       " (1, (465, 48)): 722,\n",
       " (1, (466, 76)): 723,\n",
       " (1, (468, 5)): 724,\n",
       " (1, (496, 5)): 725,\n",
       " (1, (499, 5)): 726,\n",
       " (1, (539, 62)): 727,\n",
       " (1, (571, 9)): 728,\n",
       " (1, (575, 48)): 729,\n",
       " (1, (575, 76)): 730,\n",
       " (1, (577, 76)): 731,\n",
       " (1, (579, 48)): 732,\n",
       " (1, (582, 48)): 733,\n",
       " (1, (603, 5)): 734,\n",
       " (1, (607, 48)): 735,\n",
       " (1, (609, 41)): 736,\n",
       " (1, (656, 48)): 737,\n",
       " (1, (657, 41)): 738,\n",
       " (1, (686, 48)): 739,\n",
       " (1, (688, 48)): 740,\n",
       " (3, (7, 0)): 741,\n",
       " (3, (11, 2)): 742,\n",
       " (3, (19, 1)): 743,\n",
       " (3, (20, 0)): 744,\n",
       " (3, (21, 5)): 745,\n",
       " (3, (22, 9)): 746,\n",
       " (3, (42, 2)): 747,\n",
       " (3, (48, 1)): 748,\n",
       " (3, (51, 7)): 749,\n",
       " (3, (62, 1)): 750,\n",
       " (3, (68, 2)): 751,\n",
       " (3, (80, 4)): 752,\n",
       " (3, (83, 3)): 753,\n",
       " (3, (88, 2)): 754,\n",
       " (3, (91, 2)): 755,\n",
       " (3, (97, 3)): 756,\n",
       " (1, (150, 9)): 757,\n",
       " (1, (156, 48)): 758,\n",
       " (1, (214, 48)): 759,\n",
       " (1, (215, 62)): 760,\n",
       " (1, (234, 41)): 761,\n",
       " (1, (242, 48)): 762,\n",
       " (1, (244, 5)): 763,\n",
       " (1, (269, 9)): 764,\n",
       " (1, (272, 41)): 765,\n",
       " (1, (294, 21)): 766,\n",
       " (1, (295, 9)): 767,\n",
       " (1, (299, 48)): 768,\n",
       " (1, (301, 62)): 769,\n",
       " (1, (353, 76)): 770,\n",
       " (1, (356, 9)): 771,\n",
       " (1, (356, 62)): 772,\n",
       " (1, (376, 48)): 773,\n",
       " (1, (382, 76)): 774,\n",
       " (1, (405, 41)): 775,\n",
       " (1, (408, 48)): 776,\n",
       " (1, (430, 41)): 777,\n",
       " (1, (437, 9)): 778,\n",
       " (1, (440, 5)): 779,\n",
       " (1, (456, 55)): 780,\n",
       " (1, (457, 9)): 781,\n",
       " (1, (457, 48)): 782,\n",
       " (1, (490, 21)): 783,\n",
       " (1, (491, 76)): 784,\n",
       " (1, (513, 55)): 785,\n",
       " (1, (520, 55)): 786,\n",
       " (1, (543, 76)): 787,\n",
       " (1, (577, 9)): 788,\n",
       " (1, (577, 67)): 789,\n",
       " (1, (596, 41)): 790,\n",
       " (1, (599, 48)): 791,\n",
       " (1, (604, 48)): 792,\n",
       " (1, (606, 48)): 793,\n",
       " (1, (608, 62)): 794,\n",
       " (1, (625, 41)): 795,\n",
       " (1, (630, 41)): 796,\n",
       " (1, (631, 48)): 797,\n",
       " (1, (634, 48)): 798,\n",
       " (1, (653, 62)): 799,\n",
       " (1, (659, 55)): 800,\n",
       " (1, (664, 62)): 801,\n",
       " (3, (1, 9)): 802,\n",
       " (3, (7, 9)): 803,\n",
       " (3, (11, 3)): 804,\n",
       " (3, (17, 4)): 805,\n",
       " (3, (21, 8)): 806,\n",
       " (3, (22, 5)): 807,\n",
       " (3, (24, 8)): 808,\n",
       " (3, (24, 9)): 809,\n",
       " (3, (25, 2)): 810,\n",
       " (3, (34, 1)): 811,\n",
       " (3, (41, 9)): 812,\n",
       " (3, (47, 5)): 813,\n",
       " (3, (48, 0)): 814,\n",
       " (3, (48, 5)): 815,\n",
       " (3, (53, 2)): 816,\n",
       " (3, (70, 4)): 817,\n",
       " (3, (72, 4)): 818,\n",
       " (3, (76, 0)): 819,\n",
       " (3, (81, 4)): 820,\n",
       " (3, (94, 4)): 821,\n",
       " (1, (42, 76)): 822,\n",
       " (1, (102, 48)): 823,\n",
       " (1, (158, 21)): 824,\n",
       " (1, (185, 62)): 825,\n",
       " (1, (215, 48)): 826,\n",
       " (1, (217, 48)): 827,\n",
       " (1, (235, 48)): 828,\n",
       " (1, (241, 48)): 829,\n",
       " (1, (243, 9)): 830,\n",
       " (1, (272, 55)): 831,\n",
       " (1, (327, 76)): 832,\n",
       " (1, (345, 48)): 833,\n",
       " (1, (375, 76)): 834,\n",
       " (1, (383, 48)): 835,\n",
       " (1, (384, 74)): 836,\n",
       " (1, (384, 76)): 837,\n",
       " (1, (404, 41)): 838,\n",
       " (1, (408, 76)): 839,\n",
       " (1, (411, 48)): 840,\n",
       " (1, (430, 5)): 841,\n",
       " (1, (431, 21)): 842,\n",
       " (1, (456, 62)): 843,\n",
       " (1, (457, 5)): 844,\n",
       " (1, (463, 62)): 845,\n",
       " (1, (466, 90)): 846,\n",
       " (1, (470, 48)): 847,\n",
       " (1, (481, 21)): 848,\n",
       " (1, (483, 9)): 849,\n",
       " (1, (492, 55)): 850,\n",
       " (1, (511, 48)): 851,\n",
       " (1, (513, 21)): 852,\n",
       " (1, (523, 62)): 853,\n",
       " (1, (524, 62)): 854,\n",
       " (1, (541, 41)): 855,\n",
       " (1, (550, 5)): 856,\n",
       " (1, (554, 48)): 857,\n",
       " (1, (568, 9)): 858,\n",
       " (1, (578, 5)): 859,\n",
       " (1, (596, 48)): 860,\n",
       " (1, (601, 76)): 861,\n",
       " (1, (602, 41)): 862,\n",
       " (1, (632, 48)): 863,\n",
       " (1, (636, 62)): 864,\n",
       " (1, (743, 41)): 865,\n",
       " (3, (0, 2)): 866,\n",
       " (3, (8, 3)): 867,\n",
       " (3, (10, 3)): 868,\n",
       " (3, (13, 7)): 869,\n",
       " (3, (21, 1)): 870,\n",
       " (3, (24, 7)): 871,\n",
       " (3, (29, 0)): 872,\n",
       " (3, (31, 2)): 873,\n",
       " (3, (58, 5)): 874,\n",
       " (3, (64, 1)): 875,\n",
       " (3, (72, 2)): 876,\n",
       " (3, (75, 4)): 877,\n",
       " (3, (81, 7)): 878,\n",
       " (1, (43, 62)): 879,\n",
       " (1, (67, 41)): 880,\n",
       " (1, (125, 48)): 881,\n",
       " (1, (153, 41)): 882,\n",
       " (1, (154, 48)): 883,\n",
       " (1, (155, 41)): 884,\n",
       " (1, (179, 48)): 885,\n",
       " (1, (180, 48)): 886,\n",
       " (1, (234, 76)): 887,\n",
       " (1, (243, 21)): 888,\n",
       " (1, (245, 67)): 889,\n",
       " (1, (264, 9)): 890,\n",
       " (1, (267, 62)): 891,\n",
       " (1, (299, 41)): 892,\n",
       " (1, (300, 67)): 893,\n",
       " (1, (322, 41)): 894,\n",
       " (1, (326, 76)): 895,\n",
       " (1, (347, 62)): 896,\n",
       " (1, (358, 62)): 897,\n",
       " (1, (373, 48)): 898,\n",
       " (1, (377, 48)): 899,\n",
       " (1, (380, 76)): 900,\n",
       " (1, (382, 48)): 901,\n",
       " (1, (435, 48)): 902,\n",
       " (1, (436, 5)): 903,\n",
       " (1, (436, 62)): 904,\n",
       " (1, (459, 21)): 905,\n",
       " (1, (463, 55)): 906,\n",
       " (1, (466, 41)): 907,\n",
       " (1, (490, 62)): 908,\n",
       " (1, (490, 67)): 909,\n",
       " (1, (493, 62)): 910,\n",
       " (1, (509, 55)): 911,\n",
       " (1, (512, 9)): 912,\n",
       " (1, (519, 90)): 913,\n",
       " (1, (523, 48)): 914,\n",
       " (1, (525, 55)): 915,\n",
       " (1, (537, 55)): 916,\n",
       " (1, (566, 41)): 917,\n",
       " (1, (569, 5)): 918,\n",
       " (1, (574, 76)): 919,\n",
       " (1, (576, 67)): 920,\n",
       " (1, (577, 5)): 921,\n",
       " (1, (601, 9)): 922,\n",
       " (1, (602, 55)): 923,\n",
       " (1, (602, 76)): 924,\n",
       " (1, (603, 48)): 925,\n",
       " (1, (608, 41)): 926,\n",
       " (1, (609, 62)): 927,\n",
       " (1, (624, 41)): 928,\n",
       " (1, (654, 48)): 929,\n",
       " (1, (713, 62)): 930,\n",
       " (3, (0, 8)): 931,\n",
       " (3, (3, 4)): 932,\n",
       " (3, (4, 4)): 933,\n",
       " (3, (4, 6)): 934,\n",
       " (3, (4, 8)): 935,\n",
       " (3, (22, 0)): 936,\n",
       " (3, (25, 3)): 937,\n",
       " (3, (44, 1)): 938,\n",
       " (3, (52, 3)): 939,\n",
       " (3, (55, 7)): 940,\n",
       " (3, (58, 7)): 941,\n",
       " (3, (63, 8)): 942,\n",
       " (3, (64, 5)): 943,\n",
       " (3, (73, 5)): 944,\n",
       " (3, (80, 7)): 945,\n",
       " (3, (90, 2)): 946,\n",
       " (3, (92, 2)): 947,\n",
       " (3, (94, 8)): 948,\n",
       " (3, (98, 0)): 949,\n",
       " (1, (40, 41)): 950,\n",
       " (1, (131, 9)): 951,\n",
       " (1, (182, 48)): 952,\n",
       " (1, (187, 48)): 953,\n",
       " (1, (188, 76)): 954,\n",
       " (1, (205, 48)): 955,\n",
       " (1, (212, 55)): 956,\n",
       " (1, (231, 67)): 957,\n",
       " (1, (237, 48)): 958,\n",
       " (1, (241, 55)): 959,\n",
       " (1, (242, 76)): 960,\n",
       " (1, (271, 67)): 961,\n",
       " (1, (274, 5)): 962,\n",
       " (1, (291, 48)): 963,\n",
       " (1, (295, 67)): 964,\n",
       " (1, (300, 41)): 965,\n",
       " (1, (301, 9)): 966,\n",
       " (1, (327, 48)): 967,\n",
       " (1, (328, 76)): 968,\n",
       " (1, (330, 62)): 969,\n",
       " (1, (348, 48)): 970,\n",
       " (1, (350, 76)): 971,\n",
       " (1, (352, 48)): 972,\n",
       " (1, (373, 67)): 973,\n",
       " (1, (374, 41)): 974,\n",
       " (1, (386, 5)): 975,\n",
       " (1, (387, 5)): 976,\n",
       " (1, (403, 76)): 977,\n",
       " (1, (409, 48)): 978,\n",
       " (1, (414, 48)): 979,\n",
       " (1, (432, 55)): 980,\n",
       " (1, (438, 9)): 981,\n",
       " (1, (438, 90)): 982,\n",
       " (1, (455, 62)): 983,\n",
       " (1, (457, 76)): 984,\n",
       " (1, (459, 67)): 985,\n",
       " (1, (466, 67)): 986,\n",
       " (1, (482, 5)): 987,\n",
       " (1, (497, 55)): 988,\n",
       " (1, (510, 9)): 989,\n",
       " (1, (512, 41)): 990,\n",
       " (1, (518, 90)): 991,\n",
       " (1, (519, 62)): 992,\n",
       " (1, (520, 9)): 993,\n",
       " (1, (524, 41)): 994,\n",
       " (1, (547, 5)): 995,\n",
       " (1, (573, 76)): 996,\n",
       " (1, (578, 55)): 997,\n",
       " (1, (580, 67)): 998,\n",
       " (1, (594, 9)): 999,\n",
       " (1, (597, 5)): 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "loc_file = \"results/rq1/all_layers/simple_fm/random/loc.all_cost.loc.0.1.random.pkl\"\n",
    "loc_which = 'random'\n",
    "target_weights = fm_target_layes\n",
    "\n",
    "pairs_rd = get_weight_and_cost(loc_which, seed, loc_file, target_weights, method = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, (393, 24)): 1,\n",
       " (1, (542, 78)): 2,\n",
       " (1, (74, 83)): 3,\n",
       " (1, (614, 36)): 4,\n",
       " (1, (596, 47)): 5,\n",
       " (1, (375, 46)): 6,\n",
       " (1, (628, 72)): 7,\n",
       " (1, (586, 58)): 8,\n",
       " (1, (580, 92)): 9,\n",
       " (1, (311, 14)): 10,\n",
       " (1, (348, 85)): 11,\n",
       " (1, (395, 62)): 12,\n",
       " (1, (150, 11)): 13,\n",
       " (1, (578, 30)): 14,\n",
       " (1, (237, 3)): 15,\n",
       " (1, (173, 27)): 16,\n",
       " (1, (699, 8)): 17,\n",
       " (1, (542, 5)): 18,\n",
       " (1, (431, 54)): 19,\n",
       " (1, (306, 10)): 20,\n",
       " (1, (287, 37)): 21,\n",
       " (1, (264, 7)): 22,\n",
       " (1, (430, 58)): 23,\n",
       " (1, (506, 78)): 24,\n",
       " (1, (7, 66)): 25,\n",
       " (1, (240, 32)): 26,\n",
       " (1, (588, 61)): 27,\n",
       " (1, (405, 47)): 28,\n",
       " (1, (740, 91)): 29,\n",
       " (1, (666, 86)): 30,\n",
       " (1, (92, 11)): 31,\n",
       " (1, (536, 61)): 32,\n",
       " (1, (72, 13)): 33,\n",
       " (1, (65, 69)): 34,\n",
       " (1, (496, 25)): 35,\n",
       " (1, (176, 3)): 36,\n",
       " (1, (551, 35)): 37,\n",
       " (1, (624, 52)): 38,\n",
       " (1, (244, 10)): 39,\n",
       " (1, (167, 37)): 40,\n",
       " (1, (508, 56)): 41,\n",
       " (1, (439, 55)): 42,\n",
       " (1, (742, 9)): 43,\n",
       " (1, (488, 66)): 44,\n",
       " (1, (708, 31)): 45,\n",
       " (1, (210, 4)): 46,\n",
       " (1, (51, 60)): 47,\n",
       " (1, (610, 28)): 48,\n",
       " (1, (174, 21)): 49,\n",
       " (1, (125, 59)): 50,\n",
       " (1, (476, 95)): 51,\n",
       " (1, (407, 94)): 52,\n",
       " (1, (185, 91)): 53,\n",
       " (1, (481, 47)): 54,\n",
       " (1, (544, 60)): 55,\n",
       " (1, (107, 35)): 56,\n",
       " (1, (604, 90)): 57,\n",
       " (3, (55, 1)): 58,\n",
       " (1, (707, 25)): 59,\n",
       " (1, (71, 39)): 60,\n",
       " (1, (16, 20)): 61,\n",
       " (1, (749, 79)): 62,\n",
       " (1, (574, 9)): 63,\n",
       " (1, (448, 44)): 64,\n",
       " (1, (562, 66)): 65,\n",
       " (1, (367, 44)): 66,\n",
       " (1, (570, 41)): 67,\n",
       " (1, (180, 38)): 68,\n",
       " (1, (673, 6)): 69,\n",
       " (1, (123, 26)): 70,\n",
       " (1, (341, 49)): 71,\n",
       " (1, (726, 68)): 72,\n",
       " (1, (28, 49)): 73,\n",
       " (1, (402, 38)): 74,\n",
       " (1, (258, 3)): 75,\n",
       " (1, (85, 82)): 76,\n",
       " (1, (305, 59)): 77,\n",
       " (1, (596, 41)): 78,\n",
       " (1, (363, 9)): 79,\n",
       " (1, (453, 97)): 80,\n",
       " (1, (95, 99)): 81,\n",
       " (1, (571, 55)): 82,\n",
       " (1, (483, 42)): 83,\n",
       " (1, (414, 10)): 84,\n",
       " (1, (172, 61)): 85,\n",
       " (1, (544, 48)): 86,\n",
       " (1, (548, 35)): 87,\n",
       " (1, (424, 60)): 88,\n",
       " (1, (47, 12)): 89,\n",
       " (1, (375, 16)): 90,\n",
       " (1, (734, 97)): 91,\n",
       " (1, (633, 45)): 92,\n",
       " (1, (175, 69)): 93,\n",
       " (1, (537, 26)): 94,\n",
       " (1, (300, 46)): 95,\n",
       " (1, (14, 6)): 96,\n",
       " (1, (159, 99)): 97,\n",
       " (1, (667, 5)): 98,\n",
       " (1, (487, 48)): 99,\n",
       " (1, (195, 48)): 100,\n",
       " (1, (268, 31)): 101,\n",
       " (1, (254, 21)): 102,\n",
       " (1, (367, 40)): 103,\n",
       " (1, (232, 60)): 104,\n",
       " (1, (364, 81)): 105,\n",
       " (1, (661, 35)): 106,\n",
       " (1, (4, 15)): 107,\n",
       " (1, (471, 90)): 108,\n",
       " (1, (738, 7)): 109,\n",
       " (1, (629, 90)): 110,\n",
       " (1, (137, 54)): 111,\n",
       " (1, (139, 99)): 112,\n",
       " (1, (431, 40)): 113,\n",
       " (1, (597, 50)): 114,\n",
       " (1, (219, 76)): 115,\n",
       " (1, (269, 44)): 116,\n",
       " (1, (620, 51)): 117,\n",
       " (1, (543, 5)): 118,\n",
       " (1, (292, 34)): 119,\n",
       " (1, (209, 2)): 120,\n",
       " (1, (187, 14)): 121,\n",
       " (1, (460, 32)): 122,\n",
       " (1, (575, 44)): 123,\n",
       " (1, (548, 91)): 124,\n",
       " (1, (527, 5)): 125,\n",
       " (1, (636, 66)): 126,\n",
       " (1, (149, 48)): 127,\n",
       " (1, (321, 4)): 128,\n",
       " (1, (389, 85)): 129,\n",
       " (1, (338, 43)): 130,\n",
       " (1, (132, 10)): 131,\n",
       " (1, (522, 51)): 132,\n",
       " (1, (408, 13)): 133,\n",
       " (1, (236, 25)): 134,\n",
       " (1, (8, 94)): 135,\n",
       " (1, (744, 78)): 136,\n",
       " (1, (383, 92)): 137,\n",
       " (1, (114, 36)): 138,\n",
       " (1, (622, 18)): 139,\n",
       " (1, (50, 67)): 140,\n",
       " (1, (720, 16)): 141,\n",
       " (1, (249, 62)): 142,\n",
       " (1, (651, 85)): 143,\n",
       " (1, (484, 42)): 144,\n",
       " (1, (443, 26)): 145,\n",
       " (1, (234, 2)): 146,\n",
       " (1, (599, 48)): 147,\n",
       " (1, (507, 16)): 148,\n",
       " (1, (274, 40)): 149,\n",
       " (1, (31, 76)): 150,\n",
       " (1, (585, 71)): 151,\n",
       " (1, (461, 78)): 152,\n",
       " (1, (434, 61)): 153,\n",
       " (1, (645, 58)): 154,\n",
       " (1, (318, 57)): 155,\n",
       " (1, (29, 32)): 156,\n",
       " (1, (303, 91)): 157,\n",
       " (1, (511, 67)): 158,\n",
       " (1, (600, 79)): 159,\n",
       " (1, (289, 23)): 160,\n",
       " (1, (418, 47)): 161,\n",
       " (1, (176, 49)): 162,\n",
       " (1, (317, 96)): 163,\n",
       " (1, (722, 69)): 164,\n",
       " (1, (527, 72)): 165,\n",
       " (1, (88, 46)): 166,\n",
       " (1, (458, 35)): 167,\n",
       " (1, (558, 11)): 168,\n",
       " (1, (453, 46)): 169,\n",
       " (1, (495, 79)): 170,\n",
       " (1, (572, 29)): 171,\n",
       " (1, (658, 9)): 172,\n",
       " (1, (59, 76)): 173,\n",
       " (1, (493, 5)): 174,\n",
       " (1, (181, 20)): 175,\n",
       " (1, (709, 96)): 176,\n",
       " (1, (742, 72)): 177,\n",
       " (1, (68, 8)): 178,\n",
       " (1, (540, 37)): 179,\n",
       " (1, (521, 68)): 180,\n",
       " (1, (276, 83)): 181,\n",
       " (1, (704, 80)): 182,\n",
       " (1, (115, 3)): 183,\n",
       " (1, (357, 5)): 184,\n",
       " (1, (29, 54)): 185,\n",
       " (1, (152, 34)): 186,\n",
       " (1, (687, 88)): 187,\n",
       " (1, (702, 85)): 188,\n",
       " (1, (266, 4)): 189,\n",
       " (1, (170, 91)): 190,\n",
       " (1, (779, 87)): 191,\n",
       " (1, (317, 4)): 192,\n",
       " (1, (255, 17)): 193,\n",
       " (1, (65, 87)): 194,\n",
       " (1, (386, 82)): 195,\n",
       " (1, (549, 22)): 196,\n",
       " (1, (116, 64)): 197,\n",
       " (1, (248, 47)): 198,\n",
       " (1, (761, 34)): 199,\n",
       " (1, (179, 10)): 200,\n",
       " (1, (23, 74)): 201,\n",
       " (1, (223, 88)): 202,\n",
       " (1, (225, 11)): 203,\n",
       " (1, (271, 44)): 204,\n",
       " (1, (544, 24)): 205,\n",
       " (1, (451, 68)): 206,\n",
       " (1, (675, 24)): 207,\n",
       " (1, (173, 14)): 208,\n",
       " (1, (29, 14)): 209,\n",
       " (1, (248, 25)): 210,\n",
       " (1, (599, 38)): 211,\n",
       " (1, (237, 88)): 212,\n",
       " (1, (678, 90)): 213,\n",
       " (1, (377, 41)): 214,\n",
       " (1, (507, 61)): 215,\n",
       " (1, (329, 84)): 216,\n",
       " (3, (80, 1)): 217,\n",
       " (1, (549, 43)): 218,\n",
       " (1, (190, 43)): 219,\n",
       " (1, (718, 1)): 220,\n",
       " (1, (720, 43)): 221,\n",
       " (1, (361, 10)): 222,\n",
       " (1, (435, 81)): 223,\n",
       " (1, (469, 40)): 224,\n",
       " (1, (418, 75)): 225,\n",
       " (1, (393, 23)): 226,\n",
       " (1, (130, 19)): 227,\n",
       " (1, (399, 28)): 228,\n",
       " (1, (593, 32)): 229,\n",
       " (1, (303, 98)): 230,\n",
       " (1, (119, 75)): 231,\n",
       " (1, (255, 84)): 232,\n",
       " (1, (69, 94)): 233,\n",
       " (1, (252, 73)): 234,\n",
       " (1, (425, 87)): 235,\n",
       " (1, (530, 56)): 236,\n",
       " (1, (530, 0)): 237,\n",
       " (1, (41, 52)): 238,\n",
       " (1, (663, 19)): 239,\n",
       " (1, (636, 38)): 240,\n",
       " (1, (519, 8)): 241,\n",
       " (1, (483, 15)): 242,\n",
       " (1, (781, 57)): 243,\n",
       " (1, (653, 44)): 244,\n",
       " (1, (465, 12)): 245,\n",
       " (1, (572, 33)): 246,\n",
       " (1, (554, 70)): 247,\n",
       " (1, (362, 95)): 248,\n",
       " (1, (774, 44)): 249,\n",
       " (3, (25, 0)): 250,\n",
       " (1, (16, 0)): 251,\n",
       " (1, (198, 96)): 252,\n",
       " (1, (197, 24)): 253,\n",
       " (1, (207, 73)): 254,\n",
       " (1, (676, 77)): 255,\n",
       " (1, (384, 12)): 256,\n",
       " (1, (167, 63)): 257,\n",
       " (1, (712, 83)): 258,\n",
       " (1, (628, 83)): 259,\n",
       " (1, (339, 99)): 260,\n",
       " (1, (278, 16)): 261,\n",
       " (1, (578, 2)): 262,\n",
       " (1, (594, 94)): 263,\n",
       " (1, (752, 61)): 264,\n",
       " (1, (242, 55)): 265,\n",
       " (1, (477, 52)): 266,\n",
       " (1, (438, 40)): 267,\n",
       " (1, (578, 40)): 268,\n",
       " (1, (551, 18)): 269,\n",
       " (1, (388, 58)): 270,\n",
       " (1, (179, 66)): 271,\n",
       " (1, (336, 86)): 272,\n",
       " (1, (370, 21)): 273,\n",
       " (1, (475, 27)): 274,\n",
       " (1, (731, 66)): 275,\n",
       " (1, (698, 94)): 276,\n",
       " (1, (390, 43)): 277,\n",
       " (1, (464, 81)): 278,\n",
       " (1, (196, 76)): 279,\n",
       " (1, (167, 66)): 280,\n",
       " (1, (587, 51)): 281,\n",
       " (1, (202, 24)): 282,\n",
       " (1, (51, 42)): 283,\n",
       " (1, (733, 4)): 284,\n",
       " (1, (461, 47)): 285,\n",
       " (1, (268, 49)): 286,\n",
       " (1, (242, 14)): 287,\n",
       " (1, (728, 19)): 288,\n",
       " (1, (350, 25)): 289,\n",
       " (1, (578, 86)): 290,\n",
       " (1, (414, 45)): 291,\n",
       " (1, (199, 40)): 292,\n",
       " (1, (600, 99)): 293,\n",
       " (1, (416, 18)): 294,\n",
       " (1, (63, 58)): 295,\n",
       " (1, (223, 64)): 296,\n",
       " (1, (286, 72)): 297,\n",
       " (1, (782, 61)): 298,\n",
       " (1, (355, 37)): 299,\n",
       " (1, (303, 23)): 300,\n",
       " (1, (541, 95)): 301,\n",
       " (1, (504, 49)): 302,\n",
       " (1, (412, 34)): 303,\n",
       " (1, (458, 40)): 304,\n",
       " (1, (590, 76)): 305,\n",
       " (1, (275, 99)): 306,\n",
       " (1, (581, 87)): 307,\n",
       " (1, (76, 54)): 308,\n",
       " (1, (61, 38)): 309,\n",
       " (1, (443, 33)): 310,\n",
       " (1, (136, 13)): 311,\n",
       " (1, (188, 1)): 312,\n",
       " (1, (452, 80)): 313,\n",
       " (1, (469, 87)): 314,\n",
       " (1, (70, 28)): 315,\n",
       " (1, (18, 99)): 316,\n",
       " (1, (357, 66)): 317,\n",
       " (1, (683, 92)): 318,\n",
       " (1, (506, 25)): 319,\n",
       " (1, (707, 73)): 320,\n",
       " (3, (12, 4)): 321,\n",
       " (1, (58, 85)): 322,\n",
       " (1, (660, 80)): 323,\n",
       " (1, (518, 93)): 324,\n",
       " (1, (392, 91)): 325,\n",
       " (1, (11, 8)): 326,\n",
       " (1, (18, 81)): 327,\n",
       " (1, (768, 61)): 328,\n",
       " (1, (194, 1)): 329,\n",
       " (1, (723, 67)): 330,\n",
       " (1, (28, 20)): 331,\n",
       " (1, (264, 36)): 332,\n",
       " (1, (1, 16)): 333,\n",
       " (1, (357, 81)): 334,\n",
       " (1, (192, 13)): 335,\n",
       " (1, (661, 58)): 336,\n",
       " (1, (615, 21)): 337,\n",
       " (1, (750, 46)): 338,\n",
       " (1, (667, 61)): 339,\n",
       " (1, (322, 54)): 340,\n",
       " (1, (173, 51)): 341,\n",
       " (1, (529, 3)): 342,\n",
       " (1, (236, 4)): 343,\n",
       " (1, (402, 25)): 344,\n",
       " (1, (181, 84)): 345,\n",
       " (1, (471, 75)): 346,\n",
       " (1, (212, 17)): 347,\n",
       " (1, (164, 22)): 348,\n",
       " (1, (605, 82)): 349,\n",
       " (1, (404, 64)): 350,\n",
       " (1, (283, 85)): 351,\n",
       " (1, (350, 2)): 352,\n",
       " (1, (427, 92)): 353,\n",
       " (1, (588, 29)): 354,\n",
       " (1, (260, 42)): 355,\n",
       " (1, (598, 91)): 356,\n",
       " (1, (776, 31)): 357,\n",
       " (1, (598, 82)): 358,\n",
       " (1, (240, 80)): 359,\n",
       " (1, (765, 79)): 360,\n",
       " (1, (472, 56)): 361,\n",
       " (1, (100, 86)): 362,\n",
       " (1, (242, 58)): 363,\n",
       " (1, (394, 82)): 364,\n",
       " (1, (46, 93)): 365,\n",
       " (1, (726, 54)): 366,\n",
       " (1, (533, 75)): 367,\n",
       " (1, (79, 76)): 368,\n",
       " (1, (705, 87)): 369,\n",
       " (1, (29, 13)): 370,\n",
       " (1, (40, 99)): 371,\n",
       " (1, (442, 84)): 372,\n",
       " (1, (544, 39)): 373,\n",
       " (1, (735, 92)): 374,\n",
       " (1, (146, 94)): 375,\n",
       " (1, (749, 83)): 376,\n",
       " (1, (503, 80)): 377,\n",
       " (1, (299, 77)): 378,\n",
       " (3, (98, 0)): 379,\n",
       " (1, (729, 50)): 380,\n",
       " (1, (47, 27)): 381,\n",
       " (1, (578, 13)): 382,\n",
       " (1, (755, 8)): 383,\n",
       " (1, (315, 84)): 384,\n",
       " (1, (337, 57)): 385,\n",
       " (1, (636, 85)): 386,\n",
       " (1, (216, 15)): 387,\n",
       " (1, (654, 52)): 388,\n",
       " (1, (511, 63)): 389,\n",
       " (1, (238, 69)): 390,\n",
       " (1, (481, 79)): 391,\n",
       " (1, (439, 70)): 392,\n",
       " (1, (449, 22)): 393,\n",
       " (1, (388, 43)): 394,\n",
       " (1, (308, 56)): 395,\n",
       " (1, (328, 75)): 396,\n",
       " (1, (212, 40)): 397,\n",
       " (1, (117, 90)): 398,\n",
       " (1, (78, 45)): 399,\n",
       " (1, (233, 35)): 400,\n",
       " (1, (260, 88)): 401,\n",
       " (1, (435, 26)): 402,\n",
       " (1, (502, 81)): 403,\n",
       " (1, (67, 41)): 404,\n",
       " (1, (345, 4)): 405,\n",
       " (1, (295, 24)): 406,\n",
       " (1, (120, 36)): 407,\n",
       " (1, (642, 10)): 408,\n",
       " (1, (6, 58)): 409,\n",
       " (1, (279, 9)): 410,\n",
       " (3, (21, 7)): 411,\n",
       " (1, (415, 46)): 412,\n",
       " (1, (586, 4)): 413,\n",
       " (1, (593, 25)): 414,\n",
       " (1, (94, 55)): 415,\n",
       " (1, (721, 17)): 416,\n",
       " (1, (131, 56)): 417,\n",
       " (1, (271, 17)): 418,\n",
       " (1, (410, 99)): 419,\n",
       " (1, (254, 67)): 420,\n",
       " (1, (536, 19)): 421,\n",
       " (3, (96, 6)): 422,\n",
       " (1, (288, 50)): 423,\n",
       " (1, (636, 93)): 424,\n",
       " (1, (496, 17)): 425,\n",
       " (1, (3, 79)): 426,\n",
       " (1, (97, 94)): 427,\n",
       " (1, (62, 32)): 428,\n",
       " (1, (619, 19)): 429,\n",
       " (1, (693, 93)): 430,\n",
       " (1, (426, 32)): 431,\n",
       " (1, (259, 99)): 432,\n",
       " (1, (400, 73)): 433,\n",
       " (1, (59, 19)): 434,\n",
       " (1, (155, 95)): 435,\n",
       " (1, (750, 23)): 436,\n",
       " (1, (24, 65)): 437,\n",
       " (1, (382, 15)): 438,\n",
       " (1, (263, 14)): 439,\n",
       " (1, (727, 24)): 440,\n",
       " (1, (497, 0)): 441,\n",
       " (1, (691, 27)): 442,\n",
       " (1, (424, 7)): 443,\n",
       " (1, (39, 60)): 444,\n",
       " (1, (123, 24)): 445,\n",
       " (1, (640, 11)): 446,\n",
       " (1, (655, 2)): 447,\n",
       " (1, (393, 43)): 448,\n",
       " (1, (735, 69)): 449,\n",
       " (1, (693, 52)): 450,\n",
       " (1, (311, 41)): 451,\n",
       " (1, (448, 80)): 452,\n",
       " (1, (687, 37)): 453,\n",
       " (1, (123, 95)): 454,\n",
       " (1, (188, 29)): 455,\n",
       " (1, (629, 39)): 456,\n",
       " (1, (613, 77)): 457,\n",
       " (1, (125, 9)): 458,\n",
       " (1, (416, 89)): 459,\n",
       " (1, (575, 20)): 460,\n",
       " (1, (770, 52)): 461,\n",
       " (1, (321, 61)): 462,\n",
       " (1, (557, 74)): 463,\n",
       " (1, (686, 4)): 464,\n",
       " (1, (635, 81)): 465,\n",
       " (1, (135, 61)): 466,\n",
       " (1, (652, 49)): 467,\n",
       " (1, (136, 91)): 468,\n",
       " (1, (0, 5)): 469,\n",
       " (1, (457, 41)): 470,\n",
       " (1, (650, 98)): 471,\n",
       " (1, (496, 84)): 472,\n",
       " (1, (657, 69)): 473,\n",
       " (1, (420, 66)): 474,\n",
       " (1, (78, 92)): 475,\n",
       " (1, (730, 77)): 476,\n",
       " (1, (361, 22)): 477,\n",
       " (1, (226, 58)): 478,\n",
       " (1, (255, 45)): 479,\n",
       " (1, (713, 42)): 480,\n",
       " (1, (645, 19)): 481,\n",
       " (1, (376, 23)): 482,\n",
       " (1, (508, 5)): 483,\n",
       " (1, (600, 27)): 484,\n",
       " (1, (679, 89)): 485,\n",
       " (1, (116, 39)): 486,\n",
       " (1, (17, 6)): 487,\n",
       " (1, (360, 59)): 488,\n",
       " (1, (98, 44)): 489,\n",
       " (1, (5, 19)): 490,\n",
       " (1, (755, 87)): 491,\n",
       " (1, (214, 34)): 492,\n",
       " (1, (453, 42)): 493,\n",
       " (1, (725, 40)): 494,\n",
       " (1, (679, 83)): 495,\n",
       " (1, (50, 62)): 496,\n",
       " (1, (11, 75)): 497,\n",
       " (1, (682, 76)): 498,\n",
       " (1, (277, 99)): 499,\n",
       " (1, (763, 56)): 500,\n",
       " (1, (556, 53)): 501,\n",
       " (1, (659, 44)): 502,\n",
       " (1, (378, 3)): 503,\n",
       " (1, (747, 57)): 504,\n",
       " (1, (53, 81)): 505,\n",
       " (1, (437, 34)): 506,\n",
       " (1, (596, 85)): 507,\n",
       " (1, (745, 17)): 508,\n",
       " (1, (728, 23)): 509,\n",
       " (1, (106, 25)): 510,\n",
       " (1, (166, 12)): 511,\n",
       " (1, (695, 56)): 512,\n",
       " (1, (8, 73)): 513,\n",
       " (1, (251, 27)): 514,\n",
       " (1, (255, 25)): 515,\n",
       " (1, (256, 96)): 516,\n",
       " (1, (459, 3)): 517,\n",
       " (1, (682, 72)): 518,\n",
       " (1, (344, 0)): 519,\n",
       " (1, (186, 16)): 520,\n",
       " (1, (411, 91)): 521,\n",
       " (1, (40, 86)): 522,\n",
       " (1, (211, 72)): 523,\n",
       " (1, (270, 37)): 524,\n",
       " (1, (676, 1)): 525,\n",
       " (1, (390, 21)): 526,\n",
       " (1, (296, 45)): 527,\n",
       " (1, (704, 1)): 528,\n",
       " (1, (504, 0)): 529,\n",
       " (1, (739, 30)): 530,\n",
       " (1, (277, 9)): 531,\n",
       " (1, (299, 79)): 532,\n",
       " (1, (309, 64)): 533,\n",
       " (1, (188, 72)): 534,\n",
       " (1, (211, 42)): 535,\n",
       " (1, (517, 70)): 536,\n",
       " (1, (273, 46)): 537,\n",
       " (1, (622, 67)): 538,\n",
       " (1, (149, 89)): 539,\n",
       " (1, (137, 52)): 540,\n",
       " (1, (473, 14)): 541,\n",
       " (3, (95, 3)): 542,\n",
       " (1, (774, 42)): 543,\n",
       " (1, (329, 63)): 544,\n",
       " (1, (675, 41)): 545,\n",
       " (1, (341, 55)): 546,\n",
       " (1, (329, 79)): 547,\n",
       " (1, (154, 68)): 548,\n",
       " (1, (11, 43)): 549,\n",
       " (1, (346, 81)): 550,\n",
       " (1, (359, 11)): 551,\n",
       " (1, (579, 77)): 552,\n",
       " (1, (694, 25)): 553,\n",
       " (1, (564, 11)): 554,\n",
       " (1, (273, 0)): 555,\n",
       " (1, (152, 7)): 556,\n",
       " (1, (777, 59)): 557,\n",
       " (1, (211, 54)): 558,\n",
       " (1, (341, 9)): 559,\n",
       " (1, (518, 12)): 560,\n",
       " (1, (415, 99)): 561,\n",
       " (1, (672, 13)): 562,\n",
       " (1, (368, 23)): 563,\n",
       " (1, (754, 76)): 564,\n",
       " (1, (549, 31)): 565,\n",
       " (1, (458, 69)): 566,\n",
       " (1, (87, 1)): 567,\n",
       " (1, (300, 51)): 568,\n",
       " (1, (216, 56)): 569,\n",
       " (1, (681, 28)): 570,\n",
       " (1, (745, 67)): 571,\n",
       " (1, (496, 72)): 572,\n",
       " (1, (75, 94)): 573,\n",
       " (1, (361, 41)): 574,\n",
       " (1, (174, 9)): 575,\n",
       " (1, (660, 5)): 576,\n",
       " (1, (385, 88)): 577,\n",
       " (1, (439, 39)): 578,\n",
       " (1, (367, 7)): 579,\n",
       " (1, (198, 48)): 580,\n",
       " (1, (70, 70)): 581,\n",
       " (1, (668, 60)): 582,\n",
       " (1, (395, 96)): 583,\n",
       " (1, (5, 51)): 584,\n",
       " (1, (783, 28)): 585,\n",
       " (1, (582, 19)): 586,\n",
       " (1, (479, 90)): 587,\n",
       " (1, (168, 18)): 588,\n",
       " (1, (12, 95)): 589,\n",
       " (1, (697, 56)): 590,\n",
       " (1, (742, 43)): 591,\n",
       " (1, (430, 94)): 592,\n",
       " (1, (432, 72)): 593,\n",
       " (1, (612, 4)): 594,\n",
       " (1, (677, 61)): 595,\n",
       " (1, (296, 28)): 596,\n",
       " (1, (164, 34)): 597,\n",
       " (1, (551, 48)): 598,\n",
       " (1, (164, 12)): 599,\n",
       " (1, (594, 15)): 600,\n",
       " (1, (28, 18)): 601,\n",
       " (1, (348, 77)): 602,\n",
       " (1, (582, 68)): 603,\n",
       " (1, (55, 91)): 604,\n",
       " (1, (234, 11)): 605,\n",
       " (1, (517, 91)): 606,\n",
       " (1, (616, 21)): 607,\n",
       " (1, (621, 74)): 608,\n",
       " (1, (603, 99)): 609,\n",
       " (1, (309, 44)): 610,\n",
       " (1, (11, 77)): 611,\n",
       " (1, (453, 12)): 612,\n",
       " (1, (531, 24)): 613,\n",
       " (1, (580, 45)): 614,\n",
       " (1, (177, 45)): 615,\n",
       " (1, (447, 27)): 616,\n",
       " (1, (371, 9)): 617,\n",
       " (1, (159, 94)): 618,\n",
       " (1, (369, 58)): 619,\n",
       " (1, (109, 30)): 620,\n",
       " (1, (200, 93)): 621,\n",
       " (1, (612, 50)): 622,\n",
       " (1, (186, 43)): 623,\n",
       " (1, (562, 63)): 624,\n",
       " (1, (382, 27)): 625,\n",
       " (1, (88, 72)): 626,\n",
       " (1, (286, 70)): 627,\n",
       " (1, (549, 72)): 628,\n",
       " (1, (469, 97)): 629,\n",
       " (1, (630, 91)): 630,\n",
       " (1, (84, 66)): 631,\n",
       " (1, (235, 52)): 632,\n",
       " (1, (634, 44)): 633,\n",
       " (1, (713, 32)): 634,\n",
       " (1, (664, 25)): 635,\n",
       " (1, (671, 39)): 636,\n",
       " (1, (141, 15)): 637,\n",
       " (1, (412, 43)): 638,\n",
       " (1, (205, 5)): 639,\n",
       " (1, (28, 25)): 640,\n",
       " (1, (572, 96)): 641,\n",
       " (1, (705, 52)): 642,\n",
       " (1, (296, 99)): 643,\n",
       " (1, (40, 88)): 644,\n",
       " (1, (751, 70)): 645,\n",
       " (1, (17, 13)): 646,\n",
       " (1, (651, 75)): 647,\n",
       " (1, (103, 60)): 648,\n",
       " (1, (326, 21)): 649,\n",
       " (1, (718, 56)): 650,\n",
       " (1, (716, 29)): 651,\n",
       " (1, (713, 64)): 652,\n",
       " (1, (693, 66)): 653,\n",
       " (1, (288, 41)): 654,\n",
       " (1, (704, 69)): 655,\n",
       " (1, (173, 0)): 656,\n",
       " (1, (288, 83)): 657,\n",
       " (1, (576, 14)): 658,\n",
       " (1, (749, 25)): 659,\n",
       " (1, (327, 68)): 660,\n",
       " (1, (624, 32)): 661,\n",
       " (3, (98, 2)): 662,\n",
       " (1, (296, 88)): 663,\n",
       " (1, (683, 27)): 664,\n",
       " (1, (513, 81)): 665,\n",
       " (1, (581, 92)): 666,\n",
       " (1, (111, 69)): 667,\n",
       " (1, (521, 77)): 668,\n",
       " (1, (359, 97)): 669,\n",
       " (1, (305, 79)): 670,\n",
       " (1, (7, 8)): 671,\n",
       " (1, (175, 49)): 672,\n",
       " (1, (408, 90)): 673,\n",
       " (1, (310, 56)): 674,\n",
       " (1, (195, 12)): 675,\n",
       " (1, (443, 69)): 676,\n",
       " (1, (526, 76)): 677,\n",
       " (1, (263, 76)): 678,\n",
       " (1, (39, 26)): 679,\n",
       " (1, (9, 76)): 680,\n",
       " (1, (328, 37)): 681,\n",
       " (1, (443, 99)): 682,\n",
       " (1, (710, 82)): 683,\n",
       " (1, (493, 41)): 684,\n",
       " (1, (724, 85)): 685,\n",
       " (1, (188, 27)): 686,\n",
       " (1, (346, 89)): 687,\n",
       " (1, (537, 75)): 688,\n",
       " (1, (324, 6)): 689,\n",
       " (1, (361, 71)): 690,\n",
       " (1, (241, 29)): 691,\n",
       " (1, (93, 16)): 692,\n",
       " (1, (350, 27)): 693,\n",
       " (1, (721, 58)): 694,\n",
       " (1, (130, 58)): 695,\n",
       " (1, (304, 34)): 696,\n",
       " (1, (88, 82)): 697,\n",
       " (1, (605, 83)): 698,\n",
       " (1, (458, 93)): 699,\n",
       " (1, (290, 80)): 700,\n",
       " (1, (356, 39)): 701,\n",
       " (1, (82, 40)): 702,\n",
       " (1, (488, 67)): 703,\n",
       " (1, (496, 38)): 704,\n",
       " (1, (259, 23)): 705,\n",
       " (1, (727, 25)): 706,\n",
       " (1, (79, 77)): 707,\n",
       " (3, (80, 9)): 708,\n",
       " (1, (442, 7)): 709,\n",
       " (1, (253, 40)): 710,\n",
       " (1, (438, 47)): 711,\n",
       " (1, (590, 13)): 712,\n",
       " (1, (243, 63)): 713,\n",
       " (1, (388, 64)): 714,\n",
       " (1, (307, 88)): 715,\n",
       " (1, (776, 63)): 716,\n",
       " (3, (16, 0)): 717,\n",
       " (1, (54, 54)): 718,\n",
       " (1, (659, 55)): 719,\n",
       " (1, (304, 29)): 720,\n",
       " (1, (130, 10)): 721,\n",
       " (1, (260, 25)): 722,\n",
       " (1, (559, 28)): 723,\n",
       " (1, (343, 65)): 724,\n",
       " (1, (238, 95)): 725,\n",
       " (1, (71, 26)): 726,\n",
       " (1, (723, 10)): 727,\n",
       " (1, (454, 56)): 728,\n",
       " (1, (384, 34)): 729,\n",
       " (1, (61, 1)): 730,\n",
       " (1, (553, 44)): 731,\n",
       " (1, (560, 24)): 732,\n",
       " (1, (416, 8)): 733,\n",
       " (1, (665, 4)): 734,\n",
       " (1, (198, 90)): 735,\n",
       " (1, (110, 67)): 736,\n",
       " (1, (604, 99)): 737,\n",
       " (1, (119, 12)): 738,\n",
       " (1, (206, 9)): 739,\n",
       " (1, (264, 17)): 740,\n",
       " (1, (115, 89)): 741,\n",
       " (1, (339, 82)): 742,\n",
       " (1, (364, 18)): 743,\n",
       " (1, (399, 71)): 744,\n",
       " (1, (273, 33)): 745,\n",
       " (1, (180, 71)): 746,\n",
       " (1, (6, 59)): 747,\n",
       " (1, (583, 44)): 748,\n",
       " (1, (254, 56)): 749,\n",
       " (1, (482, 91)): 750,\n",
       " (1, (623, 20)): 751,\n",
       " (1, (387, 31)): 752,\n",
       " (1, (600, 97)): 753,\n",
       " (1, (190, 61)): 754,\n",
       " (1, (596, 3)): 755,\n",
       " (1, (44, 6)): 756,\n",
       " (3, (9, 1)): 757,\n",
       " (1, (227, 41)): 758,\n",
       " (1, (7, 20)): 759,\n",
       " (1, (154, 67)): 760,\n",
       " (1, (195, 82)): 761,\n",
       " (1, (611, 4)): 762,\n",
       " (1, (775, 6)): 763,\n",
       " (1, (724, 39)): 764,\n",
       " (1, (556, 64)): 765,\n",
       " (1, (516, 33)): 766,\n",
       " (1, (140, 4)): 767,\n",
       " (1, (441, 65)): 768,\n",
       " (1, (120, 80)): 769,\n",
       " (1, (598, 93)): 770,\n",
       " (1, (635, 21)): 771,\n",
       " (1, (486, 75)): 772,\n",
       " (1, (282, 74)): 773,\n",
       " (1, (172, 99)): 774,\n",
       " (1, (80, 69)): 775,\n",
       " (1, (696, 38)): 776,\n",
       " (1, (721, 11)): 777,\n",
       " (1, (654, 38)): 778,\n",
       " (1, (96, 36)): 779,\n",
       " (1, (212, 88)): 780,\n",
       " (1, (714, 70)): 781,\n",
       " (1, (202, 56)): 782,\n",
       " (1, (208, 67)): 783,\n",
       " (1, (295, 49)): 784,\n",
       " (1, (359, 92)): 785,\n",
       " (1, (632, 36)): 786,\n",
       " (1, (596, 55)): 787,\n",
       " (1, (296, 60)): 788,\n",
       " (1, (720, 36)): 789,\n",
       " (1, (239, 50)): 790,\n",
       " (1, (312, 97)): 791,\n",
       " (1, (446, 4)): 792,\n",
       " (1, (637, 86)): 793,\n",
       " (1, (623, 95)): 794,\n",
       " (1, (274, 79)): 795,\n",
       " (1, (713, 12)): 796,\n",
       " (1, (571, 93)): 797,\n",
       " (1, (269, 75)): 798,\n",
       " (1, (15, 61)): 799,\n",
       " (1, (309, 45)): 800,\n",
       " (3, (33, 7)): 801,\n",
       " (1, (563, 53)): 802,\n",
       " (1, (746, 44)): 803,\n",
       " (1, (567, 73)): 804,\n",
       " (1, (350, 73)): 805,\n",
       " (1, (27, 45)): 806,\n",
       " (1, (736, 67)): 807,\n",
       " (1, (471, 96)): 808,\n",
       " (1, (423, 51)): 809,\n",
       " (1, (347, 45)): 810,\n",
       " (1, (449, 47)): 811,\n",
       " (1, (779, 22)): 812,\n",
       " (1, (151, 32)): 813,\n",
       " (1, (17, 40)): 814,\n",
       " (1, (414, 40)): 815,\n",
       " (1, (167, 28)): 816,\n",
       " (1, (709, 15)): 817,\n",
       " (1, (217, 84)): 818,\n",
       " (1, (119, 60)): 819,\n",
       " (1, (594, 80)): 820,\n",
       " (1, (543, 0)): 821,\n",
       " (1, (617, 64)): 822,\n",
       " (1, (537, 96)): 823,\n",
       " (1, (495, 38)): 824,\n",
       " (1, (376, 56)): 825,\n",
       " (1, (140, 37)): 826,\n",
       " (1, (146, 77)): 827,\n",
       " (1, (729, 97)): 828,\n",
       " (1, (465, 83)): 829,\n",
       " (1, (276, 1)): 830,\n",
       " (1, (518, 15)): 831,\n",
       " (1, (369, 71)): 832,\n",
       " (1, (585, 47)): 833,\n",
       " (1, (395, 43)): 834,\n",
       " (1, (694, 9)): 835,\n",
       " (1, (627, 35)): 836,\n",
       " (1, (516, 90)): 837,\n",
       " (1, (73, 62)): 838,\n",
       " (1, (219, 20)): 839,\n",
       " (1, (762, 84)): 840,\n",
       " (1, (728, 33)): 841,\n",
       " (1, (612, 67)): 842,\n",
       " (1, (415, 70)): 843,\n",
       " (1, (770, 36)): 844,\n",
       " (1, (255, 5)): 845,\n",
       " (1, (317, 7)): 846,\n",
       " (1, (10, 95)): 847,\n",
       " (1, (497, 61)): 848,\n",
       " (1, (152, 50)): 849,\n",
       " (1, (379, 43)): 850,\n",
       " (1, (427, 51)): 851,\n",
       " (1, (576, 39)): 852,\n",
       " (1, (648, 65)): 853,\n",
       " (1, (255, 89)): 854,\n",
       " (1, (26, 79)): 855,\n",
       " (1, (695, 3)): 856,\n",
       " (1, (350, 56)): 857,\n",
       " (1, (660, 47)): 858,\n",
       " (1, (474, 84)): 859,\n",
       " (1, (326, 32)): 860,\n",
       " (1, (261, 76)): 861,\n",
       " (1, (462, 42)): 862,\n",
       " (1, (479, 67)): 863,\n",
       " (1, (666, 10)): 864,\n",
       " (1, (452, 53)): 865,\n",
       " (1, (236, 14)): 866,\n",
       " (1, (120, 91)): 867,\n",
       " (1, (759, 14)): 868,\n",
       " (1, (293, 80)): 869,\n",
       " (1, (327, 97)): 870,\n",
       " (3, (77, 9)): 871,\n",
       " (1, (263, 46)): 872,\n",
       " (1, (341, 25)): 873,\n",
       " (1, (256, 37)): 874,\n",
       " (1, (353, 2)): 875,\n",
       " (1, (100, 15)): 876,\n",
       " (1, (134, 62)): 877,\n",
       " (1, (242, 1)): 878,\n",
       " (1, (185, 1)): 879,\n",
       " (1, (754, 67)): 880,\n",
       " (1, (563, 79)): 881,\n",
       " (1, (725, 88)): 882,\n",
       " (1, (535, 1)): 883,\n",
       " (1, (751, 82)): 884,\n",
       " (1, (117, 18)): 885,\n",
       " (1, (222, 2)): 886,\n",
       " (1, (597, 16)): 887,\n",
       " (1, (730, 90)): 888,\n",
       " (1, (308, 24)): 889,\n",
       " (1, (68, 27)): 890,\n",
       " (1, (480, 79)): 891,\n",
       " (1, (361, 26)): 892,\n",
       " (1, (714, 45)): 893,\n",
       " (1, (602, 20)): 894,\n",
       " (1, (569, 48)): 895,\n",
       " (1, (694, 44)): 896,\n",
       " (1, (450, 72)): 897,\n",
       " (1, (318, 2)): 898,\n",
       " (1, (607, 71)): 899,\n",
       " (1, (735, 84)): 900,\n",
       " (1, (129, 67)): 901,\n",
       " (1, (395, 2)): 902,\n",
       " (1, (689, 9)): 903,\n",
       " (1, (312, 27)): 904,\n",
       " (1, (587, 95)): 905,\n",
       " (1, (135, 33)): 906,\n",
       " (1, (28, 79)): 907,\n",
       " (1, (660, 89)): 908,\n",
       " (1, (286, 58)): 909,\n",
       " (1, (65, 64)): 910,\n",
       " (1, (276, 88)): 911,\n",
       " (1, (162, 76)): 912,\n",
       " (1, (374, 67)): 913,\n",
       " (1, (25, 41)): 914,\n",
       " (1, (385, 69)): 915,\n",
       " (1, (612, 85)): 916,\n",
       " (1, (637, 38)): 917,\n",
       " (1, (517, 75)): 918,\n",
       " (1, (188, 76)): 919,\n",
       " (1, (405, 88)): 920,\n",
       " (1, (374, 23)): 921,\n",
       " (1, (719, 33)): 922,\n",
       " (1, (625, 11)): 923,\n",
       " (1, (284, 63)): 924,\n",
       " (1, (612, 12)): 925,\n",
       " (1, (663, 83)): 926,\n",
       " (1, (231, 61)): 927,\n",
       " (1, (60, 77)): 928,\n",
       " (1, (467, 13)): 929,\n",
       " (1, (418, 43)): 930,\n",
       " (1, (292, 66)): 931,\n",
       " (1, (720, 0)): 932,\n",
       " (1, (117, 19)): 933,\n",
       " (1, (587, 86)): 934,\n",
       " (1, (314, 46)): 935,\n",
       " (1, (309, 25)): 936,\n",
       " (1, (643, 52)): 937,\n",
       " (1, (702, 93)): 938,\n",
       " (1, (173, 7)): 939,\n",
       " (1, (608, 23)): 940,\n",
       " (1, (594, 93)): 941,\n",
       " (1, (779, 50)): 942,\n",
       " (1, (713, 82)): 943,\n",
       " (1, (696, 22)): 944,\n",
       " (1, (5, 32)): 945,\n",
       " (1, (766, 55)): 946,\n",
       " (1, (413, 93)): 947,\n",
       " (1, (312, 74)): 948,\n",
       " (1, (449, 66)): 949,\n",
       " (1, (641, 75)): 950,\n",
       " (1, (478, 75)): 951,\n",
       " (1, (262, 8)): 952,\n",
       " (1, (583, 1)): 953,\n",
       " (1, (600, 44)): 954,\n",
       " (1, (277, 46)): 955,\n",
       " (1, (334, 4)): 956,\n",
       " (1, (531, 48)): 957,\n",
       " (1, (445, 23)): 958,\n",
       " (1, (780, 6)): 959,\n",
       " (1, (291, 2)): 960,\n",
       " (1, (377, 72)): 961,\n",
       " (1, (254, 97)): 962,\n",
       " (1, (566, 79)): 963,\n",
       " (1, (720, 64)): 964,\n",
       " (1, (125, 89)): 965,\n",
       " (1, (77, 75)): 966,\n",
       " (1, (129, 23)): 967,\n",
       " (1, (356, 84)): 968,\n",
       " (1, (643, 28)): 969,\n",
       " (1, (428, 61)): 970,\n",
       " (1, (114, 82)): 971,\n",
       " (1, (727, 80)): 972,\n",
       " (1, (662, 5)): 973,\n",
       " (1, (754, 27)): 974,\n",
       " (1, (90, 46)): 975,\n",
       " (1, (675, 61)): 976,\n",
       " (1, (630, 68)): 977,\n",
       " (1, (303, 1)): 978,\n",
       " (1, (382, 51)): 979,\n",
       " (1, (571, 44)): 980,\n",
       " (1, (94, 62)): 981,\n",
       " (1, (59, 42)): 982,\n",
       " (1, (739, 53)): 983,\n",
       " (1, (513, 62)): 984,\n",
       " (1, (113, 34)): 985,\n",
       " (1, (344, 51)): 986,\n",
       " (1, (467, 50)): 987,\n",
       " (1, (574, 46)): 988,\n",
       " (1, (251, 72)): 989,\n",
       " (1, (760, 33)): 990,\n",
       " (1, (603, 89)): 991,\n",
       " (1, (205, 93)): 992,\n",
       " (1, (186, 96)): 993,\n",
       " (1, (627, 5)): 994,\n",
       " (1, (224, 11)): 995,\n",
       " (1, (365, 38)): 996,\n",
       " (1, (749, 84)): 997,\n",
       " (1, (312, 21)): 998,\n",
       " (1, (441, 58)): 999,\n",
       " (1, (61, 11)): 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dir = \"results/rq1/all_layers/simple_fm\"\n",
    "\n",
    "loc_loc_file = \"loc.all_cost.loc.{}.1.pkl\"\n",
    "loc_grad_file = \"grad/loc.all_cost.loc.{}.1.grad.pkl\"\n",
    "loc_random_file = \"random/loc.all_cost.loc.{}.1.random.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 'fashion_mnist'\n",
    "#loc_which = 'localiser' \n",
    "loc_which = 'gradient_loss'\n",
    "#loc_which = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "if which == 'fashion_mnist':\n",
    "    target_weights = fm_target_layes\n",
    "    loc_dir = \"results/rq1/all_layers/simple_fm\"\n",
    "elif which == 'cifar10':\n",
    "    target_weights = c10_target_layes\n",
    "    loc_dir = \"results/rq1/all_layers/simple_cm\"\n",
    "#else:\n",
    "#    target_weights = gtsrb_target_layes\n",
    "#    loc_dir = \"results/rq1/all_layers/simple_fm\"\n",
    "\n",
    "if loc_which == 'localiser':\n",
    "    loc_file = loc_loc_file\n",
    "elif loc_which == 'gradient_loss':\n",
    "    loc_file = loc_grad_file\n",
    "else:\n",
    "    loc_file = loc_random_file\n",
    "    \n",
    "dest = os.path.join(loc_dir, \"pairs/{}\".format(loc_which))\n",
    "os.makedirs(dest, exist_ok = True)\n",
    "\n",
    "for seed in tqdm.tqdm(range(30)):\n",
    "    curr_loc_file = os.path.join(loc_dir, loc_file.format(seed))\n",
    "    pairs = get_weight_and_cost(loc_which, seed, curr_loc_file, target_weights, method = 'max')\n",
    "    df = pd.DataFrame(list(pairs.items()))\n",
    "    pairfile = os.path.join(dest, \"{}.pairs.csv\".format(seed))\n",
    "    \n",
    "    df.to_csv(pairfile, sep = \";\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([3, (93, 6)], 14614.842),\n",
       " ([3, (93, 4)], 9396.044),\n",
       " ([3, (93, 8)], 6033.9316),\n",
       " ([3, (93, 0)], 5806.341),\n",
       " ([3, (9, 6)], 5498.6074),\n",
       " ([3, (93, 2)], 4745.653),\n",
       " ([3, (45, 6)], 4572.8706),\n",
       " ([3, (50, 6)], 4295.22),\n",
       " ([3, (71, 6)], 4265.6543),\n",
       " ([3, (45, 4)], 3572.9094),\n",
       " ([3, (9, 4)], 3434.061),\n",
       " ([3, (9, 8)], 3323.628),\n",
       " ([3, (5, 4)], 2947.9844),\n",
       " ([3, (5, 6)], 2673.6934),\n",
       " ([3, (45, 8)], 2503.706),\n",
       " ([3, (46, 7)], 2474.5686),\n",
       " ([3, (27, 7)], 2474.4722),\n",
       " ([3, (37, 7)], 2395.8098),\n",
       " ([3, (33, 7)], 2303.5208),\n",
       " ([3, (86, 4)], 2232.5571),\n",
       " ([3, (67, 6)], 2217.7637),\n",
       " ([3, (74, 4)], 2179.2095),\n",
       " ([3, (42, 7)], 2129.6577),\n",
       " ([3, (71, 4)], 2101.9414),\n",
       " ([3, (74, 6)], 2086.6382),\n",
       " ([3, (86, 6)], 2050.6292),\n",
       " ([3, (50, 4)], 2048.1226),\n",
       " ([3, (67, 4)], 2032.7578),\n",
       " ([3, (9, 2)], 1962.869),\n",
       " ([3, (50, 8)], 1961.8867),\n",
       " ([3, (45, 2)], 1959.9155),\n",
       " ([3, (1, 6)], 1951.5448),\n",
       " ([3, (71, 8)], 1945.7554),\n",
       " ([1, (343, 48)], 1933.6929),\n",
       " ([1, (371, 48)], 1929.2078),\n",
       " ([1, (315, 48)], 1922.9739),\n",
       " ([3, (34, 7)], 1919.3209),\n",
       " ([3, (55, 6)], 1909.739),\n",
       " ([1, (399, 48)], 1905.4373),\n",
       " ([1, (287, 48)], 1897.5898),\n",
       " ([3, (50, 0)], 1897.0603),\n",
       " ([1, (288, 48)], 1891.9346),\n",
       " ([1, (441, 48)], 1889.0779),\n",
       " ([1, (427, 48)], 1885.5095),\n",
       " ([1, (469, 48)], 1885.1481),\n",
       " ([1, (413, 48)], 1883.0422),\n",
       " ([1, (316, 48)], 1881.2915),\n",
       " ([1, (426, 48)], 1880.2167),\n",
       " ([1, (385, 48)], 1876.675),\n",
       " ([1, (259, 48)], 1874.2831),\n",
       " ([1, (454, 48)], 1873.9937),\n",
       " ([1, (497, 48)], 1870.8721),\n",
       " ([1, (398, 48)], 1869.2386),\n",
       " ([1, (482, 48)], 1868.5414),\n",
       " ([1, (260, 48)], 1865.6833),\n",
       " ([1, (510, 48)], 1865.0183),\n",
       " ([1, (538, 48)], 1864.1943),\n",
       " ([1, (455, 48)], 1863.7479),\n",
       " ([1, (328, 48)], 1863.3245),\n",
       " ([1, (370, 48)], 1862.9279),\n",
       " ([3, (59, 6)], 1862.0586),\n",
       " ([1, (566, 48)], 1859.8015),\n",
       " ([1, (541, 48)], 1859.4207),\n",
       " ([1, (300, 48)], 1858.138),\n",
       " ([1, (569, 48)], 1855.1227),\n",
       " ([1, (344, 48)], 1853.0613),\n",
       " ([1, (342, 48)], 1849.9442),\n",
       " ([1, (357, 48)], 1849.1722),\n",
       " ([1, (594, 48)], 1845.549),\n",
       " ([1, (231, 48)], 1845.1257),\n",
       " ([1, (458, 48)], 1843.5488),\n",
       " ([1, (486, 48)], 1841.6986),\n",
       " ([1, (525, 48)], 1841.6707),\n",
       " ([1, (542, 48)], 1840.7122),\n",
       " ([1, (356, 48)], 1840.5294),\n",
       " ([1, (329, 48)], 1840.5256),\n",
       " ([1, (514, 48)], 1839.0293),\n",
       " ([1, (314, 48)], 1837.8843),\n",
       " ([1, (430, 48)], 1834.3795),\n",
       " ([1, (544, 48)], 1832.7714),\n",
       " ([3, (23, 7)], 1830.7268),\n",
       " ([1, (513, 48)], 1830.3737),\n",
       " ([1, (543, 48)], 1829.4857),\n",
       " ([1, (516, 48)], 1828.7893),\n",
       " ([1, (550, 48)], 1827.7362),\n",
       " ([1, (570, 48)], 1825.3522),\n",
       " ([1, (622, 48)], 1824.9924),\n",
       " ([1, (597, 48)], 1824.4938),\n",
       " ([1, (488, 48)], 1824.0728),\n",
       " ([1, (515, 48)], 1822.2222),\n",
       " ([1, (483, 48)], 1821.6921),\n",
       " ([1, (232, 48)], 1821.0546),\n",
       " ([1, (286, 48)], 1820.7589),\n",
       " ([1, (272, 48)], 1820.7062),\n",
       " ([1, (547, 48)], 1820.3958),\n",
       " ([1, (487, 48)], 1820.1683),\n",
       " ([3, (93, 3)], 1819.9073),\n",
       " ([1, (494, 48)], 1819.7961),\n",
       " ([1, (301, 48)], 1818.9878),\n",
       " ([1, (571, 48)], 1818.875),\n",
       " ([1, (459, 48)], 1818.6432),\n",
       " ([1, (522, 48)], 1818.4072),\n",
       " ([1, (572, 48)], 1817.9778),\n",
       " ([1, (402, 48)], 1817.0938),\n",
       " ([1, (625, 48)], 1816.9308),\n",
       " ([1, (553, 48)], 1815.505),\n",
       " ([1, (374, 48)], 1815.3046),\n",
       " ([1, (466, 48)], 1814.8123),\n",
       " ([1, (548, 48)], 1814.5942),\n",
       " ([1, (578, 48)], 1813.628),\n",
       " ([1, (460, 48)], 1811.4359),\n",
       " ([1, (545, 48)], 1810.1912),\n",
       " ([1, (519, 48)], 1810.0215),\n",
       " ([1, (575, 48)], 1809.5571),\n",
       " ([1, (485, 48)], 1807.8351),\n",
       " ([1, (576, 48)], 1806.7458),\n",
       " ([1, (431, 48)], 1806.5686),\n",
       " ([1, (573, 48)], 1806.2461),\n",
       " ([1, (517, 48)], 1806.2217),\n",
       " ([1, (520, 48)], 1806.0894),\n",
       " ([1, (273, 48)], 1805.5764),\n",
       " ([1, (491, 48)], 1804.3381),\n",
       " ([1, (492, 48)], 1804.279),\n",
       " ([1, (432, 48)], 1804.1252),\n",
       " ([1, (372, 48)], 1802.1252),\n",
       " ([1, (384, 48)], 1800.9716),\n",
       " ([1, (346, 48)], 1800.2964),\n",
       " ([1, (489, 48)], 1800.0288),\n",
       " ([1, (549, 48)], 1799.9583),\n",
       " ([1, (546, 48)], 1798.2955),\n",
       " ([1, (464, 48)], 1798.1915),\n",
       " ([1, (438, 48)], 1797.5398),\n",
       " ([1, (203, 48)], 1797.3328),\n",
       " ([1, (258, 48)], 1795.5833),\n",
       " ([1, (577, 48)], 1795.3231),\n",
       " ([1, (493, 48)], 1793.9082),\n",
       " ([1, (574, 48)], 1793.3601),\n",
       " ([1, (299, 48)], 1792.5242),\n",
       " ([1, (461, 48)], 1792.3264),\n",
       " ([1, (442, 48)], 1792.2966),\n",
       " ([1, (463, 48)], 1791.718),\n",
       " ([1, (465, 48)], 1790.5986),\n",
       " ([1, (600, 48)], 1788.7859),\n",
       " ([1, (518, 48)], 1788.6963),\n",
       " ([1, (521, 48)], 1788.4801),\n",
       " ([1, (289, 48)], 1787.9756),\n",
       " ([1, (436, 48)], 1787.8842),\n",
       " ([1, (403, 48)], 1786.7202),\n",
       " ([1, (599, 48)], 1786.5947),\n",
       " ([1, (490, 48)], 1786.4891),\n",
       " ([1, (470, 48)], 1786.438),\n",
       " ([1, (404, 48)], 1786.2117),\n",
       " ([1, (318, 48)], 1784.9009),\n",
       " ([1, (204, 48)], 1783.5856),\n",
       " ([1, (457, 48)], 1783.3687),\n",
       " ([1, (376, 48)], 1782.3057),\n",
       " ([1, (375, 48)], 1781.8533),\n",
       " ([1, (601, 48)], 1781.6111),\n",
       " ([1, (435, 48)], 1781.1863),\n",
       " ([1, (598, 48)], 1780.8925),\n",
       " ([1, (511, 48)], 1780.7109),\n",
       " ([1, (414, 48)], 1780.4121),\n",
       " ([1, (410, 48)], 1780.3052),\n",
       " ([1, (462, 48)], 1780.2261),\n",
       " ([1, (433, 48)], 1780.0107),\n",
       " ([1, (581, 48)], 1779.9073),\n",
       " ([1, (603, 48)], 1779.1333),\n",
       " ([1, (498, 48)], 1778.7599),\n",
       " ([1, (317, 48)], 1778.1127),\n",
       " ([1, (245, 48)], 1776.8843),\n",
       " ([1, (437, 48)], 1776.7455),\n",
       " ([1, (244, 48)], 1776.2064),\n",
       " ([1, (628, 48)], 1775.8862),\n",
       " ([1, (526, 48)], 1773.7692),\n",
       " ([1, (380, 48)], 1773.6573),\n",
       " ([1, (381, 48)], 1773.5398),\n",
       " ([1, (408, 48)], 1773.324),\n",
       " ([1, (271, 48)], 1773.2378),\n",
       " ([1, (627, 48)], 1773.0579),\n",
       " ([1, (606, 48)], 1772.3628),\n",
       " ([1, (554, 48)], 1771.8667),\n",
       " ([1, (604, 48)], 1770.8647),\n",
       " ([1, (409, 48)], 1770.5627),\n",
       " ([1, (602, 48)], 1770.0271),\n",
       " ([1, (261, 48)], 1769.0134),\n",
       " ([1, (382, 48)], 1768.6145),\n",
       " ([1, (434, 48)], 1768.1575),\n",
       " ([1, (327, 48)], 1766.7961),\n",
       " ([1, (582, 48)], 1766.4092),\n",
       " ([1, (650, 48)], 1766.3815),\n",
       " ([1, (626, 48)], 1764.5962),\n",
       " ([1, (631, 48)], 1764.468),\n",
       " ([1, (290, 48)], 1764.3162),\n",
       " ([1, (386, 48)], 1763.6912),\n",
       " ([1, (629, 48)], 1762.5615),\n",
       " ([1, (407, 48)], 1762.4888),\n",
       " ([1, (176, 48)], 1760.3181),\n",
       " ([1, (405, 48)], 1759.4802),\n",
       " ([1, (632, 48)], 1758.2913),\n",
       " ([1, (377, 48)], 1758.0276),\n",
       " ([1, (347, 48)], 1757.9988),\n",
       " ([1, (605, 48)], 1757.9606),\n",
       " ([1, (348, 48)], 1757.3853),\n",
       " ([1, (610, 48)], 1756.8175),\n",
       " ([1, (634, 48)], 1756.7839),\n",
       " ([1, (429, 48)], 1756.3671),\n",
       " ([1, (379, 48)], 1755.7949),\n",
       " ([1, (630, 48)], 1755.7883),\n",
       " ([1, (243, 48)], 1755.0786),\n",
       " ([1, (345, 48)], 1753.5546),\n",
       " ([1, (205, 48)], 1752.9907),\n",
       " ([1, (177, 48)], 1750.9612),\n",
       " ([1, (373, 48)], 1748.6749),\n",
       " ([1, (406, 48)], 1748.6504),\n",
       " ([1, (353, 48)], 1748.5273),\n",
       " ([1, (354, 48)], 1748.3508),\n",
       " ([1, (326, 48)], 1747.0295),\n",
       " ([1, (233, 48)], 1746.4927),\n",
       " ([1, (325, 48)], 1744.9808),\n",
       " ([1, (633, 48)], 1744.749),\n",
       " ([1, (378, 48)], 1743.1555),\n",
       " ([1, (349, 48)], 1742.9861),\n",
       " ([1, (401, 48)], 1741.9819),\n",
       " ([1, (319, 48)], 1741.4685),\n",
       " ([1, (149, 48)], 1741.4293),\n",
       " ([1, (262, 48)], 1740.7686),\n",
       " ([1, (175, 48)], 1740.2202),\n",
       " ([1, (291, 48)], 1739.7472),\n",
       " ([1, (352, 48)], 1738.7698),\n",
       " ([1, (653, 48)], 1738.5629),\n",
       " ([1, (215, 48)], 1738.4863),\n",
       " ([1, (638, 48)], 1738.009),\n",
       " ([1, (122, 48)], 1736.1913),\n",
       " ([1, (216, 48)], 1736.1637),\n",
       " ([1, (350, 48)], 1736.0247),\n",
       " ([1, (206, 48)], 1733.7607),\n",
       " ([1, (320, 48)], 1732.2377),\n",
       " ([1, (355, 48)], 1732.0715),\n",
       " ([1, (539, 48)], 1732.0573),\n",
       " ([1, (351, 48)], 1731.9756),\n",
       " ([1, (358, 48)], 1731.1263),\n",
       " ([3, (71, 0)], 1729.97),\n",
       " ([1, (230, 48)], 1729.8673),\n",
       " ([1, (412, 48)], 1729.8132),\n",
       " ([1, (298, 48)], 1729.6316),\n",
       " ([1, (178, 48)], 1729.1155),\n",
       " ([1, (217, 48)], 1728.2999),\n",
       " ([3, (1, 4)], 1725.0447),\n",
       " ([1, (579, 48)], 1724.748),\n",
       " ([1, (187, 48)], 1724.7018),\n",
       " ([1, (150, 48)], 1723.8634),\n",
       " ([1, (188, 48)], 1723.2789),\n",
       " ([1, (234, 48)], 1722.0042),\n",
       " ([1, (158, 48)], 1721.448),\n",
       " ([1, (148, 48)], 1720.2017),\n",
       " ([1, (324, 48)], 1719.8228),\n",
       " ([1, (321, 48)], 1719.0408),\n",
       " ([1, (159, 48)], 1718.9089),\n",
       " ([1, (270, 48)], 1718.8308),\n",
       " ([1, (123, 48)], 1717.9692),\n",
       " ([1, (609, 48)], 1716.7065),\n",
       " ([1, (129, 48)], 1716.3767),\n",
       " ([1, (323, 48)], 1715.7632),\n",
       " ([1, (186, 48)], 1715.4731),\n",
       " ([1, (551, 48)], 1715.2856),\n",
       " ([1, (400, 48)], 1715.0437),\n",
       " ([1, (151, 48)], 1714.2754),\n",
       " ([1, (185, 48)], 1713.8291),\n",
       " ([1, (99, 48)], 1712.6116),\n",
       " ([1, (322, 48)], 1712.269),\n",
       " ([1, (153, 48)], 1711.584),\n",
       " ([1, (157, 48)], 1711.5181),\n",
       " ([1, (295, 48)], 1709.5468),\n",
       " ([1, (214, 48)], 1708.8779),\n",
       " ([1, (96, 48)], 1708.2502),\n",
       " ([1, (297, 48)], 1708.2213),\n",
       " ([1, (95, 48)], 1707.5813),\n",
       " ([1, (127, 48)], 1706.7571),\n",
       " ([1, (292, 48)], 1706.134),\n",
       " ([1, (263, 48)], 1705.8356),\n",
       " ([1, (296, 48)], 1705.8088),\n",
       " ([1, (152, 48)], 1705.5393),\n",
       " ([1, (124, 48)], 1704.5801),\n",
       " ([1, (330, 48)], 1703.9519),\n",
       " ([1, (659, 48)], 1702.9061),\n",
       " ([1, (155, 48)], 1702.834),\n",
       " ([1, (154, 48)], 1702.6493),\n",
       " ([1, (156, 48)], 1702.2782),\n",
       " ([1, (656, 48)], 1701.411),\n",
       " ([1, (241, 48)], 1701.273),\n",
       " ([1, (125, 48)], 1700.7826),\n",
       " ([1, (607, 48)], 1700.4481),\n",
       " ([1, (383, 48)], 1700.166),\n",
       " ([1, (126, 48)], 1700.0642),\n",
       " ([1, (179, 48)], 1700.0271),\n",
       " ([1, (128, 48)], 1699.722),\n",
       " ([1, (657, 48)], 1698.8955),\n",
       " ([1, (655, 48)], 1697.629),\n",
       " ([1, (242, 48)], 1696.4893),\n",
       " ([1, (264, 48)], 1695.8436),\n",
       " ([1, (294, 48)], 1695.6309),\n",
       " ([1, (182, 48)], 1694.4324),\n",
       " ([1, (293, 48)], 1693.6925),\n",
       " ([1, (207, 48)], 1693.3772),\n",
       " ([1, (660, 48)], 1692.9126),\n",
       " ([1, (654, 48)], 1692.8533),\n",
       " ([1, (267, 48)], 1692.8223),\n",
       " ([1, (130, 48)], 1692.791),\n",
       " ([1, (235, 48)], 1691.392),\n",
       " ([1, (213, 48)], 1691.18),\n",
       " ([1, (236, 48)], 1690.7393),\n",
       " ([1, (181, 48)], 1690.3735),\n",
       " ([1, (183, 48)], 1690.2437),\n",
       " ([1, (658, 48)], 1689.8335),\n",
       " ([1, (94, 48)], 1689.5605),\n",
       " ([1, (635, 48)], 1689.1927),\n",
       " ([1, (678, 48)], 1688.612),\n",
       " ([1, (666, 48)], 1688.5051),\n",
       " ([1, (184, 48)], 1688.3318),\n",
       " ([1, (269, 48)], 1687.2456),\n",
       " ([1, (239, 48)], 1686.603),\n",
       " ([1, (662, 48)], 1686.469),\n",
       " ([1, (523, 48)], 1686.3633),\n",
       " ([1, (240, 48)], 1686.2014),\n",
       " ([1, (180, 48)], 1685.2578),\n",
       " ([1, (237, 48)], 1684.7826),\n",
       " ([1, (71, 48)], 1684.1663),\n",
       " ([1, (211, 48)], 1683.2175),\n",
       " ([1, (100, 48)], 1682.229),\n",
       " ([1, (268, 48)], 1680.8618),\n",
       " ([1, (68, 48)], 1680.7756),\n",
       " ([1, (101, 48)], 1680.5723),\n",
       " ([1, (97, 48)], 1680.276),\n",
       " ([1, (661, 48)], 1678.7319),\n",
       " ([1, (72, 48)], 1677.897),\n",
       " ([1, (266, 48)], 1674.4265),\n",
       " ([1, (238, 48)], 1673.9138),\n",
       " ([1, (212, 48)], 1673.5831),\n",
       " ([1, (121, 48)], 1672.728),\n",
       " ([1, (98, 48)], 1672.3488),\n",
       " ([1, (209, 48)], 1671.3546),\n",
       " ([1, (210, 48)], 1671.0449),\n",
       " ([1, (265, 48)], 1670.406),\n",
       " ([1, (208, 48)], 1669.5809),\n",
       " ([1, (567, 48)], 1669.5135),\n",
       " ([1, (160, 48)], 1668.4685),\n",
       " ([1, (440, 48)], 1668.2649),\n",
       " ([1, (411, 48)], 1665.1277),\n",
       " ([1, (467, 48)], 1664.5696),\n",
       " ([1, (495, 48)], 1663.186),\n",
       " ([1, (439, 48)], 1659.025),\n",
       " ([1, (637, 48)], 1652.5253),\n",
       " ([1, (428, 48)], 1651.975),\n",
       " ([1, (302, 48)], 1646.821),\n",
       " ([1, (69, 48)], 1643.626),\n",
       " ([3, (8, 4)], 1640.5754),\n",
       " ([1, (481, 48)], 1639.188),\n",
       " ([1, (147, 48)], 1638.6025),\n",
       " ([1, (509, 48)], 1637.2952),\n",
       " ([1, (189, 48)], 1634.7793),\n",
       " ([1, (202, 48)], 1632.9479),\n",
       " ([1, (663, 48)], 1628.2212),\n",
       " ([1, (67, 48)], 1626.6506),\n",
       " ([1, (453, 48)], 1625.0813),\n",
       " ([3, (40, 7)], 1623.9254),\n",
       " ([1, (565, 48)], 1622.1505),\n",
       " ([1, (537, 48)], 1620.9729),\n",
       " ([3, (70, 7)], 1618.7427),\n",
       " ([1, (694, 48)], 1617.7957),\n",
       " ([1, (468, 48)], 1616.2225),\n",
       " ([1, (425, 48)], 1613.4419),\n",
       " ([1, (706, 48)], 1611.961),\n",
       " ([1, (456, 48)], 1611.2922),\n",
       " ([1, (70, 48)], 1609.9692),\n",
       " ([1, (593, 48)], 1609.5563),\n",
       " ([1, (102, 48)], 1603.531),\n",
       " ([1, (40, 48)], 1597.5664),\n",
       " ([1, (44, 48)], 1597.1299),\n",
       " ([1, (131, 48)], 1596.0441),\n",
       " ([1, (43, 48)], 1594.1873),\n",
       " ([1, (73, 48)], 1589.3508),\n",
       " ([1, (595, 48)], 1585.0276),\n",
       " ([1, (621, 48)], 1583.8126),\n",
       " ([1, (681, 48)], 1583.583),\n",
       " ([1, (397, 48)], 1579.9038),\n",
       " ([3, (14, 4)], 1577.3097),\n",
       " ([3, (62, 7)], 1576.8689),\n",
       " ([1, (484, 48)], 1574.9188),\n",
       " ([1, (41, 48)], 1572.9966),\n",
       " ([1, (274, 48)], 1567.6404),\n",
       " ([1, (496, 48)], 1566.2507),\n",
       " ([1, (541, 76)], 1565.5448),\n",
       " ([1, (120, 48)], 1564.002),\n",
       " ([1, (665, 48)], 1562.732),\n",
       " ([1, (687, 48)], 1559.8108),\n",
       " ([1, (569, 76)], 1559.7023),\n",
       " ([1, (684, 48)], 1558.124),\n",
       " ([1, (688, 48)], 1557.8132),\n",
       " ([1, (512, 48)], 1555.6934),\n",
       " ([1, (685, 48)], 1554.7625),\n",
       " ([1, (686, 48)], 1552.8088),\n",
       " ([1, (683, 48)], 1550.019),\n",
       " ([1, (682, 48)], 1547.6318),\n",
       " ([1, (690, 48)], 1544.2185),\n",
       " ([1, (513, 76)], 1543.4248),\n",
       " ([1, (722, 48)], 1542.8068),\n",
       " ([1, (540, 48)], 1540.6213),\n",
       " ([1, (649, 48)], 1540.0369),\n",
       " ([1, (42, 48)], 1539.7567),\n",
       " ([1, (546, 76)], 1539.2761),\n",
       " ([1, (544, 76)], 1538.429),\n",
       " ([1, (545, 76)], 1537.2413),\n",
       " ([1, (689, 48)], 1535.6526),\n",
       " ([1, (547, 76)], 1535.2761),\n",
       " ([1, (369, 48)], 1534.2035),\n",
       " ([1, (543, 76)], 1532.4094),\n",
       " ([1, (548, 76)], 1529.4304),\n",
       " ([1, (66, 48)], 1528.4443),\n",
       " ([1, (549, 76)], 1528.195),\n",
       " ([1, (568, 48)], 1526.3049),\n",
       " ([1, (300, 76)], 1525.4889),\n",
       " ([1, (571, 76)], 1525.4668),\n",
       " ([1, (597, 76)], 1525.3545),\n",
       " ([1, (572, 76)], 1525.1436),\n",
       " ([1, (518, 76)], 1524.5022),\n",
       " ([1, (570, 76)], 1524.2124),\n",
       " ([1, (574, 76)], 1524.0411),\n",
       " ([1, (485, 76)], 1523.0642),\n",
       " ([1, (519, 76)], 1523.0166),\n",
       " ([1, (575, 76)], 1522.44),\n",
       " ([1, (516, 76)], 1522.3257),\n",
       " ([1, (517, 76)], 1522.3076),\n",
       " ([1, (542, 76)], 1521.645),\n",
       " ([1, (573, 76)], 1521.4502),\n",
       " ([1, (93, 48)], 1519.6741),\n",
       " ([1, (524, 48)], 1519.6238),\n",
       " ([1, (576, 76)], 1514.9408),\n",
       " ([1, (486, 76)], 1511.9622),\n",
       " ([1, (514, 76)], 1511.9124),\n",
       " ([1, (328, 76)], 1511.2542),\n",
       " ([1, (272, 76)], 1510.921),\n",
       " ([1, (623, 48)], 1510.7402),\n",
       " ([1, (520, 76)], 1510.6919),\n",
       " ([1, (462, 76)], 1510.4685),\n",
       " ([1, (522, 76)], 1509.8452),\n",
       " ([1, (577, 76)], 1508.5359),\n",
       " ([1, (521, 76)], 1507.7131),\n",
       " ([1, (515, 76)], 1507.6482),\n",
       " ([1, (491, 76)], 1506.8262),\n",
       " ([1, (490, 76)], 1504.7136),\n",
       " ([1, (550, 76)], 1504.6942),\n",
       " ([1, (489, 76)], 1502.9379),\n",
       " ([1, (596, 48)], 1502.0544),\n",
       " ([1, (487, 76)], 1500.8398),\n",
       " ([1, (522, 90)], 1500.6555),\n",
       " ([1, (457, 76)], 1499.4275),\n",
       " ([1, (463, 76)], 1499.3542),\n",
       " ([1, (599, 76)], 1498.5876),\n",
       " ([1, (601, 76)], 1498.4868),\n",
       " ([1, (494, 76)], 1498.4062),\n",
       " ([1, (602, 76)], 1497.5159),\n",
       " ([1, (488, 76)], 1497.3403),\n",
       " ([1, (578, 76)], 1496.5032),\n",
       " ([1, (600, 76)], 1496.3987),\n",
       " ([1, (299, 76)], 1496.2997),\n",
       " ([1, (327, 76)], 1495.9324),\n",
       " ([3, (27, 9)], 1493.4175),\n",
       " ([1, (598, 76)], 1493.2644),\n",
       " ([1, (493, 76)], 1492.3472),\n",
       " ([1, (603, 76)], 1491.6128),\n",
       " ([1, (174, 48)], 1491.3562),\n",
       " ([1, (461, 76)], 1490.0317),\n",
       " ([1, (356, 76)], 1488.999),\n",
       " ([1, (459, 76)], 1488.6377),\n",
       " ([1, (492, 76)], 1488.5564),\n",
       " ([1, (458, 76)], 1488.001),\n",
       " ([1, (271, 76)], 1487.888),\n",
       " ([1, (434, 76)], 1487.234),\n",
       " ([3, (66, 4)], 1486.9763),\n",
       " ([1, (460, 76)], 1486.743),\n",
       " ([1, (435, 76)], 1484.9053),\n",
       " ([1, (466, 76)], 1484.7778),\n",
       " ([1, (552, 48)], 1484.7676),\n",
       " ([1, (518, 62)], 1484.5498),\n",
       " ([1, (161, 48)], 1484.0432),\n",
       " ([1, (355, 76)], 1483.9836),\n",
       " ([1, (604, 76)], 1483.7861),\n",
       " ([1, (518, 90)], 1483.3513),\n",
       " ([1, (625, 76)], 1483.3499),\n",
       " ([1, (244, 76)], 1480.9553),\n",
       " ([1, (517, 90)], 1480.4734),\n",
       " ([1, (465, 76)], 1480.2229),\n",
       " ([1, (132, 48)], 1479.7822),\n",
       " ([1, (433, 76)], 1479.6328),\n",
       " ([1, (551, 76)], 1479.4695),\n",
       " ([1, (382, 76)], 1479.1909),\n",
       " ([1, (519, 90)], 1478.6277),\n",
       " ([1, (519, 62)], 1478.227),\n",
       " ([1, (410, 76)], 1478.1025),\n",
       " ([1, (431, 76)], 1477.9299),\n",
       " ([1, (438, 76)], 1477.8629),\n",
       " ([1, (523, 62)], 1477.3472),\n",
       " ([1, (325, 76)], 1477.1968),\n",
       " ([1, (429, 76)], 1476.0514),\n",
       " ([1, (677, 48)], 1475.931),\n",
       " ([1, (379, 76)], 1475.9142),\n",
       " ([1, (407, 76)], 1475.7498),\n",
       " ([1, (341, 48)], 1475.5771),\n",
       " ([1, (436, 76)], 1475.0533),\n",
       " ([1, (605, 76)], 1474.9867),\n",
       " ([1, (522, 62)], 1474.8438),\n",
       " ([1, (494, 90)], 1474.7544),\n",
       " ([1, (734, 48)], 1474.7131),\n",
       " ([1, (579, 76)], 1474.3456),\n",
       " ([1, (430, 76)], 1473.9382),\n",
       " ([1, (432, 76)], 1473.797),\n",
       " ([1, (297, 76)], 1473.4613),\n",
       " ([1, (406, 76)], 1472.9185),\n",
       " ([1, (624, 48)], 1472.4722),\n",
       " ([1, (437, 76)], 1471.8538),\n",
       " ([1, (464, 76)], 1471.4783),\n",
       " ([1, (523, 76)], 1471.3389),\n",
       " ([1, (521, 62)], 1470.6611),\n",
       " ([1, (606, 76)], 1470.6167),\n",
       " ([1, (288, 76)], 1470.5746),\n",
       " ([1, (517, 62)], 1470.2041),\n",
       " ([3, (55, 4)], 1470.0194),\n",
       " ([1, (354, 76)], 1469.7852),\n",
       " ([1, (353, 76)], 1469.6489),\n",
       " ([1, (381, 76)], 1468.258),\n",
       " ([1, (351, 76)], 1468.2554),\n",
       " ([1, (243, 76)], 1467.8513),\n",
       " ([1, (409, 76)], 1467.4756),\n",
       " ([1, (693, 48)], 1466.5875),\n",
       " ([1, (520, 90)], 1466.4907),\n",
       " ([1, (629, 76)], 1466.365),\n",
       " ([1, (691, 48)], 1466.268),\n",
       " ([1, (326, 76)], 1465.5106),\n",
       " ([1, (630, 76)], 1465.084),\n",
       " ([1, (494, 62)], 1465.02),\n",
       " ([1, (466, 90)], 1464.9915),\n",
       " ([1, (408, 76)], 1464.9443),\n",
       " ([1, (260, 76)], 1464.6531),\n",
       " ([1, (521, 90)], 1464.5842),\n",
       " ([1, (298, 76)], 1464.389),\n",
       " ([1, (352, 76)], 1463.6782),\n",
       " ([1, (384, 76)], 1463.0657),\n",
       " ([1, (378, 76)], 1462.8616),\n",
       " ([1, (493, 62)], 1461.8667),\n",
       " ([1, (246, 48)], 1459.9329),\n",
       " ([1, (628, 76)], 1459.342),\n",
       " ([1, (466, 62)], 1459.0245),\n",
       " ([1, (405, 76)], 1458.3794),\n",
       " ([1, (438, 90)], 1458.3193),\n",
       " ([1, (607, 76)], 1458.1813),\n",
       " ([1, (627, 76)], 1458.0769),\n",
       " ([1, (520, 62)], 1457.9724),\n",
       " ([1, (316, 76)], 1457.6628),\n",
       " ([1, (495, 62)], 1457.5952),\n",
       " ([3, (33, 9)], 1456.6974),\n",
       " ([1, (383, 76)], 1456.5),\n",
       " ([1, (580, 48)], 1456.46),\n",
       " ([1, (631, 76)], 1456.4419),\n",
       " ([1, (380, 76)], 1456.3206),\n",
       " ([1, (377, 76)], 1456.314),\n",
       " ([1, (404, 76)], 1455.771),\n",
       " ([1, (324, 76)], 1455.7612),\n",
       " ([1, (490, 62)], 1455.0472),\n",
       " ([1, (491, 62)], 1454.8741),\n",
       " ([1, (490, 90)], 1452.9082),\n",
       " ([1, (270, 76)], 1452.3005),\n",
       " ([1, (546, 90)], 1452.2625),\n",
       " ([1, (516, 90)], 1452.0574),\n",
       " ([1, (495, 76)], 1451.7219),\n",
       " ([3, (99, 7)], 1451.4498),\n",
       " ([1, (403, 76)], 1451.2046),\n",
       " ([1, (382, 62)], 1450.59),\n",
       " ([1, (626, 76)], 1450.2069),\n",
       " ([1, (545, 90)], 1449.3881),\n",
       " ([1, (232, 76)], 1448.8955),\n",
       " ([1, (462, 90)], 1448.8873),\n",
       " ([1, (438, 62)], 1448.7007),\n",
       " ([1, (39, 48)], 1448.3799),\n",
       " ([1, (402, 76)], 1448.0012),\n",
       " ([1, (269, 76)], 1447.3218),\n",
       " ([1, (491, 90)], 1446.7094),\n",
       " ([1, (410, 62)], 1446.5283),\n",
       " ([1, (410, 90)], 1446.4568),\n",
       " ([1, (462, 62)], 1446.001),\n",
       " ([1, (382, 90)], 1445.7593),\n",
       " ([1, (492, 62)], 1444.8451),\n",
       " ([1, (493, 90)], 1444.7341),\n",
       " ([1, (632, 76)], 1443.8835),\n",
       " ([1, (411, 76)], 1443.8396),\n",
       " ([1, (547, 90)], 1443.8281),\n",
       " ([1, (323, 76)], 1443.8098),\n",
       " ([1, (489, 62)], 1443.7565),\n",
       " ([1, (489, 90)], 1442.909),\n",
       " ([1, (541, 90)], 1442.5623),\n",
       " ([1, (467, 62)], 1441.2181),\n",
       " ([1, (272, 62)], 1440.8284),\n",
       " ([1, (376, 76)], 1440.5197),\n",
       " ([1, (465, 62)], 1440.3254),\n",
       " ([1, (350, 76)], 1439.9626),\n",
       " ([1, (492, 90)], 1439.5422),\n",
       " ([1, (344, 76)], 1439.338),\n",
       " ([1, (653, 76)], 1439.2902),\n",
       " ([1, (467, 76)], 1439.2583),\n",
       " ([1, (401, 76)], 1439.2021),\n",
       " ([1, (384, 90)], 1436.8644),\n",
       " ([1, (463, 62)], 1436.8207),\n",
       " ([1, (513, 90)], 1436.8076),\n",
       " ([1, (242, 76)], 1436.31),\n",
       " ([1, (515, 90)], 1436.2903),\n",
       " ([1, (349, 76)], 1435.3778),\n",
       " ([1, (463, 90)], 1434.7712),\n",
       " ([1, (657, 76)], 1433.7148),\n",
       " ([1, (544, 90)], 1433.5669),\n",
       " ([1, (523, 90)], 1433.3035),\n",
       " ([1, (296, 76)], 1433.2334),\n",
       " ([1, (300, 62)], 1432.7649),\n",
       " ([1, (295, 76)], 1432.3414),\n",
       " ([1, (543, 90)], 1431.75),\n",
       " ([1, (633, 76)], 1431.7468),\n",
       " ([1, (215, 76)], 1431.5498),\n",
       " ([1, (411, 62)], 1431.3003),\n",
       " ([1, (465, 90)], 1430.9675),\n",
       " ([1, (439, 76)], 1430.8789),\n",
       " ([1, (464, 62)], 1430.1147),\n",
       " ([1, (439, 62)], 1430.0703),\n",
       " ([1, (516, 62)], 1429.2272),\n",
       " ([1, (550, 90)], 1428.9517),\n",
       " ([1, (656, 76)], 1428.258),\n",
       " ([1, (412, 76)], 1428.1877),\n",
       " ([1, (658, 76)], 1427.7993),\n",
       " ([1, (750, 48)], 1427.6799),\n",
       " ([1, (546, 62)], 1427.4902),\n",
       " ([1, (634, 76)], 1426.5092),\n",
       " ([1, (548, 90)], 1426.2117),\n",
       " ([1, (436, 62)], 1426.0377),\n",
       " ([1, (635, 76)], 1425.7759),\n",
       " ([1, (383, 62)], 1425.7152),\n",
       " ([1, (464, 90)], 1425.3633),\n",
       " ([1, (545, 62)], 1424.5725),\n",
       " ([1, (513, 62)], 1424.3975),\n",
       " ([1, (659, 76)], 1424.2546),\n",
       " ([1, (435, 90)], 1423.9114),\n",
       " ([1, (436, 90)], 1423.8569),\n",
       " ([1, (241, 76)], 1423.5508),\n",
       " ([1, (461, 90)], 1423.0706),\n",
       " ([1, (461, 62)], 1422.9431),\n",
       " ([1, (514, 90)], 1422.7554),\n",
       " ([1, (216, 76)], 1422.5669),\n",
       " ([1, (681, 76)], 1422.52),\n",
       " ([1, (434, 90)], 1422.0812),\n",
       " ([1, (354, 62)], 1421.8448),\n",
       " ([1, (322, 76)], 1421.4424),\n",
       " ([1, (488, 90)], 1419.3569),\n",
       " ([1, (375, 76)], 1418.9973),\n",
       " ([1, (655, 76)], 1418.3215),\n",
       " ([1, (435, 62)], 1418.0964),\n",
       " ([1, (437, 62)], 1418.0028),\n",
       " ([1, (547, 62)], 1417.7871),\n",
       " ([1, (685, 76)], 1417.5436),\n",
       " ([1, (686, 76)], 1417.4978),\n",
       " ([1, (549, 90)], 1417.4509),\n",
       " ([1, (437, 90)], 1417.3531),\n",
       " ([1, (214, 76)], 1416.9951),\n",
       " ([1, (412, 90)], 1416.6514),\n",
       " ([1, (268, 76)], 1416.5933),\n",
       " ([1, (373, 76)], 1415.9386),\n",
       " ([1, (383, 90)], 1415.4253),\n",
       " ([1, (289, 76)], 1414.5105),\n",
       " ([1, (374, 76)], 1414.3591),\n",
       " ([1, (495, 90)], 1414.133),\n",
       " ([1, (204, 76)], 1413.8357),\n",
       " ([1, (356, 90)], 1413.6199),\n",
       " ([1, (408, 62)], 1413.1536),\n",
       " ([1, (488, 62)], 1412.9629),\n",
       " ([3, (19, 4)], 1412.6267),\n",
       " ([1, (327, 90)], 1412.5936),\n",
       " ([1, (684, 76)], 1412.5217),\n",
       " ([1, (355, 90)], 1412.323),\n",
       " ([1, (326, 62)], 1411.9221),\n",
       " ([1, (348, 76)], 1411.8218),\n",
       " ([1, (485, 90)], 1411.6483),\n",
       " ([1, (542, 90)], 1410.6953),\n",
       " ([1, (74, 48)], 1409.6666),\n",
       " ([1, (487, 90)], 1409.5042),\n",
       " ([1, (515, 62)], 1409.235),\n",
       " ([1, (355, 62)], 1409.0001),\n",
       " ([1, (654, 76)], 1408.8086),\n",
       " ([1, (434, 62)], 1408.2457),\n",
       " ([1, (313, 48)], 1407.9313),\n",
       " ([1, (261, 76)], 1407.7053),\n",
       " ([1, (407, 62)], 1407.7048),\n",
       " ([1, (317, 76)], 1407.1384),\n",
       " ([1, (287, 76)], 1406.9817),\n",
       " ([1, (408, 90)], 1406.57),\n",
       " ([1, (660, 76)], 1406.5581),\n",
       " ([1, (345, 76)], 1406.4706),\n",
       " ([1, (267, 76)], 1405.9539),\n",
       " ([1, (409, 62)], 1405.8861),\n",
       " ([1, (687, 76)], 1405.7783),\n",
       " ([1, (651, 48)], 1405.3313),\n",
       " ([1, (549, 62)], 1404.8217),\n",
       " ([1, (381, 62)], 1404.468),\n",
       " ([1, (468, 90)], 1404.3062),\n",
       " ([1, (354, 90)], 1403.8962),\n",
       " ([1, (259, 76)], 1403.7544),\n",
       " ([1, (294, 76)], 1403.56),\n",
       " ([1, (409, 90)], 1403.5208),\n",
       " ([1, (433, 90)], 1403.0289),\n",
       " ([1, (548, 62)], 1402.9886),\n",
       " ([1, (372, 76)], 1402.4121),\n",
       " ([1, (688, 76)], 1402.2485),\n",
       " ([1, (440, 90)], 1402.0277),\n",
       " ([1, (381, 90)], 1402.0082),\n",
       " ([1, (661, 76)], 1401.881),\n",
       " ([1, (467, 90)], 1401.835),\n",
       " ([1, (321, 76)], 1401.3752),\n",
       " ([1, (315, 76)], 1401.3749),\n",
       " ([1, (683, 76)], 1401.1602),\n",
       " ([1, (411, 90)], 1400.8816),\n",
       " ([1, (544, 62)], 1400.4485),\n",
       " ([1, (487, 62)], 1400.3674),\n",
       " ([1, (353, 62)], 1400.0137),\n",
       " ([1, (299, 90)], 1399.7524),\n",
       " ([1, (439, 90)], 1399.2194),\n",
       " ([1, (119, 48)], 1399.0284),\n",
       " ([1, (407, 90)], 1398.3762),\n",
       " ([1, (608, 48)], 1398.2166),\n",
       " ([1, (233, 76)], 1397.6646),\n",
       " ([1, (486, 90)], 1397.621),\n",
       " ([1, (514, 62)], 1397.2673),\n",
       " ([1, (541, 62)], 1396.6046),\n",
       " ([1, (347, 76)], 1395.7947),\n",
       " ([1, (689, 76)], 1395.0797),\n",
       " ([1, (231, 76)], 1394.7981),\n",
       " ([1, (540, 76)], 1394.5483),\n",
       " ([1, (353, 90)], 1394.5148),\n",
       " ([1, (326, 90)], 1394.3629),\n",
       " ([1, (682, 76)], 1394.2266),\n",
       " ([1, (568, 76)], 1394.2034),\n",
       " ([1, (380, 90)], 1393.4873),\n",
       " ([1, (485, 62)], 1393.4233),\n",
       " ([1, (328, 90)], 1393.19),\n",
       " ([1, (187, 76)], 1392.7136),\n",
       " ([1, (551, 62)], 1392.6884),\n",
       " ([1, (379, 90)], 1392.6565),\n",
       " ([1, (705, 48)], 1392.5645),\n",
       " ([1, (325, 62)], 1392.5089),\n",
       " ([1, (325, 90)], 1392.2396),\n",
       " ([1, (244, 62)], 1392.0459),\n",
       " ([1, (320, 76)], 1391.6313),\n",
       " ([1, (240, 76)], 1391.5995),\n",
       " ([1, (346, 76)], 1391.4988),\n",
       " ([1, (440, 76)], 1391.0138),\n",
       " ([1, (460, 90)], 1390.2162),\n",
       " ([1, (652, 48)], 1390.0867),\n",
       " ([1, (524, 90)], 1389.8531),\n",
       " ([1, (543, 62)], 1389.254),\n",
       " ([1, (406, 90)], 1389.2441),\n",
       " ([3, (66, 6)], 1388.5654),\n",
       " ([1, (298, 62)], 1388.3992),\n",
       " ([3, (42, 9)], 1387.3315),\n",
       " ([1, (406, 62)], 1387.1616),\n",
       " ([1, (496, 90)], 1386.7644),\n",
       " ([1, (328, 62)], 1386.4539),\n",
       " ([1, (663, 76)], 1386.084),\n",
       " ([1, (266, 76)], 1385.0017),\n",
       " ([1, (380, 62)], 1384.2871),\n",
       " ([1, (318, 76)], 1383.1321),\n",
       " ([1, (327, 62)], 1382.9827),\n",
       " ([1, (213, 76)], 1382.9363),\n",
       " ([1, (352, 62)], 1382.7687),\n",
       " ([1, (459, 90)], 1382.6819),\n",
       " ([1, (352, 90)], 1382.5791),\n",
       " ([1, (290, 76)], 1382.4188),\n",
       " ([1, (379, 62)], 1382.3184),\n",
       " ([1, (433, 62)], 1381.982),\n",
       " ([1, (273, 62)], 1381.8817),\n",
       " ([1, (460, 62)], 1380.4537),\n",
       " ([1, (690, 76)], 1380.0017),\n",
       " ([1, (324, 62)], 1379.8171),\n",
       " ([1, (550, 62)], 1379.3477),\n",
       " ([1, (596, 76)], 1379.0684),\n",
       " ([1, (662, 76)], 1379.0051),\n",
       " ([1, (512, 76)], 1378.6816),\n",
       " ([1, (239, 76)], 1378.3344),\n",
       " ([1, (186, 76)], 1377.459),\n",
       " ([1, (262, 76)], 1377.1854),\n",
       " ([1, (205, 76)], 1376.6501),\n",
       " ([1, (176, 76)], 1376.343),\n",
       " ([1, (569, 90)], 1375.2299),\n",
       " ([1, (484, 76)], 1374.4905),\n",
       " ([1, (486, 62)], 1374.3696),\n",
       " ([1, (324, 90)], 1374.179),\n",
       " ([1, (691, 76)], 1373.996),\n",
       " ([1, (292, 76)], 1373.6001),\n",
       " ([1, (319, 76)], 1373.5967),\n",
       " ([1, (378, 90)], 1373.5476),\n",
       " ([1, (271, 90)], 1373.2457),\n",
       " ([1, (468, 76)], 1373.1605),\n",
       " ([1, (400, 76)], 1373.0566),\n",
       " ([1, (293, 76)], 1372.922),\n",
       " ([1, (573, 90)], 1372.0659),\n",
       " ([1, (456, 76)], 1370.9661),\n",
       " ([1, (297, 62)], 1370.8806),\n",
       " ([1, (103, 48)], 1370.814),\n",
       " ([1, (291, 76)], 1369.7815),\n",
       " ([1, (351, 90)], 1369.263),\n",
       " ([1, (299, 62)], 1368.5521),\n",
       " ([1, (300, 90)], 1368.5498),\n",
       " ([1, (551, 90)], 1368.3804),\n",
       " ([1, (574, 90)], 1368.1106),\n",
       " ([1, (428, 76)], 1367.5052),\n",
       " ([1, (264, 76)], 1366.986),\n",
       " ([1, (457, 90)], 1366.1301),\n",
       " ([1, (265, 76)], 1366.0818),\n",
       " ([1, (301, 62)], 1365.8296),\n",
       " ([1, (542, 62)], 1364.0542),\n",
       " ([1, (458, 90)], 1363.9414),\n",
       " ([1, (234, 76)], 1363.1042),\n",
       " ([1, (203, 76)], 1362.873),\n",
       " ([1, (263, 76)], 1362.3687),\n",
       " ([1, (149, 76)], 1362.241),\n",
       " ([1, (298, 90)], 1362.032),\n",
       " ([1, (271, 62)], 1361.9609),\n",
       " ([1, (343, 76)], 1361.8713),\n",
       " ([1, (351, 62)], 1361.4523),\n",
       " ([1, (459, 62)], 1360.7778),\n",
       " ([1, (238, 76)], 1359.812),\n",
       " ([1, (457, 62)], 1358.5078),\n",
       " ([1, (624, 76)], 1358.3059),\n",
       " ([1, (177, 76)], 1358.2799),\n",
       " ([1, (378, 62)], 1358.1799),\n",
       " ([1, (572, 90)], 1358.1512),\n",
       " ([3, (46, 9)], 1357.1923),\n",
       " ([1, (212, 76)], 1357.1787),\n",
       " ([1, (432, 90)], 1356.8665),\n",
       " ([1, (297, 90)], 1356.4811),\n",
       " ([1, (188, 76)], 1355.6147),\n",
       " ([1, (571, 90)], 1355.1489),\n",
       " ([1, (185, 76)], 1355.1274),\n",
       " ([1, (405, 90)], 1354.5753),\n",
       " ([1, (570, 90)], 1353.3619),\n",
       " ([1, (210, 76)], 1353.0852),\n",
       " ([1, (511, 76)], 1352.7844),\n",
       " ([1, (211, 76)], 1352.7711),\n",
       " ([1, (525, 90)], 1351.8022),\n",
       " ([1, (158, 76)], 1351.5754),\n",
       " ([1, (182, 76)], 1351.0483),\n",
       " ([1, (575, 90)], 1351.0244),\n",
       " ([1, (483, 76)], 1350.9082),\n",
       " ([1, (496, 76)], 1350.5012),\n",
       " ([1, (206, 76)], 1350.175),\n",
       " ([1, (159, 76)], 1349.3746),\n",
       " ([1, (583, 48)], 1349.1455),\n",
       " ([1, (45, 48)], 1348.6068),\n",
       " ([1, (235, 76)], 1348.324),\n",
       " ([1, (178, 76)], 1347.4767),\n",
       " ([1, (721, 48)], 1346.9192),\n",
       " ([1, (150, 76)], 1345.9829),\n",
       " ([1, (243, 62)], 1345.8542),\n",
       " ([1, (236, 76)], 1345.8132),\n",
       " ([1, (329, 62)], 1344.7507),\n",
       " ([1, (237, 76)], 1344.2031),\n",
       " ([1, (455, 76)], 1343.8293),\n",
       " ([1, (524, 76)], 1343.1838),\n",
       " ([1, (431, 90)], 1342.8875),\n",
       " ([1, (611, 48)], 1342.4392),\n",
       " ([1, (209, 76)], 1342.1428),\n",
       " ([1, (148, 76)], 1341.4453),\n",
       " ([1, (377, 90)], 1341.4055),\n",
       " ([1, (273, 76)], 1341.3242),\n",
       " ([1, (154, 76)], 1340.8542),\n",
       " ([1, (323, 90)], 1340.5557),\n",
       " ([1, (555, 48)], 1340.3208),\n",
       " ([1, (713, 76)], 1339.9889),\n",
       " ([1, (469, 90)], 1339.9615),\n",
       " ([1, (458, 62)], 1339.8522),\n",
       " ([1, (270, 62)], 1339.554),\n",
       " ([1, (578, 90)], 1339.4907),\n",
       " ([1, (207, 76)], 1339.2052),\n",
       " ([1, (539, 76)], 1338.8135),\n",
       " ([1, (153, 76)], 1338.1494),\n",
       " ([1, (497, 90)], 1338.0317),\n",
       " ([1, (714, 76)], 1337.9128),\n",
       " ([1, (709, 76)], 1337.8501),\n",
       " ([1, (181, 76)], 1337.2952),\n",
       " ([1, (576, 90)], 1337.2451),\n",
       " ([1, (126, 76)], 1336.7173),\n",
       " ([1, (512, 90)], 1336.415),\n",
       " ([1, (511, 90)], 1335.6661),\n",
       " ([1, (636, 48)], 1335.3511),\n",
       " ([1, (712, 76)], 1334.9236),\n",
       " ([1, (296, 90)], 1334.481),\n",
       " ([1, (301, 76)], 1334.406),\n",
       " ([1, (124, 76)], 1334.3657),\n",
       " ([1, (208, 76)], 1334.363),\n",
       " ([1, (179, 76)], 1332.9348),\n",
       " ([1, (552, 76)], 1332.8776),\n",
       " ([1, (405, 62)], 1332.2625),\n",
       " ([1, (183, 76)], 1331.6853),\n",
       " ([1, (285, 48)], 1331.523),\n",
       " ([1, (527, 48)], 1331.206),\n",
       " ([1, (184, 76)], 1330.7446),\n",
       " ([1, (157, 76)], 1330.6643),\n",
       " ([1, (243, 90)], 1329.51),\n",
       " ([1, (125, 76)], 1329.034),\n",
       " ([1, (569, 62)], 1328.5195),\n",
       " ([1, (432, 62)], 1328.5037),\n",
       " ([1, (441, 90)], 1328.3164),\n",
       " ([1, (577, 90)], 1328.2355),\n",
       " ([1, (427, 76)], 1327.8403),\n",
       " ([1, (127, 76)], 1327.4553),\n",
       " ([1, (270, 90)], 1327.2279),\n",
       " ([1, (639, 48)], 1327.0582),\n",
       " ([1, (323, 62)], 1326.905),\n",
       " ([1, (296, 62)], 1326.7086),\n",
       " ([1, (413, 90)], 1326.5608),\n",
       " ([1, (152, 76)], 1326.4342),\n",
       " ([1, (371, 76)], 1326.3391),\n",
       " ([1, (350, 90)], 1326.0542),\n",
       " ([1, (245, 76)], 1326.0444),\n",
       " ([1, (715, 76)], 1325.6204),\n",
       " ([1, (597, 90)], 1325.4723),\n",
       " ([1, (540, 90)], 1325.0642),\n",
       " ([1, (272, 90)], 1324.7888),\n",
       " ([1, (155, 76)], 1324.266),\n",
       " ([1, (68, 76)], 1324.1194),\n",
       " ([1, (711, 76)], 1324.0808),\n",
       " ([1, (180, 76)], 1323.9194),\n",
       " ([1, (385, 90)], 1323.1572),\n",
       " ([1, (356, 62)], 1322.8802),\n",
       " ([1, (242, 62)], 1322.8684),\n",
       " ([1, (430, 90)], 1322.4585),\n",
       " ([1, (652, 76)], 1322.3145),\n",
       " ([1, (40, 76)], 1322.0238),\n",
       " ([1, (121, 76)], 1321.8525),\n",
       " ([1, (404, 90)], 1321.7346),\n",
       " ([1, (269, 62)], 1321.5287),\n",
       " ([1, (329, 76)], 1320.6002),\n",
       " ([1, (71, 76)], 1320.4141),\n",
       " ([1, (156, 76)], 1319.9579),\n",
       " ([1, (483, 90)], 1319.9072),\n",
       " ([1, (710, 76)], 1319.715),\n",
       " ([1, (601, 90)], 1319.6799),\n",
       " ([1, (574, 62)], 1318.3914),\n",
       " ([1, (151, 76)], 1318.1772),\n",
       " ([1, (245, 62)], 1318.1523),\n",
       " ([1, (175, 76)], 1318.1227),\n",
       " ([1, (96, 76)], 1317.9316),\n",
       " ([1, (716, 76)], 1317.5326),\n",
       " ([1, (218, 48)], 1316.7578),\n",
       " ([1, (499, 48)], 1315.9521),\n",
       " ([1, (573, 62)], 1315.7687),\n",
       " ([1, (99, 76)], 1314.4813),\n",
       " ([1, (399, 76)], 1313.6089),\n",
       " ([1, (120, 76)], 1310.9246),\n",
       " ([1, (575, 62)], 1310.6453),\n",
       " ([1, (602, 90)], 1309.7175),\n",
       " ([1, (122, 76)], 1309.562),\n",
       " ([1, (718, 76)], 1309.4131),\n",
       " ([1, (269, 90)], 1308.5667),\n",
       " ([1, (484, 90)], 1308.4065),\n",
       " ([1, (431, 62)], 1308.1907),\n",
       " ([1, (717, 76)], 1307.3365),\n",
       " ([1, (123, 76)], 1307.2749),\n",
       " ([1, (95, 76)], 1305.3784),\n",
       " ([1, (680, 76)], 1304.9775),\n",
       " ([1, (552, 90)], 1304.821),\n",
       " ([1, (567, 76)], 1304.779),\n",
       " ([1, (131, 76)], 1304.582),\n",
       " ([1, (242, 90)], 1304.3303),\n",
       " ([1, (130, 76)], 1304.25),\n",
       " ([1, (600, 90)], 1304.2261),\n",
       " ([1, (128, 76)], 1304.0042),\n",
       " ([1, (599, 90)], 1303.5559),\n",
       " ([1, (97, 76)], 1301.2482),\n",
       " ([1, (572, 62)], 1300.3335),\n",
       " ([1, (598, 90)], 1299.8568),\n",
       " ([3, (25, 6)], 1298.9314),\n",
       " ([1, (160, 76)], 1298.2739),\n",
       " ([1, (709, 48)], 1297.4832),\n",
       " ([1, (580, 76)], 1296.4795),\n",
       " ([1, (384, 62)], 1296.4617),\n",
       " ([1, (350, 62)], 1296.4202),\n",
       " ([1, (43, 76)], 1296.4192),\n",
       " ([1, (579, 90)], 1296.1576),\n",
       " ([1, (576, 62)], 1296.107),\n",
       " ([1, (129, 76)], 1295.6301),\n",
       " ([1, (404, 62)], 1295.543),\n",
       " ([1, (98, 76)], 1295.4829),\n",
       " ([1, (577, 62)], 1295.3374),\n",
       " ([1, (67, 76)], 1294.9375),\n",
       " ([1, (539, 90)], 1294.459),\n",
       " ([1, (94, 76)], 1294.0339),\n",
       " ([1, (571, 62)], 1293.5287),\n",
       " ...]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, (93, 6)): 1,\n",
       " (3, (93, 4)): 2,\n",
       " (3, (93, 8)): 3,\n",
       " (3, (93, 0)): 4,\n",
       " (3, (9, 6)): 5,\n",
       " (3, (93, 2)): 6,\n",
       " (3, (45, 6)): 7,\n",
       " (3, (50, 6)): 8,\n",
       " (3, (71, 6)): 9,\n",
       " (3, (45, 4)): 10,\n",
       " (3, (9, 4)): 11,\n",
       " (3, (9, 8)): 12,\n",
       " (3, (5, 4)): 13,\n",
       " (3, (5, 6)): 14,\n",
       " (3, (45, 8)): 15,\n",
       " (3, (46, 7)): 16,\n",
       " (3, (27, 7)): 17,\n",
       " (3, (37, 7)): 18,\n",
       " (3, (33, 7)): 19,\n",
       " (3, (86, 4)): 20,\n",
       " (3, (67, 6)): 21,\n",
       " (3, (74, 4)): 22,\n",
       " (3, (42, 7)): 23,\n",
       " (3, (71, 4)): 24,\n",
       " (3, (74, 6)): 25,\n",
       " (3, (86, 6)): 26,\n",
       " (3, (50, 4)): 27,\n",
       " (3, (67, 4)): 28,\n",
       " (3, (9, 2)): 29,\n",
       " (3, (50, 8)): 30,\n",
       " (3, (45, 2)): 31,\n",
       " (3, (1, 6)): 32,\n",
       " (3, (71, 8)): 33,\n",
       " (1, (343, 48)): 34,\n",
       " (1, (371, 48)): 35,\n",
       " (1, (315, 48)): 36,\n",
       " (3, (34, 7)): 37,\n",
       " (3, (55, 6)): 38,\n",
       " (1, (399, 48)): 39,\n",
       " (1, (287, 48)): 40,\n",
       " (3, (50, 0)): 41,\n",
       " (1, (288, 48)): 42,\n",
       " (1, (441, 48)): 43,\n",
       " (1, (427, 48)): 44,\n",
       " (1, (469, 48)): 45,\n",
       " (1, (413, 48)): 46,\n",
       " (1, (316, 48)): 47,\n",
       " (1, (426, 48)): 48,\n",
       " (1, (385, 48)): 49,\n",
       " (1, (259, 48)): 50,\n",
       " (1, (454, 48)): 51,\n",
       " (1, (497, 48)): 52,\n",
       " (1, (398, 48)): 53,\n",
       " (1, (482, 48)): 54,\n",
       " (1, (260, 48)): 55,\n",
       " (1, (510, 48)): 56,\n",
       " (1, (538, 48)): 57,\n",
       " (1, (455, 48)): 58,\n",
       " (1, (328, 48)): 59,\n",
       " (1, (370, 48)): 60,\n",
       " (3, (59, 6)): 61,\n",
       " (1, (566, 48)): 62,\n",
       " (1, (541, 48)): 63,\n",
       " (1, (300, 48)): 64,\n",
       " (1, (569, 48)): 65,\n",
       " (1, (344, 48)): 66,\n",
       " (1, (342, 48)): 67,\n",
       " (1, (357, 48)): 68,\n",
       " (1, (594, 48)): 69,\n",
       " (1, (231, 48)): 70,\n",
       " (1, (458, 48)): 71,\n",
       " (1, (486, 48)): 72,\n",
       " (1, (525, 48)): 73,\n",
       " (1, (542, 48)): 74,\n",
       " (1, (356, 48)): 75,\n",
       " (1, (329, 48)): 76,\n",
       " (1, (514, 48)): 77,\n",
       " (1, (314, 48)): 78,\n",
       " (1, (430, 48)): 79,\n",
       " (1, (544, 48)): 80,\n",
       " (3, (23, 7)): 81,\n",
       " (1, (513, 48)): 82,\n",
       " (1, (543, 48)): 83,\n",
       " (1, (516, 48)): 84,\n",
       " (1, (550, 48)): 85,\n",
       " (1, (570, 48)): 86,\n",
       " (1, (622, 48)): 87,\n",
       " (1, (597, 48)): 88,\n",
       " (1, (488, 48)): 89,\n",
       " (1, (515, 48)): 90,\n",
       " (1, (483, 48)): 91,\n",
       " (1, (232, 48)): 92,\n",
       " (1, (286, 48)): 93,\n",
       " (1, (272, 48)): 94,\n",
       " (1, (547, 48)): 95,\n",
       " (1, (487, 48)): 96,\n",
       " (3, (93, 3)): 97,\n",
       " (1, (494, 48)): 98,\n",
       " (1, (301, 48)): 99,\n",
       " (1, (571, 48)): 100,\n",
       " (1, (459, 48)): 101,\n",
       " (1, (522, 48)): 102,\n",
       " (1, (572, 48)): 103,\n",
       " (1, (402, 48)): 104,\n",
       " (1, (625, 48)): 105,\n",
       " (1, (553, 48)): 106,\n",
       " (1, (374, 48)): 107,\n",
       " (1, (466, 48)): 108,\n",
       " (1, (548, 48)): 109,\n",
       " (1, (578, 48)): 110,\n",
       " (1, (460, 48)): 111,\n",
       " (1, (545, 48)): 112,\n",
       " (1, (519, 48)): 113,\n",
       " (1, (575, 48)): 114,\n",
       " (1, (485, 48)): 115,\n",
       " (1, (576, 48)): 116,\n",
       " (1, (431, 48)): 117,\n",
       " (1, (573, 48)): 118,\n",
       " (1, (517, 48)): 119,\n",
       " (1, (520, 48)): 120,\n",
       " (1, (273, 48)): 121,\n",
       " (1, (491, 48)): 122,\n",
       " (1, (492, 48)): 123,\n",
       " (1, (432, 48)): 124,\n",
       " (1, (372, 48)): 125,\n",
       " (1, (384, 48)): 126,\n",
       " (1, (346, 48)): 127,\n",
       " (1, (489, 48)): 128,\n",
       " (1, (549, 48)): 129,\n",
       " (1, (546, 48)): 130,\n",
       " (1, (464, 48)): 131,\n",
       " (1, (438, 48)): 132,\n",
       " (1, (203, 48)): 133,\n",
       " (1, (258, 48)): 134,\n",
       " (1, (577, 48)): 135,\n",
       " (1, (493, 48)): 136,\n",
       " (1, (574, 48)): 137,\n",
       " (1, (299, 48)): 138,\n",
       " (1, (461, 48)): 139,\n",
       " (1, (442, 48)): 140,\n",
       " (1, (463, 48)): 141,\n",
       " (1, (465, 48)): 142,\n",
       " (1, (600, 48)): 143,\n",
       " (1, (518, 48)): 144,\n",
       " (1, (521, 48)): 145,\n",
       " (1, (289, 48)): 146,\n",
       " (1, (436, 48)): 147,\n",
       " (1, (403, 48)): 148,\n",
       " (1, (599, 48)): 149,\n",
       " (1, (490, 48)): 150,\n",
       " (1, (470, 48)): 151,\n",
       " (1, (404, 48)): 152,\n",
       " (1, (318, 48)): 153,\n",
       " (1, (204, 48)): 154,\n",
       " (1, (457, 48)): 155,\n",
       " (1, (376, 48)): 156,\n",
       " (1, (375, 48)): 157,\n",
       " (1, (601, 48)): 158,\n",
       " (1, (435, 48)): 159,\n",
       " (1, (598, 48)): 160,\n",
       " (1, (511, 48)): 161,\n",
       " (1, (414, 48)): 162,\n",
       " (1, (410, 48)): 163,\n",
       " (1, (462, 48)): 164,\n",
       " (1, (433, 48)): 165,\n",
       " (1, (581, 48)): 166,\n",
       " (1, (603, 48)): 167,\n",
       " (1, (498, 48)): 168,\n",
       " (1, (317, 48)): 169,\n",
       " (1, (245, 48)): 170,\n",
       " (1, (437, 48)): 171,\n",
       " (1, (244, 48)): 172,\n",
       " (1, (628, 48)): 173,\n",
       " (1, (526, 48)): 174,\n",
       " (1, (380, 48)): 175,\n",
       " (1, (381, 48)): 176,\n",
       " (1, (408, 48)): 177,\n",
       " (1, (271, 48)): 178,\n",
       " (1, (627, 48)): 179,\n",
       " (1, (606, 48)): 180,\n",
       " (1, (554, 48)): 181,\n",
       " (1, (604, 48)): 182,\n",
       " (1, (409, 48)): 183,\n",
       " (1, (602, 48)): 184,\n",
       " (1, (261, 48)): 185,\n",
       " (1, (382, 48)): 186,\n",
       " (1, (434, 48)): 187,\n",
       " (1, (327, 48)): 188,\n",
       " (1, (582, 48)): 189,\n",
       " (1, (650, 48)): 190,\n",
       " (1, (626, 48)): 191,\n",
       " (1, (631, 48)): 192,\n",
       " (1, (290, 48)): 193,\n",
       " (1, (386, 48)): 194,\n",
       " (1, (629, 48)): 195,\n",
       " (1, (407, 48)): 196,\n",
       " (1, (176, 48)): 197,\n",
       " (1, (405, 48)): 198,\n",
       " (1, (632, 48)): 199,\n",
       " (1, (377, 48)): 200,\n",
       " (1, (347, 48)): 201,\n",
       " (1, (605, 48)): 202,\n",
       " (1, (348, 48)): 203,\n",
       " (1, (610, 48)): 204,\n",
       " (1, (634, 48)): 205,\n",
       " (1, (429, 48)): 206,\n",
       " (1, (379, 48)): 207,\n",
       " (1, (630, 48)): 208,\n",
       " (1, (243, 48)): 209,\n",
       " (1, (345, 48)): 210,\n",
       " (1, (205, 48)): 211,\n",
       " (1, (177, 48)): 212,\n",
       " (1, (373, 48)): 213,\n",
       " (1, (406, 48)): 214,\n",
       " (1, (353, 48)): 215,\n",
       " (1, (354, 48)): 216,\n",
       " (1, (326, 48)): 217,\n",
       " (1, (233, 48)): 218,\n",
       " (1, (325, 48)): 219,\n",
       " (1, (633, 48)): 220,\n",
       " (1, (378, 48)): 221,\n",
       " (1, (349, 48)): 222,\n",
       " (1, (401, 48)): 223,\n",
       " (1, (319, 48)): 224,\n",
       " (1, (149, 48)): 225,\n",
       " (1, (262, 48)): 226,\n",
       " (1, (175, 48)): 227,\n",
       " (1, (291, 48)): 228,\n",
       " (1, (352, 48)): 229,\n",
       " (1, (653, 48)): 230,\n",
       " (1, (215, 48)): 231,\n",
       " (1, (638, 48)): 232,\n",
       " (1, (122, 48)): 233,\n",
       " (1, (216, 48)): 234,\n",
       " (1, (350, 48)): 235,\n",
       " (1, (206, 48)): 236,\n",
       " (1, (320, 48)): 237,\n",
       " (1, (355, 48)): 238,\n",
       " (1, (539, 48)): 239,\n",
       " (1, (351, 48)): 240,\n",
       " (1, (358, 48)): 241,\n",
       " (3, (71, 0)): 242,\n",
       " (1, (230, 48)): 243,\n",
       " (1, (412, 48)): 244,\n",
       " (1, (298, 48)): 245,\n",
       " (1, (178, 48)): 246,\n",
       " (1, (217, 48)): 247,\n",
       " (3, (1, 4)): 248,\n",
       " (1, (579, 48)): 249,\n",
       " (1, (187, 48)): 250,\n",
       " (1, (150, 48)): 251,\n",
       " (1, (188, 48)): 252,\n",
       " (1, (234, 48)): 253,\n",
       " (1, (158, 48)): 254,\n",
       " (1, (148, 48)): 255,\n",
       " (1, (324, 48)): 256,\n",
       " (1, (321, 48)): 257,\n",
       " (1, (159, 48)): 258,\n",
       " (1, (270, 48)): 259,\n",
       " (1, (123, 48)): 260,\n",
       " (1, (609, 48)): 261,\n",
       " (1, (129, 48)): 262,\n",
       " (1, (323, 48)): 263,\n",
       " (1, (186, 48)): 264,\n",
       " (1, (551, 48)): 265,\n",
       " (1, (400, 48)): 266,\n",
       " (1, (151, 48)): 267,\n",
       " (1, (185, 48)): 268,\n",
       " (1, (99, 48)): 269,\n",
       " (1, (322, 48)): 270,\n",
       " (1, (153, 48)): 271,\n",
       " (1, (157, 48)): 272,\n",
       " (1, (295, 48)): 273,\n",
       " (1, (214, 48)): 274,\n",
       " (1, (96, 48)): 275,\n",
       " (1, (297, 48)): 276,\n",
       " (1, (95, 48)): 277,\n",
       " (1, (127, 48)): 278,\n",
       " (1, (292, 48)): 279,\n",
       " (1, (263, 48)): 280,\n",
       " (1, (296, 48)): 281,\n",
       " (1, (152, 48)): 282,\n",
       " (1, (124, 48)): 283,\n",
       " (1, (330, 48)): 284,\n",
       " (1, (659, 48)): 285,\n",
       " (1, (155, 48)): 286,\n",
       " (1, (154, 48)): 287,\n",
       " (1, (156, 48)): 288,\n",
       " (1, (656, 48)): 289,\n",
       " (1, (241, 48)): 290,\n",
       " (1, (125, 48)): 291,\n",
       " (1, (607, 48)): 292,\n",
       " (1, (383, 48)): 293,\n",
       " (1, (126, 48)): 294,\n",
       " (1, (179, 48)): 295,\n",
       " (1, (128, 48)): 296,\n",
       " (1, (657, 48)): 297,\n",
       " (1, (655, 48)): 298,\n",
       " (1, (242, 48)): 299,\n",
       " (1, (264, 48)): 300,\n",
       " (1, (294, 48)): 301,\n",
       " (1, (182, 48)): 302,\n",
       " (1, (293, 48)): 303,\n",
       " (1, (207, 48)): 304,\n",
       " (1, (660, 48)): 305,\n",
       " (1, (654, 48)): 306,\n",
       " (1, (267, 48)): 307,\n",
       " (1, (130, 48)): 308,\n",
       " (1, (235, 48)): 309,\n",
       " (1, (213, 48)): 310,\n",
       " (1, (236, 48)): 311,\n",
       " (1, (181, 48)): 312,\n",
       " (1, (183, 48)): 313,\n",
       " (1, (658, 48)): 314,\n",
       " (1, (94, 48)): 315,\n",
       " (1, (635, 48)): 316,\n",
       " (1, (678, 48)): 317,\n",
       " (1, (666, 48)): 318,\n",
       " (1, (184, 48)): 319,\n",
       " (1, (269, 48)): 320,\n",
       " (1, (239, 48)): 321,\n",
       " (1, (662, 48)): 322,\n",
       " (1, (523, 48)): 323,\n",
       " (1, (240, 48)): 324,\n",
       " (1, (180, 48)): 325,\n",
       " (1, (237, 48)): 326,\n",
       " (1, (71, 48)): 327,\n",
       " (1, (211, 48)): 328,\n",
       " (1, (100, 48)): 329,\n",
       " (1, (268, 48)): 330,\n",
       " (1, (68, 48)): 331,\n",
       " (1, (101, 48)): 332,\n",
       " (1, (97, 48)): 333,\n",
       " (1, (661, 48)): 334,\n",
       " (1, (72, 48)): 335,\n",
       " (1, (266, 48)): 336,\n",
       " (1, (238, 48)): 337,\n",
       " (1, (212, 48)): 338,\n",
       " (1, (121, 48)): 339,\n",
       " (1, (98, 48)): 340,\n",
       " (1, (209, 48)): 341,\n",
       " (1, (210, 48)): 342,\n",
       " (1, (265, 48)): 343,\n",
       " (1, (208, 48)): 344,\n",
       " (1, (567, 48)): 345,\n",
       " (1, (160, 48)): 346,\n",
       " (1, (440, 48)): 347,\n",
       " (1, (411, 48)): 348,\n",
       " (1, (467, 48)): 349,\n",
       " (1, (495, 48)): 350,\n",
       " (1, (439, 48)): 351,\n",
       " (1, (637, 48)): 352,\n",
       " (1, (428, 48)): 353,\n",
       " (1, (302, 48)): 354,\n",
       " (1, (69, 48)): 355,\n",
       " (3, (8, 4)): 356,\n",
       " (1, (481, 48)): 357,\n",
       " (1, (147, 48)): 358,\n",
       " (1, (509, 48)): 359,\n",
       " (1, (189, 48)): 360,\n",
       " (1, (202, 48)): 361,\n",
       " (1, (663, 48)): 362,\n",
       " (1, (67, 48)): 363,\n",
       " (1, (453, 48)): 364,\n",
       " (3, (40, 7)): 365,\n",
       " (1, (565, 48)): 366,\n",
       " (1, (537, 48)): 367,\n",
       " (3, (70, 7)): 368,\n",
       " (1, (694, 48)): 369,\n",
       " (1, (468, 48)): 370,\n",
       " (1, (425, 48)): 371,\n",
       " (1, (706, 48)): 372,\n",
       " (1, (456, 48)): 373,\n",
       " (1, (70, 48)): 374,\n",
       " (1, (593, 48)): 375,\n",
       " (1, (102, 48)): 376,\n",
       " (1, (40, 48)): 377,\n",
       " (1, (44, 48)): 378,\n",
       " (1, (131, 48)): 379,\n",
       " (1, (43, 48)): 380,\n",
       " (1, (73, 48)): 381,\n",
       " (1, (595, 48)): 382,\n",
       " (1, (621, 48)): 383,\n",
       " (1, (681, 48)): 384,\n",
       " (1, (397, 48)): 385,\n",
       " (3, (14, 4)): 386,\n",
       " (3, (62, 7)): 387,\n",
       " (1, (484, 48)): 388,\n",
       " (1, (41, 48)): 389,\n",
       " (1, (274, 48)): 390,\n",
       " (1, (496, 48)): 391,\n",
       " (1, (541, 76)): 392,\n",
       " (1, (120, 48)): 393,\n",
       " (1, (665, 48)): 394,\n",
       " (1, (687, 48)): 395,\n",
       " (1, (569, 76)): 396,\n",
       " (1, (684, 48)): 397,\n",
       " (1, (688, 48)): 398,\n",
       " (1, (512, 48)): 399,\n",
       " (1, (685, 48)): 400,\n",
       " (1, (686, 48)): 401,\n",
       " (1, (683, 48)): 402,\n",
       " (1, (682, 48)): 403,\n",
       " (1, (690, 48)): 404,\n",
       " (1, (513, 76)): 405,\n",
       " (1, (722, 48)): 406,\n",
       " (1, (540, 48)): 407,\n",
       " (1, (649, 48)): 408,\n",
       " (1, (42, 48)): 409,\n",
       " (1, (546, 76)): 410,\n",
       " (1, (544, 76)): 411,\n",
       " (1, (545, 76)): 412,\n",
       " (1, (689, 48)): 413,\n",
       " (1, (547, 76)): 414,\n",
       " (1, (369, 48)): 415,\n",
       " (1, (543, 76)): 416,\n",
       " (1, (548, 76)): 417,\n",
       " (1, (66, 48)): 418,\n",
       " (1, (549, 76)): 419,\n",
       " (1, (568, 48)): 420,\n",
       " (1, (300, 76)): 421,\n",
       " (1, (571, 76)): 422,\n",
       " (1, (597, 76)): 423,\n",
       " (1, (572, 76)): 424,\n",
       " (1, (518, 76)): 425,\n",
       " (1, (570, 76)): 426,\n",
       " (1, (574, 76)): 427,\n",
       " (1, (485, 76)): 428,\n",
       " (1, (519, 76)): 429,\n",
       " (1, (575, 76)): 430,\n",
       " (1, (516, 76)): 431,\n",
       " (1, (517, 76)): 432,\n",
       " (1, (542, 76)): 433,\n",
       " (1, (573, 76)): 434,\n",
       " (1, (93, 48)): 435,\n",
       " (1, (524, 48)): 436,\n",
       " (1, (576, 76)): 437,\n",
       " (1, (486, 76)): 438,\n",
       " (1, (514, 76)): 439,\n",
       " (1, (328, 76)): 440,\n",
       " (1, (272, 76)): 441,\n",
       " (1, (623, 48)): 442,\n",
       " (1, (520, 76)): 443,\n",
       " (1, (462, 76)): 444,\n",
       " (1, (522, 76)): 445,\n",
       " (1, (577, 76)): 446,\n",
       " (1, (521, 76)): 447,\n",
       " (1, (515, 76)): 448,\n",
       " (1, (491, 76)): 449,\n",
       " (1, (490, 76)): 450,\n",
       " (1, (550, 76)): 451,\n",
       " (1, (489, 76)): 452,\n",
       " (1, (596, 48)): 453,\n",
       " (1, (487, 76)): 454,\n",
       " (1, (522, 90)): 455,\n",
       " (1, (457, 76)): 456,\n",
       " (1, (463, 76)): 457,\n",
       " (1, (599, 76)): 458,\n",
       " (1, (601, 76)): 459,\n",
       " (1, (494, 76)): 460,\n",
       " (1, (602, 76)): 461,\n",
       " (1, (488, 76)): 462,\n",
       " (1, (578, 76)): 463,\n",
       " (1, (600, 76)): 464,\n",
       " (1, (299, 76)): 465,\n",
       " (1, (327, 76)): 466,\n",
       " (3, (27, 9)): 467,\n",
       " (1, (598, 76)): 468,\n",
       " (1, (493, 76)): 469,\n",
       " (1, (603, 76)): 470,\n",
       " (1, (174, 48)): 471,\n",
       " (1, (461, 76)): 472,\n",
       " (1, (356, 76)): 473,\n",
       " (1, (459, 76)): 474,\n",
       " (1, (492, 76)): 475,\n",
       " (1, (458, 76)): 476,\n",
       " (1, (271, 76)): 477,\n",
       " (1, (434, 76)): 478,\n",
       " (3, (66, 4)): 479,\n",
       " (1, (460, 76)): 480,\n",
       " (1, (435, 76)): 481,\n",
       " (1, (466, 76)): 482,\n",
       " (1, (552, 48)): 483,\n",
       " (1, (518, 62)): 484,\n",
       " (1, (161, 48)): 485,\n",
       " (1, (355, 76)): 486,\n",
       " (1, (604, 76)): 487,\n",
       " (1, (518, 90)): 488,\n",
       " (1, (625, 76)): 489,\n",
       " (1, (244, 76)): 490,\n",
       " (1, (517, 90)): 491,\n",
       " (1, (465, 76)): 492,\n",
       " (1, (132, 48)): 493,\n",
       " (1, (433, 76)): 494,\n",
       " (1, (551, 76)): 495,\n",
       " (1, (382, 76)): 496,\n",
       " (1, (519, 90)): 497,\n",
       " (1, (519, 62)): 498,\n",
       " (1, (410, 76)): 499,\n",
       " (1, (431, 76)): 500,\n",
       " (1, (438, 76)): 501,\n",
       " (1, (523, 62)): 502,\n",
       " (1, (325, 76)): 503,\n",
       " (1, (429, 76)): 504,\n",
       " (1, (677, 48)): 505,\n",
       " (1, (379, 76)): 506,\n",
       " (1, (407, 76)): 507,\n",
       " (1, (341, 48)): 508,\n",
       " (1, (436, 76)): 509,\n",
       " (1, (605, 76)): 510,\n",
       " (1, (522, 62)): 511,\n",
       " (1, (494, 90)): 512,\n",
       " (1, (734, 48)): 513,\n",
       " (1, (579, 76)): 514,\n",
       " (1, (430, 76)): 515,\n",
       " (1, (432, 76)): 516,\n",
       " (1, (297, 76)): 517,\n",
       " (1, (406, 76)): 518,\n",
       " (1, (624, 48)): 519,\n",
       " (1, (437, 76)): 520,\n",
       " (1, (464, 76)): 521,\n",
       " (1, (523, 76)): 522,\n",
       " (1, (521, 62)): 523,\n",
       " (1, (606, 76)): 524,\n",
       " (1, (288, 76)): 525,\n",
       " (1, (517, 62)): 526,\n",
       " (3, (55, 4)): 527,\n",
       " (1, (354, 76)): 528,\n",
       " (1, (353, 76)): 529,\n",
       " (1, (381, 76)): 530,\n",
       " (1, (351, 76)): 531,\n",
       " (1, (243, 76)): 532,\n",
       " (1, (409, 76)): 533,\n",
       " (1, (693, 48)): 534,\n",
       " (1, (520, 90)): 535,\n",
       " (1, (629, 76)): 536,\n",
       " (1, (691, 48)): 537,\n",
       " (1, (326, 76)): 538,\n",
       " (1, (630, 76)): 539,\n",
       " (1, (494, 62)): 540,\n",
       " (1, (466, 90)): 541,\n",
       " (1, (408, 76)): 542,\n",
       " (1, (260, 76)): 543,\n",
       " (1, (521, 90)): 544,\n",
       " (1, (298, 76)): 545,\n",
       " (1, (352, 76)): 546,\n",
       " (1, (384, 76)): 547,\n",
       " (1, (378, 76)): 548,\n",
       " (1, (493, 62)): 549,\n",
       " (1, (246, 48)): 550,\n",
       " (1, (628, 76)): 551,\n",
       " (1, (466, 62)): 552,\n",
       " (1, (405, 76)): 553,\n",
       " (1, (438, 90)): 554,\n",
       " (1, (607, 76)): 555,\n",
       " (1, (627, 76)): 556,\n",
       " (1, (520, 62)): 557,\n",
       " (1, (316, 76)): 558,\n",
       " (1, (495, 62)): 559,\n",
       " (3, (33, 9)): 560,\n",
       " (1, (383, 76)): 561,\n",
       " (1, (580, 48)): 562,\n",
       " (1, (631, 76)): 563,\n",
       " (1, (380, 76)): 564,\n",
       " (1, (377, 76)): 565,\n",
       " (1, (404, 76)): 566,\n",
       " (1, (324, 76)): 567,\n",
       " (1, (490, 62)): 568,\n",
       " (1, (491, 62)): 569,\n",
       " (1, (490, 90)): 570,\n",
       " (1, (270, 76)): 571,\n",
       " (1, (546, 90)): 572,\n",
       " (1, (516, 90)): 573,\n",
       " (1, (495, 76)): 574,\n",
       " (3, (99, 7)): 575,\n",
       " (1, (403, 76)): 576,\n",
       " (1, (382, 62)): 577,\n",
       " (1, (626, 76)): 578,\n",
       " (1, (545, 90)): 579,\n",
       " (1, (232, 76)): 580,\n",
       " (1, (462, 90)): 581,\n",
       " (1, (438, 62)): 582,\n",
       " (1, (39, 48)): 583,\n",
       " (1, (402, 76)): 584,\n",
       " (1, (269, 76)): 585,\n",
       " (1, (491, 90)): 586,\n",
       " (1, (410, 62)): 587,\n",
       " (1, (410, 90)): 588,\n",
       " (1, (462, 62)): 589,\n",
       " (1, (382, 90)): 590,\n",
       " (1, (492, 62)): 591,\n",
       " (1, (493, 90)): 592,\n",
       " (1, (632, 76)): 593,\n",
       " (1, (411, 76)): 594,\n",
       " (1, (547, 90)): 595,\n",
       " (1, (323, 76)): 596,\n",
       " (1, (489, 62)): 597,\n",
       " (1, (489, 90)): 598,\n",
       " (1, (541, 90)): 599,\n",
       " (1, (467, 62)): 600,\n",
       " (1, (272, 62)): 601,\n",
       " (1, (376, 76)): 602,\n",
       " (1, (465, 62)): 603,\n",
       " (1, (350, 76)): 604,\n",
       " (1, (492, 90)): 605,\n",
       " (1, (344, 76)): 606,\n",
       " (1, (653, 76)): 607,\n",
       " (1, (467, 76)): 608,\n",
       " (1, (401, 76)): 609,\n",
       " (1, (384, 90)): 610,\n",
       " (1, (463, 62)): 611,\n",
       " (1, (513, 90)): 612,\n",
       " (1, (242, 76)): 613,\n",
       " (1, (515, 90)): 614,\n",
       " (1, (349, 76)): 615,\n",
       " (1, (463, 90)): 616,\n",
       " (1, (657, 76)): 617,\n",
       " (1, (544, 90)): 618,\n",
       " (1, (523, 90)): 619,\n",
       " (1, (296, 76)): 620,\n",
       " (1, (300, 62)): 621,\n",
       " (1, (295, 76)): 622,\n",
       " (1, (543, 90)): 623,\n",
       " (1, (633, 76)): 624,\n",
       " (1, (215, 76)): 625,\n",
       " (1, (411, 62)): 626,\n",
       " (1, (465, 90)): 627,\n",
       " (1, (439, 76)): 628,\n",
       " (1, (464, 62)): 629,\n",
       " (1, (439, 62)): 630,\n",
       " (1, (516, 62)): 631,\n",
       " (1, (550, 90)): 632,\n",
       " (1, (656, 76)): 633,\n",
       " (1, (412, 76)): 634,\n",
       " (1, (658, 76)): 635,\n",
       " (1, (750, 48)): 636,\n",
       " (1, (546, 62)): 637,\n",
       " (1, (634, 76)): 638,\n",
       " (1, (548, 90)): 639,\n",
       " (1, (436, 62)): 640,\n",
       " (1, (635, 76)): 641,\n",
       " (1, (383, 62)): 642,\n",
       " (1, (464, 90)): 643,\n",
       " (1, (545, 62)): 644,\n",
       " (1, (513, 62)): 645,\n",
       " (1, (659, 76)): 646,\n",
       " (1, (435, 90)): 647,\n",
       " (1, (436, 90)): 648,\n",
       " (1, (241, 76)): 649,\n",
       " (1, (461, 90)): 650,\n",
       " (1, (461, 62)): 651,\n",
       " (1, (514, 90)): 652,\n",
       " (1, (216, 76)): 653,\n",
       " (1, (681, 76)): 654,\n",
       " (1, (434, 90)): 655,\n",
       " (1, (354, 62)): 656,\n",
       " (1, (322, 76)): 657,\n",
       " (1, (488, 90)): 658,\n",
       " (1, (375, 76)): 659,\n",
       " (1, (655, 76)): 660,\n",
       " (1, (435, 62)): 661,\n",
       " (1, (437, 62)): 662,\n",
       " (1, (547, 62)): 663,\n",
       " (1, (685, 76)): 664,\n",
       " (1, (686, 76)): 665,\n",
       " (1, (549, 90)): 666,\n",
       " (1, (437, 90)): 667,\n",
       " (1, (214, 76)): 668,\n",
       " (1, (412, 90)): 669,\n",
       " (1, (268, 76)): 670,\n",
       " (1, (373, 76)): 671,\n",
       " (1, (383, 90)): 672,\n",
       " (1, (289, 76)): 673,\n",
       " (1, (374, 76)): 674,\n",
       " (1, (495, 90)): 675,\n",
       " (1, (204, 76)): 676,\n",
       " (1, (356, 90)): 677,\n",
       " (1, (408, 62)): 678,\n",
       " (1, (488, 62)): 679,\n",
       " (3, (19, 4)): 680,\n",
       " (1, (327, 90)): 681,\n",
       " (1, (684, 76)): 682,\n",
       " (1, (355, 90)): 683,\n",
       " (1, (326, 62)): 684,\n",
       " (1, (348, 76)): 685,\n",
       " (1, (485, 90)): 686,\n",
       " (1, (542, 90)): 687,\n",
       " (1, (74, 48)): 688,\n",
       " (1, (487, 90)): 689,\n",
       " (1, (515, 62)): 690,\n",
       " (1, (355, 62)): 691,\n",
       " (1, (654, 76)): 692,\n",
       " (1, (434, 62)): 693,\n",
       " (1, (313, 48)): 694,\n",
       " (1, (261, 76)): 695,\n",
       " (1, (407, 62)): 696,\n",
       " (1, (317, 76)): 697,\n",
       " (1, (287, 76)): 698,\n",
       " (1, (408, 90)): 699,\n",
       " (1, (660, 76)): 700,\n",
       " (1, (345, 76)): 701,\n",
       " (1, (267, 76)): 702,\n",
       " (1, (409, 62)): 703,\n",
       " (1, (687, 76)): 704,\n",
       " (1, (651, 48)): 705,\n",
       " (1, (549, 62)): 706,\n",
       " (1, (381, 62)): 707,\n",
       " (1, (468, 90)): 708,\n",
       " (1, (354, 90)): 709,\n",
       " (1, (259, 76)): 710,\n",
       " (1, (294, 76)): 711,\n",
       " (1, (409, 90)): 712,\n",
       " (1, (433, 90)): 713,\n",
       " (1, (548, 62)): 714,\n",
       " (1, (372, 76)): 715,\n",
       " (1, (688, 76)): 716,\n",
       " (1, (440, 90)): 717,\n",
       " (1, (381, 90)): 718,\n",
       " (1, (661, 76)): 719,\n",
       " (1, (467, 90)): 720,\n",
       " (1, (321, 76)): 721,\n",
       " (1, (315, 76)): 722,\n",
       " (1, (683, 76)): 723,\n",
       " (1, (411, 90)): 724,\n",
       " (1, (544, 62)): 725,\n",
       " (1, (487, 62)): 726,\n",
       " (1, (353, 62)): 727,\n",
       " (1, (299, 90)): 728,\n",
       " (1, (439, 90)): 729,\n",
       " (1, (119, 48)): 730,\n",
       " (1, (407, 90)): 731,\n",
       " (1, (608, 48)): 732,\n",
       " (1, (233, 76)): 733,\n",
       " (1, (486, 90)): 734,\n",
       " (1, (514, 62)): 735,\n",
       " (1, (541, 62)): 736,\n",
       " (1, (347, 76)): 737,\n",
       " (1, (689, 76)): 738,\n",
       " (1, (231, 76)): 739,\n",
       " (1, (540, 76)): 740,\n",
       " (1, (353, 90)): 741,\n",
       " (1, (326, 90)): 742,\n",
       " (1, (682, 76)): 743,\n",
       " (1, (568, 76)): 744,\n",
       " (1, (380, 90)): 745,\n",
       " (1, (485, 62)): 746,\n",
       " (1, (328, 90)): 747,\n",
       " (1, (187, 76)): 748,\n",
       " (1, (551, 62)): 749,\n",
       " (1, (379, 90)): 750,\n",
       " (1, (705, 48)): 751,\n",
       " (1, (325, 62)): 752,\n",
       " (1, (325, 90)): 753,\n",
       " (1, (244, 62)): 754,\n",
       " (1, (320, 76)): 755,\n",
       " (1, (240, 76)): 756,\n",
       " (1, (346, 76)): 757,\n",
       " (1, (440, 76)): 758,\n",
       " (1, (460, 90)): 759,\n",
       " (1, (652, 48)): 760,\n",
       " (1, (524, 90)): 761,\n",
       " (1, (543, 62)): 762,\n",
       " (1, (406, 90)): 763,\n",
       " (3, (66, 6)): 764,\n",
       " (1, (298, 62)): 765,\n",
       " (3, (42, 9)): 766,\n",
       " (1, (406, 62)): 767,\n",
       " (1, (496, 90)): 768,\n",
       " (1, (328, 62)): 769,\n",
       " (1, (663, 76)): 770,\n",
       " (1, (266, 76)): 771,\n",
       " (1, (380, 62)): 772,\n",
       " (1, (318, 76)): 773,\n",
       " (1, (327, 62)): 774,\n",
       " (1, (213, 76)): 775,\n",
       " (1, (352, 62)): 776,\n",
       " (1, (459, 90)): 777,\n",
       " (1, (352, 90)): 778,\n",
       " (1, (290, 76)): 779,\n",
       " (1, (379, 62)): 780,\n",
       " (1, (433, 62)): 781,\n",
       " (1, (273, 62)): 782,\n",
       " (1, (460, 62)): 783,\n",
       " (1, (690, 76)): 784,\n",
       " (1, (324, 62)): 785,\n",
       " (1, (550, 62)): 786,\n",
       " (1, (596, 76)): 787,\n",
       " (1, (662, 76)): 788,\n",
       " (1, (512, 76)): 789,\n",
       " (1, (239, 76)): 790,\n",
       " (1, (186, 76)): 791,\n",
       " (1, (262, 76)): 792,\n",
       " (1, (205, 76)): 793,\n",
       " (1, (176, 76)): 794,\n",
       " (1, (569, 90)): 795,\n",
       " (1, (484, 76)): 796,\n",
       " (1, (486, 62)): 797,\n",
       " (1, (324, 90)): 798,\n",
       " (1, (691, 76)): 799,\n",
       " (1, (292, 76)): 800,\n",
       " (1, (319, 76)): 801,\n",
       " (1, (378, 90)): 802,\n",
       " (1, (271, 90)): 803,\n",
       " (1, (468, 76)): 804,\n",
       " (1, (400, 76)): 805,\n",
       " (1, (293, 76)): 806,\n",
       " (1, (573, 90)): 807,\n",
       " (1, (456, 76)): 808,\n",
       " (1, (297, 62)): 809,\n",
       " (1, (103, 48)): 810,\n",
       " (1, (291, 76)): 811,\n",
       " (1, (351, 90)): 812,\n",
       " (1, (299, 62)): 813,\n",
       " (1, (300, 90)): 814,\n",
       " (1, (551, 90)): 815,\n",
       " (1, (574, 90)): 816,\n",
       " (1, (428, 76)): 817,\n",
       " (1, (264, 76)): 818,\n",
       " (1, (457, 90)): 819,\n",
       " (1, (265, 76)): 820,\n",
       " (1, (301, 62)): 821,\n",
       " (1, (542, 62)): 822,\n",
       " (1, (458, 90)): 823,\n",
       " (1, (234, 76)): 824,\n",
       " (1, (203, 76)): 825,\n",
       " (1, (263, 76)): 826,\n",
       " (1, (149, 76)): 827,\n",
       " (1, (298, 90)): 828,\n",
       " (1, (271, 62)): 829,\n",
       " (1, (343, 76)): 830,\n",
       " (1, (351, 62)): 831,\n",
       " (1, (459, 62)): 832,\n",
       " (1, (238, 76)): 833,\n",
       " (1, (457, 62)): 834,\n",
       " (1, (624, 76)): 835,\n",
       " (1, (177, 76)): 836,\n",
       " (1, (378, 62)): 837,\n",
       " (1, (572, 90)): 838,\n",
       " (3, (46, 9)): 839,\n",
       " (1, (212, 76)): 840,\n",
       " (1, (432, 90)): 841,\n",
       " (1, (297, 90)): 842,\n",
       " (1, (188, 76)): 843,\n",
       " (1, (571, 90)): 844,\n",
       " (1, (185, 76)): 845,\n",
       " (1, (405, 90)): 846,\n",
       " (1, (570, 90)): 847,\n",
       " (1, (210, 76)): 848,\n",
       " (1, (511, 76)): 849,\n",
       " (1, (211, 76)): 850,\n",
       " (1, (525, 90)): 851,\n",
       " (1, (158, 76)): 852,\n",
       " (1, (182, 76)): 853,\n",
       " (1, (575, 90)): 854,\n",
       " (1, (483, 76)): 855,\n",
       " (1, (496, 76)): 856,\n",
       " (1, (206, 76)): 857,\n",
       " (1, (159, 76)): 858,\n",
       " (1, (583, 48)): 859,\n",
       " (1, (45, 48)): 860,\n",
       " (1, (235, 76)): 861,\n",
       " (1, (178, 76)): 862,\n",
       " (1, (721, 48)): 863,\n",
       " (1, (150, 76)): 864,\n",
       " (1, (243, 62)): 865,\n",
       " (1, (236, 76)): 866,\n",
       " (1, (329, 62)): 867,\n",
       " (1, (237, 76)): 868,\n",
       " (1, (455, 76)): 869,\n",
       " (1, (524, 76)): 870,\n",
       " (1, (431, 90)): 871,\n",
       " (1, (611, 48)): 872,\n",
       " (1, (209, 76)): 873,\n",
       " (1, (148, 76)): 874,\n",
       " (1, (377, 90)): 875,\n",
       " (1, (273, 76)): 876,\n",
       " (1, (154, 76)): 877,\n",
       " (1, (323, 90)): 878,\n",
       " (1, (555, 48)): 879,\n",
       " (1, (713, 76)): 880,\n",
       " (1, (469, 90)): 881,\n",
       " (1, (458, 62)): 882,\n",
       " (1, (270, 62)): 883,\n",
       " (1, (578, 90)): 884,\n",
       " (1, (207, 76)): 885,\n",
       " (1, (539, 76)): 886,\n",
       " (1, (153, 76)): 887,\n",
       " (1, (497, 90)): 888,\n",
       " (1, (714, 76)): 889,\n",
       " (1, (709, 76)): 890,\n",
       " (1, (181, 76)): 891,\n",
       " (1, (576, 90)): 892,\n",
       " (1, (126, 76)): 893,\n",
       " (1, (512, 90)): 894,\n",
       " (1, (511, 90)): 895,\n",
       " (1, (636, 48)): 896,\n",
       " (1, (712, 76)): 897,\n",
       " (1, (296, 90)): 898,\n",
       " (1, (301, 76)): 899,\n",
       " (1, (124, 76)): 900,\n",
       " (1, (208, 76)): 901,\n",
       " (1, (179, 76)): 902,\n",
       " (1, (552, 76)): 903,\n",
       " (1, (405, 62)): 904,\n",
       " (1, (183, 76)): 905,\n",
       " (1, (285, 48)): 906,\n",
       " (1, (527, 48)): 907,\n",
       " (1, (184, 76)): 908,\n",
       " (1, (157, 76)): 909,\n",
       " (1, (243, 90)): 910,\n",
       " (1, (125, 76)): 911,\n",
       " (1, (569, 62)): 912,\n",
       " (1, (432, 62)): 913,\n",
       " (1, (441, 90)): 914,\n",
       " (1, (577, 90)): 915,\n",
       " (1, (427, 76)): 916,\n",
       " (1, (127, 76)): 917,\n",
       " (1, (270, 90)): 918,\n",
       " (1, (639, 48)): 919,\n",
       " (1, (323, 62)): 920,\n",
       " (1, (296, 62)): 921,\n",
       " (1, (413, 90)): 922,\n",
       " (1, (152, 76)): 923,\n",
       " (1, (371, 76)): 924,\n",
       " (1, (350, 90)): 925,\n",
       " (1, (245, 76)): 926,\n",
       " (1, (715, 76)): 927,\n",
       " (1, (597, 90)): 928,\n",
       " (1, (540, 90)): 929,\n",
       " (1, (272, 90)): 930,\n",
       " (1, (155, 76)): 931,\n",
       " (1, (68, 76)): 932,\n",
       " (1, (711, 76)): 933,\n",
       " (1, (180, 76)): 934,\n",
       " (1, (385, 90)): 935,\n",
       " (1, (356, 62)): 936,\n",
       " (1, (242, 62)): 937,\n",
       " (1, (430, 90)): 938,\n",
       " (1, (652, 76)): 939,\n",
       " (1, (40, 76)): 940,\n",
       " (1, (121, 76)): 941,\n",
       " (1, (404, 90)): 942,\n",
       " (1, (269, 62)): 943,\n",
       " (1, (329, 76)): 944,\n",
       " (1, (71, 76)): 945,\n",
       " (1, (156, 76)): 946,\n",
       " (1, (483, 90)): 947,\n",
       " (1, (710, 76)): 948,\n",
       " (1, (601, 90)): 949,\n",
       " (1, (574, 62)): 950,\n",
       " (1, (151, 76)): 951,\n",
       " (1, (245, 62)): 952,\n",
       " (1, (175, 76)): 953,\n",
       " (1, (96, 76)): 954,\n",
       " (1, (716, 76)): 955,\n",
       " (1, (218, 48)): 956,\n",
       " (1, (499, 48)): 957,\n",
       " (1, (573, 62)): 958,\n",
       " (1, (99, 76)): 959,\n",
       " (1, (399, 76)): 960,\n",
       " (1, (120, 76)): 961,\n",
       " (1, (575, 62)): 962,\n",
       " (1, (602, 90)): 963,\n",
       " (1, (122, 76)): 964,\n",
       " (1, (718, 76)): 965,\n",
       " (1, (269, 90)): 966,\n",
       " (1, (484, 90)): 967,\n",
       " (1, (431, 62)): 968,\n",
       " (1, (717, 76)): 969,\n",
       " (1, (123, 76)): 970,\n",
       " (1, (95, 76)): 971,\n",
       " (1, (680, 76)): 972,\n",
       " (1, (552, 90)): 973,\n",
       " (1, (567, 76)): 974,\n",
       " (1, (131, 76)): 975,\n",
       " (1, (242, 90)): 976,\n",
       " (1, (130, 76)): 977,\n",
       " (1, (600, 90)): 978,\n",
       " (1, (128, 76)): 979,\n",
       " (1, (599, 90)): 980,\n",
       " (1, (97, 76)): 981,\n",
       " (1, (572, 62)): 982,\n",
       " (1, (598, 90)): 983,\n",
       " (3, (25, 6)): 984,\n",
       " (1, (160, 76)): 985,\n",
       " (1, (709, 48)): 986,\n",
       " (1, (580, 76)): 987,\n",
       " (1, (384, 62)): 988,\n",
       " (1, (350, 62)): 989,\n",
       " (1, (43, 76)): 990,\n",
       " (1, (579, 90)): 991,\n",
       " (1, (576, 62)): 992,\n",
       " (1, (129, 76)): 993,\n",
       " (1, (404, 62)): 994,\n",
       " (1, (98, 76)): 995,\n",
       " (1, (577, 62)): 996,\n",
       " (1, (67, 76)): 997,\n",
       " (1, (539, 90)): 998,\n",
       " (1, (94, 76)): 999,\n",
       " (1, (571, 62)): 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
